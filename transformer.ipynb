{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msAhyT0aHKeU",
        "outputId": "ae0dbe81-355a-4c11-8811-7c8af53d44e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-q5M9JFHAnP"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOrZ4JAGKZq9",
        "outputId": "4d53649c-0174-46f3-e87a-7a296e8de268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1\n"
          ]
        }
      ],
      "source": [
        "pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amO0Oi_yKdH-",
        "outputId": "3903d479-a791-4bb4-a6a8-49cab64bb5fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (2.7.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.5)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.13.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.2)\n",
            "Requirement already satisfied: torch<1.14,>=1.7 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.12.1+cu113)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.0.7)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (21.1.3)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.5.27)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.7.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (3.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.6.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.64.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.10.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (8.1.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.10)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4->fastai) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4->fastai) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4->fastai) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2022.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install -U fastai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woAxhdjfKoEt",
        "outputId": "eea07ee3-2cb3-446b-8342-54afa392f734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 63.7 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 66.3 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 69.6 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=c2144fbc007330edfdd1ae2c0e39778c07f9f00c71ad08e492716baf56cb1193\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.3 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-3.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCVKaWi3KjUg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(1)\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from tensorflow.keras.layers import BatchNormalization,Dropout\n",
        "from tensorflow.keras import models, layers, losses, optimizers, activations, regularizers\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZvNm_xZKrIQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oli40y6pKxHG"
      },
      "outputs": [],
      "source": [
        "from optuna.visualization import plot_contour\n",
        "from optuna.visualization import plot_edf\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_slice\n",
        "import joblib\n",
        "import pickle\n",
        "from keras.engine.input_spec import InputSpec\n",
        "initializer = tf.keras.initializers.Zeros()\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZw5RTc7K0hV"
      },
      "outputs": [],
      "source": [
        "flow = np.load('/content/drive/MyDrive/CNN model data/lung_data/flow400.npy')\n",
        "volume = np.load('/content/drive/MyDrive/CNN model data/lung_data/volume400.npy')\n",
        "paw = np.load('/content/drive/MyDrive/CNN model data/lung_data/paw400.npy')\n",
        "capacitances = np.load('/content/drive/MyDrive/CNN model data/lung_data/capacitances400.npy')\n",
        "resistances = np.load(\"/content/drive/MyDrive/CNN model data/lung_data/rins400.npy\")\n",
        "#output1 = np.load(\"/content/drive/MyDrive/CNN model data/output1.npy\")\n",
        "#input1 = np.load(\"/content/drive/MyDrive/CNN model data/input1.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVE4lUIfKy5r"
      },
      "outputs": [],
      "source": [
        "def reset_random_seeds():\n",
        "   os.environ['PYTHONHASHSEED']=str(1)\n",
        "   tf.random.set_seed(1)\n",
        "   np.random.seed(1)\n",
        "   random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hu5sN2WK96a"
      },
      "outputs": [],
      "source": [
        "def normalize_data(data, minimum = None,maximum = None):\n",
        "    if minimum is None:\n",
        "        minimum = np.min(np.min(data))\n",
        "    if maximum is None:\n",
        "        maximum = np.max(np.max(data))\n",
        "    data_norm = (data - minimum) / (maximum - minimum)\n",
        "    return minimum, maximum, data_norm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSVil5B1K2B7",
        "outputId": "0496bb07-22bc-410c-cc35-7a8d2edc085c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transposed\n",
            "num_samples are 400\n",
            "normalized data\n",
            "input created\n"
          ]
        }
      ],
      "source": [
        "flow = flow.T\n",
        "volume = volume.T\n",
        "paw = paw.T\n",
        "resistances = resistances.T\n",
        "capacitances = capacitances.T\n",
        "\n",
        "print(\"transposed\")\n",
        "\n",
        "num_examples = flow.shape[0]\n",
        "num_samples = flow.shape[1]\n",
        "print(\"num_samples are\",num_examples)\n",
        "(min_flow, max_flow, flow) = normalize_data(flow)\n",
        "(min_volume, max_volume, volume) = normalize_data(volume)\n",
        "(min_paw, max_paw, paw) = normalize_data(paw)\n",
        "(min_resistance, max_resistance, resistances) = normalize_data(resistances)\n",
        "(min_capacitance, max_capacitance, capacitances) = normalize_data(capacitances)\n",
        "\n",
        "print(\"normalized data\")\n",
        "\n",
        "input_data = np.zeros((num_examples, num_samples, 3))\n",
        "input_data[:, :, 0] = flow\n",
        "input_data[:, :, 1] = volume\n",
        "input_data[:, :, 2] = paw\n",
        "output_data = np.concatenate((resistances, capacitances), axis=1)\n",
        "indices = np.arange(num_examples)\n",
        "\n",
        "print(\"input created\")\n",
        "\n",
        "input_train, input_test, output_train, output_test, indices_train, indices_test = \\\n",
        "    train_test_split(input_data, output_data, indices, test_size=0.3, shuffle=False, random_state=11)\n",
        "\n",
        "input_validation, input_test, output_validation, output_test, indices_validation, indices_test = \\\n",
        "    train_test_split(input_test, output_test, indices_test, test_size=0.5, shuffle=False, random_state=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQRmFYCMLBls"
      },
      "outputs": [],
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "    print(res.shape)\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BarRfqoiNsVA"
      },
      "outputs": [],
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    \n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(2)(x)\n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWMo8u6KOYX4"
      },
      "outputs": [],
      "source": [
        "input_shape = input_train.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wDIEkghN2KN"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    reset_random_seeds()\n",
        "    params = {\n",
        "              'learning_rate': trial.suggest_uniform('learning_rate', 1e-5, 1e-3),\n",
        "              #'nb_filter': trial.suggest_categorical(\"nb_filter\", [2, 3]),\n",
        "              #'kernel_size': trial.suggest_int(\"kernel_size\",2, 3, 5),\n",
        "              'head_size': trial.suggest_int(\"head_size\",128,256),\n",
        "              'num_heads': trial.suggest_int(\"num_heads\",3,4,5),\n",
        "              'ff_dim': trial.suggest_int(\"ff_dim\",2,3,4),\n",
        "              'num_transformer_bock': trial.suggest_int(\"num_transformer_bock\",3,4),\n",
        "              'decay': trial.suggest_categorical(\"decay\",[1e-3, 1e-5]),\n",
        "              #'dense1': trial.suggest_int('dense1',50,100,150),\n",
        "              #'dense2': trial.suggest_int('dense2',50,100,150),\n",
        "              #'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
        "              #'activation1': trial.suggest_categorical(\"activation1\", [\"relu\", \"LeakyReLU\", \"linear\"]),\n",
        "              #'activation2': trial.suggest_categorical(\"activation2\", [\"relu\", \"LeakyReLU\", \"linear\"]),\n",
        "              #'layers1': trial.suggest_categorical(\"layers1\", [1,3]),\n",
        "              #'layers2': trial.suggest_categorical(\"layers2\", [1,3]),\n",
        "              'dropout_rate': trial.suggest_categorical(\"dropout_rate\", [0.0,0.3]),\n",
        "              'epochs': trial.suggest_categorical(\"epochs\", [100,150])\n",
        "              }\n",
        "    model = build_model(\n",
        "    input_shape,\n",
        "    head_size=params['head_size'],\n",
        "    num_heads=params['num_heads'],\n",
        "    ff_dim=params['ff_dim'],\n",
        "    num_transformer_blocks=params['num_transformer_bock'],\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.0,\n",
        "    dropout=0.0,\n",
        "    )\n",
        "\n",
        "    model.compile(optimizer=optimizers.Adam(lr=params['learning_rate'], decay=params['decay']), loss=losses.mean_squared_error)\n",
        "\n",
        "    model.fit(input_train, output_train, epochs=params['epochs'], verbose=1,\n",
        "            validation_data=(input_validation, output_validation)\n",
        "            )\n",
        "\n",
        "    y_pred = model.predict(input_test)\n",
        "    mse = mean_squared_error(output_test, y_pred)\n",
        "    mae = mean_absolute_error(output_test,y_pred)\n",
        "    mape = mean_absolute_percentage_error(output_test,y_pred)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/transformer_pk/{}.pickle\".format(trial.number), \"wb\") as fout:\n",
        "        pickle.dump(model, fout)\n",
        "    return mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRnLtwlDRcIV",
        "outputId": "8f7eb988-f7ba-4b60-c973-bfdba4b206a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-12 16:19:43,428]\u001b[0m A new study created in memory with name: no-name-acb2a962-e89b-4acf-abe8-699045e3fdf1\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [3, 4] and step=5, but the range is not divisible by `step`. It will be replaced by [3, 3].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=4, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 39s 4s/step - loss: 0.7628 - val_loss: 0.3128\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.2547 - val_loss: 0.1670\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.1961 - val_loss: 0.1456\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.1552 - val_loss: 0.1026\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.1198 - val_loss: 0.0950\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.1085 - val_loss: 0.0858\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0978 - val_loss: 0.0881\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0901 - val_loss: 0.0784\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0862 - val_loss: 0.0772\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0828 - val_loss: 0.0751\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0801 - val_loss: 0.0741\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0786 - val_loss: 0.0730\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0760 - val_loss: 0.0728\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0721 - val_loss: 0.0727\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 35s 4s/step - loss: 0.0704 - val_loss: 0.0723\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0712 - val_loss: 0.0748\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 35s 4s/step - loss: 0.0706 - val_loss: 0.0733\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0684 - val_loss: 0.0744\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0672 - val_loss: 0.0731\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0659 - val_loss: 0.0729\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0656 - val_loss: 0.0723\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 36s 4s/step - loss: 0.0651 - val_loss: 0.0722\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0637 - val_loss: 0.0718\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0608 - val_loss: 0.0736\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0618 - val_loss: 0.0739\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0613 - val_loss: 0.0736\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0613 - val_loss: 0.0736\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0586 - val_loss: 0.0745\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0579 - val_loss: 0.0734\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0570 - val_loss: 0.0727\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0557 - val_loss: 0.0745\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 34s 4s/step - loss: 0.0554 - val_loss: 0.0730\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0568 - val_loss: 0.0732\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0547 - val_loss: 0.0723\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0563 - val_loss: 0.0719\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0562 - val_loss: 0.0747\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0566 - val_loss: 0.0727\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0553 - val_loss: 0.0744\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0536 - val_loss: 0.0731\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0538 - val_loss: 0.0747\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0547 - val_loss: 0.0726\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0534 - val_loss: 0.0734\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0525 - val_loss: 0.0761\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0511 - val_loss: 0.0735\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0510 - val_loss: 0.0728\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0493 - val_loss: 0.0753\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0498 - val_loss: 0.0786\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0492 - val_loss: 0.0740\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0478 - val_loss: 0.0764\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0476 - val_loss: 0.0749\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0470 - val_loss: 0.0756\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0462 - val_loss: 0.0756\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0459 - val_loss: 0.0736\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0460 - val_loss: 0.0773\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0463 - val_loss: 0.0752\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0460 - val_loss: 0.0769\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0448 - val_loss: 0.0784\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0445 - val_loss: 0.0774\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0446 - val_loss: 0.0809\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0460 - val_loss: 0.0781\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0442 - val_loss: 0.0775\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0461 - val_loss: 0.0801\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0427 - val_loss: 0.0769\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0424 - val_loss: 0.0774\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0414 - val_loss: 0.0807\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0421 - val_loss: 0.0787\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0424 - val_loss: 0.0785\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0428 - val_loss: 0.0775\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0439 - val_loss: 0.0789\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0423 - val_loss: 0.0788\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0430 - val_loss: 0.0775\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0427 - val_loss: 0.0797\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0427 - val_loss: 0.0790\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0414 - val_loss: 0.0795\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0425 - val_loss: 0.0804\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0417 - val_loss: 0.0817\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0411 - val_loss: 0.0801\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0396 - val_loss: 0.0802\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0393 - val_loss: 0.0812\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0389 - val_loss: 0.0803\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0387 - val_loss: 0.0802\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0387 - val_loss: 0.0810\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0389 - val_loss: 0.0798\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0379 - val_loss: 0.0817\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0383 - val_loss: 0.0838\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0372 - val_loss: 0.0807\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0370 - val_loss: 0.0813\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0380 - val_loss: 0.0832\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0372 - val_loss: 0.0819\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0371 - val_loss: 0.0806\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0389 - val_loss: 0.0901\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0409 - val_loss: 0.0855\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0386 - val_loss: 0.0826\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0368 - val_loss: 0.0801\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0368 - val_loss: 0.0805\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0356 - val_loss: 0.0818\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0360 - val_loss: 0.0851\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0376 - val_loss: 0.0924\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0365 - val_loss: 0.0856\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0357 - val_loss: 0.0844\n",
            "2/2 [==============================] - 3s 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-12 17:14:34,491]\u001b[0m Trial 0 finished with value: 0.06646088942762529 and parameters: {'learning_rate': 5.8237632001036017e-05, 'head_size': 165, 'num_heads': 3, 'ff_dim': 2, 'num_transformer_bock': 4, 'decay': 1e-05, 'dropout_rate': 0.3, 'epochs': 100}. Best is trial 0 with value: 0.06646088942762529.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [3, 4] and step=5, but the range is not divisible by `step`. It will be replaced by [3, 3].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=4, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 33s 3s/step - loss: 0.4129 - val_loss: 0.1237\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0951 - val_loss: 0.0776\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0739 - val_loss: 0.0694\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0630 - val_loss: 0.0778\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0625 - val_loss: 0.0623\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0549 - val_loss: 0.0707\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0523 - val_loss: 0.0623\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0438 - val_loss: 0.0526\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0408 - val_loss: 0.0576\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0381 - val_loss: 0.0676\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0385 - val_loss: 0.0543\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0408 - val_loss: 0.0616\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0380 - val_loss: 0.0552\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0350 - val_loss: 0.0579\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0328 - val_loss: 0.0611\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0285 - val_loss: 0.0506\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0270 - val_loss: 0.0600\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0287 - val_loss: 0.0537\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0289 - val_loss: 0.0521\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0276 - val_loss: 0.0503\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0285 - val_loss: 0.0503\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0240 - val_loss: 0.0504\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0241 - val_loss: 0.0496\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0229 - val_loss: 0.0595\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0213 - val_loss: 0.0535\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0206 - val_loss: 0.0565\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0199 - val_loss: 0.0535\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0228 - val_loss: 0.0571\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0263 - val_loss: 0.0459\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0210 - val_loss: 0.0539\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0196 - val_loss: 0.0571\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0189 - val_loss: 0.0560\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0206 - val_loss: 0.0503\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0199 - val_loss: 0.0574\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0171 - val_loss: 0.0530\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0149 - val_loss: 0.0557\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0165 - val_loss: 0.0471\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0180 - val_loss: 0.0527\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0167 - val_loss: 0.0522\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0161 - val_loss: 0.0581\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0192 - val_loss: 0.0490\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0210 - val_loss: 0.0581\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0156 - val_loss: 0.0500\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0197 - val_loss: 0.0484\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0235 - val_loss: 0.0620\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0232 - val_loss: 0.0495\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0202 - val_loss: 0.0507\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0179 - val_loss: 0.0523\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0179 - val_loss: 0.0466\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0157 - val_loss: 0.0454\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0137 - val_loss: 0.0654\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0133 - val_loss: 0.0481\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0119 - val_loss: 0.0532\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0122 - val_loss: 0.0650\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0216 - val_loss: 0.0671\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0172 - val_loss: 0.0584\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0156 - val_loss: 0.0495\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0159 - val_loss: 0.0652\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0136 - val_loss: 0.0513\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0110 - val_loss: 0.0546\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0103 - val_loss: 0.0531\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0124 - val_loss: 0.0587\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0150 - val_loss: 0.0613\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0136 - val_loss: 0.0511\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0107 - val_loss: 0.0511\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0101 - val_loss: 0.0473\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0093 - val_loss: 0.0511\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0087 - val_loss: 0.0482\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0081 - val_loss: 0.0502\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0111 - val_loss: 0.0498\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0102 - val_loss: 0.0535\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0127 - val_loss: 0.0460\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0154 - val_loss: 0.0489\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0176 - val_loss: 0.0569\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0181 - val_loss: 0.0467\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0129 - val_loss: 0.0506\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0129 - val_loss: 0.0514\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0126 - val_loss: 0.0572\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0159 - val_loss: 0.0493\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0091 - val_loss: 0.0504\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0080 - val_loss: 0.0553\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0072 - val_loss: 0.0533\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0063 - val_loss: 0.0512\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0059 - val_loss: 0.0542\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0061 - val_loss: 0.0498\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0076 - val_loss: 0.0507\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0097 - val_loss: 0.0583\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0081 - val_loss: 0.0517\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0066 - val_loss: 0.0499\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0055 - val_loss: 0.0597\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0060 - val_loss: 0.0491\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0059 - val_loss: 0.0648\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0065 - val_loss: 0.0496\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0064 - val_loss: 0.0543\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0054 - val_loss: 0.0512\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0053 - val_loss: 0.0568\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0046 - val_loss: 0.0556\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0057 - val_loss: 0.0535\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0058 - val_loss: 0.0549\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0056 - val_loss: 0.0506\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0072 - val_loss: 0.0535\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0063 - val_loss: 0.0540\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0059 - val_loss: 0.0515\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0069 - val_loss: 0.0525\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0061 - val_loss: 0.0519\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0051 - val_loss: 0.0623\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0076 - val_loss: 0.0522\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0057 - val_loss: 0.0557\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0056 - val_loss: 0.0504\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0046 - val_loss: 0.0563\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0043 - val_loss: 0.0567\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0080 - val_loss: 0.0688\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0140 - val_loss: 0.0594\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0133 - val_loss: 0.0705\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0118 - val_loss: 0.0596\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0119 - val_loss: 0.0576\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0075 - val_loss: 0.0561\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0058 - val_loss: 0.0568\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0045 - val_loss: 0.0557\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0052 - val_loss: 0.0581\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0051 - val_loss: 0.0579\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0049 - val_loss: 0.0543\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0045 - val_loss: 0.0589\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0047 - val_loss: 0.0545\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0059 - val_loss: 0.0655\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0054 - val_loss: 0.0537\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0049 - val_loss: 0.0589\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0041 - val_loss: 0.0563\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0034 - val_loss: 0.0556\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0030 - val_loss: 0.0554\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0039 - val_loss: 0.0556\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0031 - val_loss: 0.0573\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0031 - val_loss: 0.0551\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0032 - val_loss: 0.0578\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0029 - val_loss: 0.0596\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0030 - val_loss: 0.0591\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0028 - val_loss: 0.0589\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0031 - val_loss: 0.0567\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0028 - val_loss: 0.0550\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0032 - val_loss: 0.0588\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0035 - val_loss: 0.0583\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0039 - val_loss: 0.0602\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0029 - val_loss: 0.0557\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0030 - val_loss: 0.0574\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0037 - val_loss: 0.0580\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0062 - val_loss: 0.0629\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0063 - val_loss: 0.0602\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0057 - val_loss: 0.0585\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 29s 3s/step - loss: 0.0064 - val_loss: 0.0585\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 30s 3s/step - loss: 0.0053 - val_loss: 0.0620\n",
            "2/2 [==============================] - 3s 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-12 18:28:19,150]\u001b[0m Trial 1 finished with value: 0.04537991875378236 and parameters: {'learning_rate': 0.0005877553634564128, 'head_size': 136, 'num_heads': 3, 'ff_dim': 2, 'num_transformer_bock': 4, 'decay': 1e-05, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 1 with value: 0.04537991875378236.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [3, 4] and step=5, but the range is not divisible by `step`. It will be replaced by [3, 3].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=4, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 29s 3s/step - loss: 0.3449 - val_loss: 0.1444\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.1276 - val_loss: 0.0832\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.1156 - val_loss: 0.1014\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0838 - val_loss: 0.0753\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0799 - val_loss: 0.0786\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0728 - val_loss: 0.0681\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0673 - val_loss: 0.0676\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0657 - val_loss: 0.0682\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0621 - val_loss: 0.0671\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0610 - val_loss: 0.0778\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0609 - val_loss: 0.0668\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0576 - val_loss: 0.0677\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0572 - val_loss: 0.0654\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0587 - val_loss: 0.0695\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0559 - val_loss: 0.0782\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0574 - val_loss: 0.0716\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0529 - val_loss: 0.0786\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0503 - val_loss: 0.0656\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0486 - val_loss: 0.0712\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0455 - val_loss: 0.0778\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0422 - val_loss: 0.0639\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0380 - val_loss: 0.0658\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0362 - val_loss: 0.0664\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0348 - val_loss: 0.0598\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0330 - val_loss: 0.0677\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0306 - val_loss: 0.0571\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 26s 3s/step - loss: 0.0308 - val_loss: 0.0580\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0300 - val_loss: 0.0591\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0288 - val_loss: 0.0592\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0293 - val_loss: 0.0698\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0300 - val_loss: 0.0536\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0284 - val_loss: 0.0558\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0253 - val_loss: 0.0517\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0251 - val_loss: 0.0519\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0278 - val_loss: 0.0663\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0245 - val_loss: 0.0573\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0225 - val_loss: 0.0525\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0253 - val_loss: 0.0548\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0230 - val_loss: 0.0650\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0215 - val_loss: 0.0567\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0212 - val_loss: 0.0544\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0201 - val_loss: 0.0529\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0204 - val_loss: 0.0613\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0223 - val_loss: 0.0543\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0261 - val_loss: 0.0744\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0252 - val_loss: 0.0607\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0241 - val_loss: 0.0532\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0220 - val_loss: 0.0540\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0185 - val_loss: 0.0547\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0179 - val_loss: 0.0526\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0180 - val_loss: 0.0585\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0171 - val_loss: 0.0584\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0165 - val_loss: 0.0527\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0200 - val_loss: 0.0603\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0241 - val_loss: 0.0756\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0202 - val_loss: 0.0641\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0188 - val_loss: 0.0571\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0166 - val_loss: 0.0543\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0183 - val_loss: 0.0606\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0195 - val_loss: 0.0729\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0175 - val_loss: 0.0540\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0189 - val_loss: 0.0546\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 26s 3s/step - loss: 0.0174 - val_loss: 0.0539\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 26s 3s/step - loss: 0.0164 - val_loss: 0.0674\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0171 - val_loss: 0.0619\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0145 - val_loss: 0.0605\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0142 - val_loss: 0.0590\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0140 - val_loss: 0.0596\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0138 - val_loss: 0.0594\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0146 - val_loss: 0.0637\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0155 - val_loss: 0.0624\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0141 - val_loss: 0.0580\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0151 - val_loss: 0.0566\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0153 - val_loss: 0.0605\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0131 - val_loss: 0.0605\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0128 - val_loss: 0.0617\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0131 - val_loss: 0.0588\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0130 - val_loss: 0.0640\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0129 - val_loss: 0.0604\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0119 - val_loss: 0.0617\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0119 - val_loss: 0.0639\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0120 - val_loss: 0.0613\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0121 - val_loss: 0.0671\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0131 - val_loss: 0.0644\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0117 - val_loss: 0.0613\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0114 - val_loss: 0.0619\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0122 - val_loss: 0.0618\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0125 - val_loss: 0.0600\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0123 - val_loss: 0.0639\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0117 - val_loss: 0.0690\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0115 - val_loss: 0.0632\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0109 - val_loss: 0.0649\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0106 - val_loss: 0.0643\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0103 - val_loss: 0.0624\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0108 - val_loss: 0.0674\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0115 - val_loss: 0.0667\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0102 - val_loss: 0.0657\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0107 - val_loss: 0.0612\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0130 - val_loss: 0.0618\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 26s 3s/step - loss: 0.0103 - val_loss: 0.0622\n",
            "2/2 [==============================] - 3s 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 42). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-12 19:09:47,687]\u001b[0m Trial 2 finished with value: 0.047631483235427624 and parameters: {'learning_rate': 0.0007617095272576973, 'head_size': 177, 'num_heads': 3, 'ff_dim': 2, 'num_transformer_bock': 3, 'decay': 0.001, 'dropout_rate': 0.3, 'epochs': 100}. Best is trial 1 with value: 0.04537991875378236.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [3, 4] and step=5, but the range is not divisible by `step`. It will be replaced by [3, 3].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=4, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 28s 3s/step - loss: 0.3499 - val_loss: 0.1979\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.1738 - val_loss: 0.1939\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.1337 - val_loss: 0.1166\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0962 - val_loss: 0.0868\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0802 - val_loss: 0.0774\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0742 - val_loss: 0.0727\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0699 - val_loss: 0.0712\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0667 - val_loss: 0.0704\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0642 - val_loss: 0.0715\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0627 - val_loss: 0.0704\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0620 - val_loss: 0.0724\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0593 - val_loss: 0.0752\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 23s 3s/step - loss: 0.0595 - val_loss: 0.0677\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0568 - val_loss: 0.0682\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0545 - val_loss: 0.0746\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0549 - val_loss: 0.0715\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0565 - val_loss: 0.0757\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 23s 3s/step - loss: 0.0536 - val_loss: 0.0688\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0498 - val_loss: 0.0702\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0489 - val_loss: 0.0702\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0477 - val_loss: 0.0689\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0469 - val_loss: 0.0706\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0461 - val_loss: 0.0685\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0448 - val_loss: 0.0694\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0439 - val_loss: 0.0700\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0425 - val_loss: 0.0668\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0430 - val_loss: 0.0722\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0407 - val_loss: 0.0677\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0409 - val_loss: 0.0695\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0402 - val_loss: 0.0708\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0390 - val_loss: 0.0681\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0381 - val_loss: 0.0674\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0392 - val_loss: 0.0719\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0365 - val_loss: 0.0679\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0362 - val_loss: 0.0729\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0359 - val_loss: 0.0750\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0365 - val_loss: 0.0703\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0345 - val_loss: 0.0727\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0333 - val_loss: 0.0723\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0333 - val_loss: 0.0735\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0318 - val_loss: 0.0731\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0322 - val_loss: 0.0712\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0315 - val_loss: 0.0747\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0309 - val_loss: 0.0734\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0324 - val_loss: 0.0718\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0299 - val_loss: 0.0741\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0298 - val_loss: 0.0842\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0289 - val_loss: 0.0757\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0275 - val_loss: 0.0794\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0269 - val_loss: 0.0756\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0260 - val_loss: 0.0802\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0263 - val_loss: 0.0844\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0266 - val_loss: 0.0810\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0256 - val_loss: 0.0791\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0256 - val_loss: 0.0821\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0237 - val_loss: 0.0793\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0225 - val_loss: 0.0823\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0224 - val_loss: 0.0803\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0235 - val_loss: 0.0807\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0220 - val_loss: 0.0836\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0217 - val_loss: 0.0796\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0226 - val_loss: 0.0801\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0226 - val_loss: 0.0811\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0205 - val_loss: 0.0808\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0202 - val_loss: 0.0840\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0206 - val_loss: 0.0856\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0203 - val_loss: 0.0845\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0206 - val_loss: 0.0839\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0236 - val_loss: 0.0835\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0201 - val_loss: 0.0842\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0205 - val_loss: 0.0851\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0191 - val_loss: 0.0788\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0191 - val_loss: 0.0880\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0186 - val_loss: 0.0856\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0180 - val_loss: 0.0837\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0169 - val_loss: 0.0846\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0171 - val_loss: 0.0854\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0171 - val_loss: 0.0857\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0163 - val_loss: 0.0878\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0163 - val_loss: 0.0878\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0157 - val_loss: 0.0864\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0152 - val_loss: 0.0821\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0146 - val_loss: 0.0848\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0148 - val_loss: 0.0839\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0157 - val_loss: 0.0898\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0153 - val_loss: 0.0901\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0152 - val_loss: 0.0841\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 23s 3s/step - loss: 0.0157 - val_loss: 0.0920\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0180 - val_loss: 0.0874\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0152 - val_loss: 0.0842\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0145 - val_loss: 0.0928\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0135 - val_loss: 0.0811\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0128 - val_loss: 0.0902\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0133 - val_loss: 0.0876\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0125 - val_loss: 0.0848\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0119 - val_loss: 0.0876\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0116 - val_loss: 0.0871\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0123 - val_loss: 0.0862\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0113 - val_loss: 0.0880\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.0114 - val_loss: 0.0895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa32ac11b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 2s 972ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 42). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-12 19:49:54,347]\u001b[0m Trial 3 finished with value: 0.09947140780609742 and parameters: {'learning_rate': 0.00017615740756929225, 'head_size': 166, 'num_heads': 3, 'ff_dim': 2, 'num_transformer_bock': 3, 'decay': 1e-05, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 1 with value: 0.04537991875378236.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [3, 4] and step=5, but the range is not divisible by `step`. It will be replaced by [3, 3].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=4, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 36s 4s/step - loss: 0.4508 - val_loss: 0.1514\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.1185 - val_loss: 0.0916\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0851 - val_loss: 0.0805\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0770 - val_loss: 0.0737\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0671 - val_loss: 0.0677\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0631 - val_loss: 0.0706\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0611 - val_loss: 0.0665\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0598 - val_loss: 0.0660\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0577 - val_loss: 0.0725\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0583 - val_loss: 0.0656\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0561 - val_loss: 0.0667\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0561 - val_loss: 0.0721\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0545 - val_loss: 0.0675\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0521 - val_loss: 0.0698\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0512 - val_loss: 0.0656\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0516 - val_loss: 0.0658\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0546 - val_loss: 0.0887\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0558 - val_loss: 0.0695\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0486 - val_loss: 0.0705\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0451 - val_loss: 0.0628\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0417 - val_loss: 0.0617\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0406 - val_loss: 0.0640\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0411 - val_loss: 0.0603\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0374 - val_loss: 0.0617\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0378 - val_loss: 0.0633\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0362 - val_loss: 0.0596\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0365 - val_loss: 0.0614\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0342 - val_loss: 0.0602\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0348 - val_loss: 0.0604\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0333 - val_loss: 0.0661\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0350 - val_loss: 0.0602\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0324 - val_loss: 0.0614\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0319 - val_loss: 0.0661\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0360 - val_loss: 0.0574\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0315 - val_loss: 0.0620\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0300 - val_loss: 0.0600\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0288 - val_loss: 0.0597\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0280 - val_loss: 0.0586\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0283 - val_loss: 0.0563\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0275 - val_loss: 0.0650\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0308 - val_loss: 0.0595\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0282 - val_loss: 0.0586\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0266 - val_loss: 0.0572\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0295 - val_loss: 0.0768\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0313 - val_loss: 0.0601\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0287 - val_loss: 0.0593\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0252 - val_loss: 0.0563\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0239 - val_loss: 0.0601\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0250 - val_loss: 0.0651\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0263 - val_loss: 0.0658\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0230 - val_loss: 0.0574\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0245 - val_loss: 0.0632\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0228 - val_loss: 0.0573\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0227 - val_loss: 0.0721\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0266 - val_loss: 0.0551\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0242 - val_loss: 0.0562\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0201 - val_loss: 0.0569\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0201 - val_loss: 0.0562\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0198 - val_loss: 0.0615\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0217 - val_loss: 0.0548\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0230 - val_loss: 0.0550\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0207 - val_loss: 0.0613\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0201 - val_loss: 0.0579\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0198 - val_loss: 0.0625\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0207 - val_loss: 0.0561\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0185 - val_loss: 0.0598\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0178 - val_loss: 0.0580\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0177 - val_loss: 0.0578\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0167 - val_loss: 0.0607\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0177 - val_loss: 0.0584\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0170 - val_loss: 0.0577\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0178 - val_loss: 0.0589\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0169 - val_loss: 0.0580\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0189 - val_loss: 0.0612\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0201 - val_loss: 0.0565\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0186 - val_loss: 0.0571\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0188 - val_loss: 0.0594\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0192 - val_loss: 0.0662\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0191 - val_loss: 0.0579\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0157 - val_loss: 0.0624\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0152 - val_loss: 0.0585\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0148 - val_loss: 0.0591\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0163 - val_loss: 0.0616\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0158 - val_loss: 0.0585\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0154 - val_loss: 0.0585\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0161 - val_loss: 0.0584\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0192 - val_loss: 0.0582\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0176 - val_loss: 0.0592\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0162 - val_loss: 0.0681\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0152 - val_loss: 0.0594\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0146 - val_loss: 0.0596\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0152 - val_loss: 0.0637\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0137 - val_loss: 0.0601\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 33s 4s/step - loss: 0.0165 - val_loss: 0.0622\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0128 - val_loss: 0.0622\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0135 - val_loss: 0.0656\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0124 - val_loss: 0.0677\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0148 - val_loss: 0.0686\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0202 - val_loss: 0.0596\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0146 - val_loss: 0.0596\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0129 - val_loss: 0.0586\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0127 - val_loss: 0.0684\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0132 - val_loss: 0.0620\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0132 - val_loss: 0.0595\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0138 - val_loss: 0.0602\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0120 - val_loss: 0.0672\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0118 - val_loss: 0.0622\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0114 - val_loss: 0.0622\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0120 - val_loss: 0.0702\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0125 - val_loss: 0.0596\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0114 - val_loss: 0.0624\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0114 - val_loss: 0.0638\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0108 - val_loss: 0.0628\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0110 - val_loss: 0.0626\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0109 - val_loss: 0.0622\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0115 - val_loss: 0.0636\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0109 - val_loss: 0.0636\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0109 - val_loss: 0.0641\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0105 - val_loss: 0.0613\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0110 - val_loss: 0.0756\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0123 - val_loss: 0.0610\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0157 - val_loss: 0.0884\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0147 - val_loss: 0.0617\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0136 - val_loss: 0.0691\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0117 - val_loss: 0.0673\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0114 - val_loss: 0.0630\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0107 - val_loss: 0.0622\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0102 - val_loss: 0.0741\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0137 - val_loss: 0.0616\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0102 - val_loss: 0.0632\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0099 - val_loss: 0.0630\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0095 - val_loss: 0.0678\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0115 - val_loss: 0.0613\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0105 - val_loss: 0.0667\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0106 - val_loss: 0.0622\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0139 - val_loss: 0.0902\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0169 - val_loss: 0.0621\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0155 - val_loss: 0.0660\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0106 - val_loss: 0.0640\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0103 - val_loss: 0.0659\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0100 - val_loss: 0.0652\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0098 - val_loss: 0.0660\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0093 - val_loss: 0.0675\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0114 - val_loss: 0.0636\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0097 - val_loss: 0.0659\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 31s 3s/step - loss: 0.0102 - val_loss: 0.0641\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0094 - val_loss: 0.0642\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 32s 4s/step - loss: 0.0119 - val_loss: 0.0637\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0103 - val_loss: 0.0697\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 31s 4s/step - loss: 0.0091 - val_loss: 0.0659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa32ad03440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 3s 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-12 21:09:20,543]\u001b[0m Trial 4 finished with value: 0.07744068904884176 and parameters: {'learning_rate': 0.0008507997862573048, 'head_size': 162, 'num_heads': 3, 'ff_dim': 2, 'num_transformer_bock': 4, 'decay': 0.001, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 1 with value: 0.04537991875378236.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "reset_random_seeds()\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=21))\n",
        "study.optimize(objective, n_trials=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4SIbTIjBSAq6",
        "outputId": "d441a2d7-8fa7-4e47-f580-27d757343c6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.04537991875378236\n",
            "Best hyperparameters: {'learning_rate': 0.0005877553634564128, 'head_size': 136, 'num_heads': 3, 'ff_dim': 2, 'num_transformer_bock': 4, 'decay': 1e-05, 'dropout_rate': 0.3, 'epochs': 150}\n",
            "2/2 [==============================] - 3s 1s/step\n",
            "0.04537991875378236\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "trial = study.best_trial\n",
        "print('MSE: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))\n",
        "with open(\"/content/drive/MyDrive/transformer_pk/{}.pickle\".format(study.best_trial.number), \"rb\") as fin:\n",
        "    best_tcn = pickle.load(fin)\n",
        "model = best_tcn\n",
        "y_pred = model.predict(input_test)\n",
        "mse = mean_squared_error(output_test, y_pred)\n",
        "print(mse)\n",
        "print(study.best_trial.number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvQAYJGuHCw5"
      },
      "outputs": [],
      "source": [
        "train_pred = model.predict(input_train)\n",
        "train_nrmse = np.sqrt(np.sum((output_train - train_pred)**2))/np.sqrt(np.sum((output_train - np.average(output_train))**2))\n",
        "print(train_nrmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LVOJvcp0owQ7",
        "outputId": "7111ee94-ffde-4940-ea1f-b476db90d533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 3s 1s/step\n",
            "1.0030792546121376\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(input_validation)\n",
        "nrmse = np.sqrt(np.sum((output_validation - y_pred)**2))/np.sqrt(np.sum((output_validation - np.average(output_validation))**2))\n",
        "print(nrmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiWy-yKTo1zD"
      },
      "outputs": [],
      "source": [
        "plt.scatter(output_validation[:, 0], y_pred[:, 0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}