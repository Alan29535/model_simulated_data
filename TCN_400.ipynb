{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVR-eWcO8FMi",
        "outputId": "d5749967-3a4c-4a64-8921-c6f6d663eded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO1NbsnZ8IBr",
        "outputId": "15c0226e-8df2-4c11-ac96-cd9ba350b85f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (1.11.1)\n"
          ]
        }
      ],
      "source": [
        "pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42RyC0GJ8JXK",
        "outputId": "f6de9b88-84f9-45af-d40b-d3da35933352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (2.7.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.5)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.13.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.2)\n",
            "Requirement already satisfied: torch<1.14,>=1.7 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.12.1+cu113)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.0.7)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (21.1.3)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.5.27)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.7.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (3.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.6.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.64.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.10.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (8.1.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.10)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4->fastai) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4->fastai) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4->fastai) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2022.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install -U fastai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm0WHvzO8K37",
        "outputId": "4e41d7b5-59eb-46fd-d777-0ac2a9226ebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (3.0.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.11.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.2)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.2)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScEOvZBa8Mg5",
        "outputId": "ceb6ae19-b1d6-443f-df90-6cbcb273457c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-tcn in /usr/local/lib/python3.7/dist-packages (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (0.18.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (2.9.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.27.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.9.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.9.1)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.50.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (4.1.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (21.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (14.0.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-tcn) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (2.14.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (3.4.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow->keras-tcn) (3.0.9)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->keras-tcn) (2.7.1)\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tcn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hR_r3Ld8PRl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(1)\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from tensorflow.keras.layers import BatchNormalization,Dropout\n",
        "from tensorflow.keras import models, layers, losses, optimizers, activations, regularizers\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAz8UFsF8UIa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tcn import TCN\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWErcPbg8V-5"
      },
      "outputs": [],
      "source": [
        "from optuna.visualization import plot_contour\n",
        "from optuna.visualization import plot_edf\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_slice\n",
        "import joblib\n",
        "import pickle\n",
        "from keras.engine.input_spec import InputSpec\n",
        "initializer = tf.keras.initializers.Zeros()\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlsAn1Hz8ZNP"
      },
      "outputs": [],
      "source": [
        "def reset_random_seeds():\n",
        "   os.environ['PYTHONHASHSEED']=str(1)\n",
        "   tf.random.set_seed(1)\n",
        "   np.random.seed(1)\n",
        "   random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLf8O2W28ckA"
      },
      "outputs": [],
      "source": [
        "flow = np.load('/content/drive/MyDrive/CNN model data/lung_data/flow400.npy')\n",
        "volume = np.load('/content/drive/MyDrive/CNN model data/lung_data/volume400.npy')\n",
        "paw = np.load('/content/drive/MyDrive/CNN model data/lung_data/paw400.npy')\n",
        "capacitances = np.load('/content/drive/MyDrive/CNN model data/lung_data/capacitances400.npy')\n",
        "resistances = np.load(\"/content/drive/MyDrive/CNN model data/lung_data/rins400.npy\")\n",
        "#output1 = np.load(\"/content/drive/MyDrive/CNN model data/output1.npy\")\n",
        "#input1 = np.load(\"/content/drive/MyDrive/CNN model data/input1.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P062EhPU8dJJ"
      },
      "outputs": [],
      "source": [
        "def normalize_data(data, minimum = None,maximum = None):\n",
        "    if minimum is None:\n",
        "        minimum = np.min(np.min(data))\n",
        "    if maximum is None:\n",
        "        maximum = np.max(np.max(data))\n",
        "    data_norm = (data - minimum) / (maximum - minimum)\n",
        "    return minimum, maximum, data_norm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nnmswXj8fs5",
        "outputId": "69f03b4e-7e79-46a1-efcc-f1835d8070e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transposed\n",
            "num_samples are 400\n",
            "normalized data\n",
            "input created\n"
          ]
        }
      ],
      "source": [
        "flow = flow.T\n",
        "volume = volume.T\n",
        "paw = paw.T\n",
        "resistances = resistances.T\n",
        "capacitances = capacitances.T\n",
        "\n",
        "print(\"transposed\")\n",
        "\n",
        "num_examples = flow.shape[0]\n",
        "num_samples = flow.shape[1]\n",
        "print(\"num_samples are\",num_examples)\n",
        "(min_flow, max_flow, flow) = normalize_data(flow)\n",
        "(min_volume, max_volume, volume) = normalize_data(volume)\n",
        "(min_paw, max_paw, paw) = normalize_data(paw)\n",
        "(min_resistance, max_resistance, resistances) = normalize_data(resistances)\n",
        "(min_capacitance, max_capacitance, capacitances) = normalize_data(capacitances)\n",
        "\n",
        "print(\"normalized data\")\n",
        "\n",
        "input_data = np.zeros((num_examples, num_samples, 3))\n",
        "input_data[:, :, 0] = flow\n",
        "input_data[:, :, 1] = volume\n",
        "input_data[:, :, 2] = paw\n",
        "output_data = np.concatenate((resistances, capacitances), axis=1)\n",
        "indices = np.arange(num_examples)\n",
        "\n",
        "print(\"input created\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRmgmMW58gQr"
      },
      "outputs": [],
      "source": [
        "input_train, input_test, output_train, output_test, indices_train, indices_test = \\\n",
        "    train_test_split(input_data, output_data, indices, test_size=0.3, shuffle=False, random_state=11)\n",
        "\n",
        "input_validation, input_test, output_validation, output_test, indices_validation, indices_test = \\\n",
        "    train_test_split(input_test, output_test, indices_test, test_size=0.5, shuffle=False, random_state=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGyrqYH98jON"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    reset_random_seeds()\n",
        "    params = {\n",
        "              'learning_rate': trial.suggest_uniform('learning_rate', 1e-5, 1e-3),\n",
        "              'nb_filter': trial.suggest_categorical(\"nb_filter\", [2, 3]),\n",
        "              'kernel_size': trial.suggest_int(\"kernel_size\",2, 3, 5),\n",
        "              'nb_stacks': trial.suggest_int(\"nb_stacks\",1,2,3),\n",
        "              'decay': trial.suggest_categorical(\"decay\",[1e-3, 1e-5]),\n",
        "              'dense1': trial.suggest_int('dense1',50,100,150),\n",
        "              'dense2': trial.suggest_int('dense2',50,100,150),\n",
        "              #'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
        "              'activation1': trial.suggest_categorical(\"activation1\", [\"relu\", \"LeakyReLU\", \"linear\"]),\n",
        "              'activation2': trial.suggest_categorical(\"activation2\", [\"relu\", \"LeakyReLU\", \"linear\"]),\n",
        "              'layers1': trial.suggest_categorical(\"layers1\", [1,3]),\n",
        "              'layers2': trial.suggest_categorical(\"layers2\", [1,3]),\n",
        "              'dropout_rate': trial.suggest_categorical(\"dropout_rate\", [0.0,0.3]),\n",
        "              'epochs': trial.suggest_categorical(\"epochs\", [100,150])\n",
        "              }\n",
        "    model = Sequential()\n",
        "    model.add(TCN(\n",
        "      input_shape=(num_samples,3),\n",
        "      nb_filters=params['nb_filter'],\n",
        "      kernel_size=params['kernel_size'],\n",
        "      nb_stacks=params['nb_stacks'],\n",
        "      dilations=(1, 2, 4, 8),\n",
        "      padding='causal',\n",
        "      use_skip_connections=True,\n",
        "      dropout_rate=0.05,\n",
        "      return_sequences=False,\n",
        "      activation='relu',\n",
        "      kernel_initializer='he_normal',\n",
        "      use_batch_norm=False,\n",
        "      use_layer_norm=False,\n",
        "      use_weight_norm=False,\n",
        "      go_backwards=False,\n",
        "      return_state=False,\n",
        "    ))  \n",
        "\n",
        "    #model.add(Flatten())\n",
        "    for i in range(params['layers1']):\n",
        "      model.add(Dense(params['dense1'], activation=params['activation1']))\n",
        "    #if Dropout> 0.5:\n",
        "      #model.add(Dropout(params['dropout_rate'])) \n",
        "    for i in range(params['layers2']):\n",
        "      model.add(Dense(params['dense2'], activation=params['activation2']))\n",
        "    model.add(Dense(2))\n",
        "    model.compile(optimizer=optimizers.Adam(lr=params['learning_rate'], decay=params['decay']), loss=losses.mean_squared_error)\n",
        "\n",
        "    history = model.fit(input_train, output_train, epochs=params['epochs'], verbose=1,\n",
        "            validation_data=(input_validation, output_validation)\n",
        "            )#callbacks=[es_callback]\n",
        "#epochs=params['epochs']\n",
        "    y_pred = model.predict(input_test)\n",
        "    mse = mean_squared_error(output_test, y_pred)\n",
        "    mae = mean_absolute_error(output_test,y_pred)\n",
        "    mape = mean_absolute_percentage_error(output_test,y_pred)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/TCN_400/{}.pickle\".format(trial.number), \"wb\") as fout:\n",
        "        pickle.dump(model, fout)\n",
        "    return mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEMLKQ9S8sfA",
        "outputId": "25d2627e-df06-4698-c901-9a7a650d8fdc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-14 14:50:45,935]\u001b[0m A new study created in memory with name: no-name-0bef1ab3-30df-4f94-9f05-25c8910d1e6f\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "9/9 [==============================] - 3s 163ms/step - loss: 0.1143 - val_loss: 0.0815\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0967 - val_loss: 0.0729\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0917 - val_loss: 0.0707\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0909 - val_loss: 0.0694\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0876 - val_loss: 0.0680\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0863 - val_loss: 0.0670\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0836 - val_loss: 0.0670\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0871 - val_loss: 0.0669\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0857 - val_loss: 0.0662\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 148ms/step - loss: 0.0823 - val_loss: 0.0656\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0823 - val_loss: 0.0655\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0784 - val_loss: 0.0654\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0815 - val_loss: 0.0648\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0812 - val_loss: 0.0643\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0846 - val_loss: 0.0643\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0830 - val_loss: 0.0647\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0779 - val_loss: 0.0641\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0794 - val_loss: 0.0640\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0812 - val_loss: 0.0636\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0816 - val_loss: 0.0637\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0775 - val_loss: 0.0632\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0804 - val_loss: 0.0628\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0772 - val_loss: 0.0631\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0768 - val_loss: 0.0630\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0772 - val_loss: 0.0624\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0790 - val_loss: 0.0627\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0795 - val_loss: 0.0630\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0766 - val_loss: 0.0630\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0765 - val_loss: 0.0625\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0758 - val_loss: 0.0622\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0764 - val_loss: 0.0623\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0749 - val_loss: 0.0625\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0760 - val_loss: 0.0621\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 145ms/step - loss: 0.0764 - val_loss: 0.0622\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0767 - val_loss: 0.0624\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0751 - val_loss: 0.0620\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0762 - val_loss: 0.0619\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0764 - val_loss: 0.0620\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0726 - val_loss: 0.0619\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0758 - val_loss: 0.0619\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0752 - val_loss: 0.0617\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0755 - val_loss: 0.0614\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0743 - val_loss: 0.0614\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0752 - val_loss: 0.0610\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0747 - val_loss: 0.0614\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0723 - val_loss: 0.0614\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0710 - val_loss: 0.0614\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0759 - val_loss: 0.0614\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0749 - val_loss: 0.0613\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0722 - val_loss: 0.0612\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0736 - val_loss: 0.0608\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0735 - val_loss: 0.0608\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0720 - val_loss: 0.0614\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0746 - val_loss: 0.0611\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0740 - val_loss: 0.0606\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0711 - val_loss: 0.0607\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0708 - val_loss: 0.0608\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0736 - val_loss: 0.0610\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0732 - val_loss: 0.0611\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0723 - val_loss: 0.0608\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0715 - val_loss: 0.0606\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0716 - val_loss: 0.0605\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0715 - val_loss: 0.0605\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0687 - val_loss: 0.0605\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0713 - val_loss: 0.0605\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0706 - val_loss: 0.0605\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0723 - val_loss: 0.0603\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0694 - val_loss: 0.0612\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0725 - val_loss: 0.0611\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0715 - val_loss: 0.0604\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0697 - val_loss: 0.0600\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0706 - val_loss: 0.0602\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0689 - val_loss: 0.0603\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0741 - val_loss: 0.0601\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0697 - val_loss: 0.0602\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0700 - val_loss: 0.0600\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0698 - val_loss: 0.0604\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0708 - val_loss: 0.0601\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0704 - val_loss: 0.0600\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0711 - val_loss: 0.0599\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0728 - val_loss: 0.0601\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0680 - val_loss: 0.0599\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0719 - val_loss: 0.0600\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0695 - val_loss: 0.0598\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0700 - val_loss: 0.0598\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0692 - val_loss: 0.0601\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0689 - val_loss: 0.0599\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0680 - val_loss: 0.0598\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0694 - val_loss: 0.0600\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0697 - val_loss: 0.0600\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0695 - val_loss: 0.0594\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0701 - val_loss: 0.0595\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0672 - val_loss: 0.0597\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0699 - val_loss: 0.0594\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0688 - val_loss: 0.0592\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0691 - val_loss: 0.0593\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0667 - val_loss: 0.0598\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0696 - val_loss: 0.0595\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0686 - val_loss: 0.0596\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0678 - val_loss: 0.0593\n",
            "2/2 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 14:52:49,129]\u001b[0m Trial 0 finished with value: 0.061310371235159956 and parameters: {'learning_rate': 5.8237632001036017e-05, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'LeakyReLU', 'layers1': 1, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 0 with value: 0.061310371235159956.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 134ms/step - loss: 0.0998 - val_loss: 0.0673\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0884 - val_loss: 0.0671\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0872 - val_loss: 0.0680\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0849 - val_loss: 0.0647\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0812 - val_loss: 0.0641\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0786 - val_loss: 0.0632\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0779 - val_loss: 0.0633\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0785 - val_loss: 0.0625\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0772 - val_loss: 0.0609\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0754 - val_loss: 0.0620\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0758 - val_loss: 0.0617\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0750 - val_loss: 0.0610\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0734 - val_loss: 0.0608\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0727 - val_loss: 0.0606\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0753 - val_loss: 0.0616\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0760 - val_loss: 0.0619\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0714 - val_loss: 0.0600\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0708 - val_loss: 0.0621\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0707 - val_loss: 0.0595\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0700 - val_loss: 0.0595\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0680 - val_loss: 0.0594\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0708 - val_loss: 0.0597\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0683 - val_loss: 0.0590\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0677 - val_loss: 0.0591\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0670 - val_loss: 0.0587\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0681 - val_loss: 0.0594\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0675 - val_loss: 0.0584\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0674 - val_loss: 0.0587\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0670 - val_loss: 0.0593\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0673 - val_loss: 0.0583\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0681 - val_loss: 0.0602\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0679 - val_loss: 0.0605\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0672 - val_loss: 0.0579\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0706 - val_loss: 0.0617\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0656 - val_loss: 0.0577\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0665 - val_loss: 0.0584\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0662 - val_loss: 0.0633\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0660 - val_loss: 0.0573\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0642 - val_loss: 0.0586\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0580\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0662 - val_loss: 0.0587\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0671 - val_loss: 0.0589\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0648 - val_loss: 0.0573\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0656 - val_loss: 0.0590\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0690 - val_loss: 0.0582\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0573\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0623 - val_loss: 0.0601\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0676 - val_loss: 0.0592\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0674 - val_loss: 0.0584\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0657 - val_loss: 0.0595\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0643 - val_loss: 0.0571\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0598\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0662 - val_loss: 0.0572\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0662 - val_loss: 0.0581\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0658 - val_loss: 0.0595\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0568\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0653 - val_loss: 0.0587\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0634 - val_loss: 0.0585\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0584\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0584\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0574\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0581\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0602 - val_loss: 0.0566\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0624 - val_loss: 0.0601\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0641 - val_loss: 0.0569\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0619 - val_loss: 0.0615\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0574\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0575\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0634 - val_loss: 0.0580\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0583\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0633 - val_loss: 0.0581\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0642 - val_loss: 0.0589\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0624 - val_loss: 0.0577\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0627 - val_loss: 0.0574\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0589\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0562\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0632 - val_loss: 0.0590\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0568\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0659 - val_loss: 0.0581\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0619 - val_loss: 0.0559\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0664 - val_loss: 0.0577\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0632 - val_loss: 0.0559\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0645 - val_loss: 0.0583\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0553\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0592\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0639 - val_loss: 0.0573\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0639 - val_loss: 0.0578\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0571\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0581\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0565\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0571\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0642 - val_loss: 0.0581\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0570\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0572\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0641 - val_loss: 0.0565\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0589\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0566\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 76). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 14:54:21,350]\u001b[0m Trial 1 finished with value: 0.06367555398126995 and parameters: {'learning_rate': 0.00039040753176922816, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 0 with value: 0.061310371235159956.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 143ms/step - loss: 0.1622 - val_loss: 0.0954\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1158 - val_loss: 0.0781\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1076 - val_loss: 0.0759\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0972 - val_loss: 0.0717\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0921 - val_loss: 0.0702\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0845 - val_loss: 0.0675\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0821 - val_loss: 0.0652\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0784 - val_loss: 0.0633\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0757 - val_loss: 0.0630\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0721 - val_loss: 0.0618\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0720 - val_loss: 0.0615\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0714 - val_loss: 0.0605\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0698 - val_loss: 0.0604\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0685 - val_loss: 0.0599\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0680 - val_loss: 0.0591\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0683 - val_loss: 0.0600\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0665 - val_loss: 0.0590\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0660 - val_loss: 0.0596\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0648 - val_loss: 0.0597\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0661 - val_loss: 0.0592\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0597\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0597\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0603\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0601\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0596\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0648 - val_loss: 0.0599\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0652 - val_loss: 0.0596\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0655 - val_loss: 0.0596\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0599\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0649 - val_loss: 0.0596\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0645 - val_loss: 0.0596\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0645 - val_loss: 0.0611\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0599\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0618 - val_loss: 0.0599\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0636 - val_loss: 0.0602\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0611\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0640 - val_loss: 0.0599\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0640 - val_loss: 0.0599\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0665 - val_loss: 0.0597\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0609\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0603\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0638 - val_loss: 0.0600\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0638 - val_loss: 0.0599\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0602\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0635 - val_loss: 0.0602\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0606\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0631 - val_loss: 0.0605\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0602\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0608\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0603\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0609\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0635 - val_loss: 0.0611\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0645 - val_loss: 0.0604\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0602\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0605\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0652 - val_loss: 0.0607\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0609\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0605\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0617 - val_loss: 0.0603\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0626 - val_loss: 0.0605\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0636 - val_loss: 0.0603\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0608\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0604\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0640 - val_loss: 0.0608\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0670 - val_loss: 0.0609\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0637 - val_loss: 0.0607\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0612\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0630 - val_loss: 0.0604\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0631 - val_loss: 0.0604\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0653 - val_loss: 0.0606\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0604\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0623 - val_loss: 0.0608\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0610\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0636 - val_loss: 0.0606\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0604\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0610\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0649 - val_loss: 0.0601\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0633 - val_loss: 0.0598\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0601\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0613\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0642 - val_loss: 0.0601\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0602\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0596\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0607\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0639 - val_loss: 0.0601\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0634 - val_loss: 0.0600\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0602\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0641 - val_loss: 0.0602\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0602\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0642 - val_loss: 0.0599\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0612\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0605\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0602\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0601\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0602\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0601\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0624 - val_loss: 0.0596\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 79). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 14:55:54,580]\u001b[0m Trial 2 finished with value: 0.06285439970394634 and parameters: {'learning_rate': 0.0006186764640369503, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'LeakyReLU', 'activation2': 'LeakyReLU', 'layers1': 1, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 0 with value: 0.061310371235159956.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 134ms/step - loss: 0.1283 - val_loss: 0.0778\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.1042 - val_loss: 0.0773\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0940 - val_loss: 0.0682\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0852 - val_loss: 0.0641\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0770 - val_loss: 0.0620\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0727 - val_loss: 0.0596\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0710 - val_loss: 0.0590\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0676 - val_loss: 0.0588\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0672 - val_loss: 0.0588\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0655 - val_loss: 0.0598\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0665 - val_loss: 0.0588\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0659 - val_loss: 0.0590\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0663 - val_loss: 0.0587\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0659 - val_loss: 0.0584\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0664 - val_loss: 0.0583\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0659 - val_loss: 0.0589\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0668 - val_loss: 0.0589\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0652 - val_loss: 0.0594\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0642 - val_loss: 0.0590\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0656 - val_loss: 0.0587\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0656 - val_loss: 0.0594\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0589\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0643 - val_loss: 0.0586\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0643 - val_loss: 0.0584\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0586\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0586\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0584\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0652 - val_loss: 0.0586\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0581\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0651 - val_loss: 0.0588\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0646 - val_loss: 0.0599\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0650 - val_loss: 0.0587\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0617 - val_loss: 0.0583\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0641 - val_loss: 0.0589\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0580\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0582\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0664 - val_loss: 0.0590\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0589\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0654 - val_loss: 0.0587\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0639 - val_loss: 0.0584\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0637 - val_loss: 0.0582\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0583\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0633 - val_loss: 0.0585\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0630 - val_loss: 0.0588\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0647 - val_loss: 0.0592\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0588\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0586\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0626 - val_loss: 0.0587\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0579\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0652 - val_loss: 0.0586\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0592\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0585\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0607 - val_loss: 0.0580\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0578\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0586\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0585\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0586\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0581\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0661 - val_loss: 0.0582\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0584\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0582\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0582\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0577\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0579\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0585\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0585\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0627 - val_loss: 0.0580\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0577\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0633 - val_loss: 0.0576\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0577\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0580\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0632 - val_loss: 0.0582\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0638 - val_loss: 0.0577\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0583\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0583\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0622 - val_loss: 0.0586\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0609 - val_loss: 0.0578\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0577\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0582\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0589\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0591\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0584\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0617 - val_loss: 0.0578\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0579\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0620 - val_loss: 0.0579\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0613 - val_loss: 0.0575\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0581\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0615 - val_loss: 0.0583\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0614 - val_loss: 0.0576\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 14:57:28,121]\u001b[0m Trial 3 finished with value: 0.061734803556181134 and parameters: {'learning_rate': 0.000594553185907923, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'LeakyReLU', 'layers1': 1, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 0 with value: 0.061310371235159956.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 135ms/step - loss: 0.1637 - val_loss: 0.0845\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0941 - val_loss: 0.0745\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0866 - val_loss: 0.0641\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0834 - val_loss: 0.0617\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0772 - val_loss: 0.0648\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0765 - val_loss: 0.0616\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0744 - val_loss: 0.0627\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0758 - val_loss: 0.0615\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0741 - val_loss: 0.0616\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0715 - val_loss: 0.0604\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0748 - val_loss: 0.0616\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0730 - val_loss: 0.0614\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0731 - val_loss: 0.0595\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0704 - val_loss: 0.0600\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0721 - val_loss: 0.0608\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0725 - val_loss: 0.0598\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0717 - val_loss: 0.0599\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0698 - val_loss: 0.0642\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0705 - val_loss: 0.0592\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0682 - val_loss: 0.0609\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0666 - val_loss: 0.0594\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0693 - val_loss: 0.0610\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0670 - val_loss: 0.0591\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0671 - val_loss: 0.0604\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0660 - val_loss: 0.0595\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0668 - val_loss: 0.0597\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0676 - val_loss: 0.0606\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0664 - val_loss: 0.0595\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0668 - val_loss: 0.0605\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0686 - val_loss: 0.0595\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0682 - val_loss: 0.0635\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0668 - val_loss: 0.0589\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0689 - val_loss: 0.0597\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0695 - val_loss: 0.0591\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0662 - val_loss: 0.0573\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0644 - val_loss: 0.0602\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0658 - val_loss: 0.0597\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0657 - val_loss: 0.0573\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0631 - val_loss: 0.0586\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0665 - val_loss: 0.0585\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0681 - val_loss: 0.0571\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0664 - val_loss: 0.0607\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0691 - val_loss: 0.0567\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0628 - val_loss: 0.0576\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0613 - val_loss: 0.0612\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0681 - val_loss: 0.0569\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0674 - val_loss: 0.0582\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0663 - val_loss: 0.0580\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0636 - val_loss: 0.0558\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0604\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0646 - val_loss: 0.0575\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0668 - val_loss: 0.0555\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0667 - val_loss: 0.0575\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0648 - val_loss: 0.0575\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0636 - val_loss: 0.0560\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0651 - val_loss: 0.0574\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0564\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0636 - val_loss: 0.0568\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0651 - val_loss: 0.0557\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0651 - val_loss: 0.0562\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0561\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0610 - val_loss: 0.0554\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0585\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0577\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0643 - val_loss: 0.0550\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0634 - val_loss: 0.0604\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0552\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0640 - val_loss: 0.0558\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0637 - val_loss: 0.0560\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0644 - val_loss: 0.0574\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0641 - val_loss: 0.0578\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0578\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0566\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0623 - val_loss: 0.0569\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0618 - val_loss: 0.0563\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0632 - val_loss: 0.0547\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0638 - val_loss: 0.0568\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0635 - val_loss: 0.0545\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0654 - val_loss: 0.0575\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0616 - val_loss: 0.0548\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0651 - val_loss: 0.0562\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0544\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0587\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0567\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0628 - val_loss: 0.0546\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0627 - val_loss: 0.0603\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0634 - val_loss: 0.0558\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0640 - val_loss: 0.0571\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0632 - val_loss: 0.0548\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0639 - val_loss: 0.0559\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0617 - val_loss: 0.0552\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0642 - val_loss: 0.0563\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0627 - val_loss: 0.0565\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0645 - val_loss: 0.0561\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0626 - val_loss: 0.0559\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0650 - val_loss: 0.0561\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0570\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0611 - val_loss: 0.0552\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0633 - val_loss: 0.0562\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0615 - val_loss: 0.0535\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0629 - val_loss: 0.0557\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0564\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0620 - val_loss: 0.0557\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0549\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0612 - val_loss: 0.0547\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0642 - val_loss: 0.0539\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0643 - val_loss: 0.0579\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0610 - val_loss: 0.0545\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0638 - val_loss: 0.0552\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0617 - val_loss: 0.0569\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0545\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0634 - val_loss: 0.0554\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0552\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0614 - val_loss: 0.0552\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0623 - val_loss: 0.0545\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0536\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0595 - val_loss: 0.0538\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0640 - val_loss: 0.0544\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0546\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0546\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0617 - val_loss: 0.0537\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0623 - val_loss: 0.0545\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0633 - val_loss: 0.0544\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0531\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0542\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0525\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0629 - val_loss: 0.0550\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0608 - val_loss: 0.0530\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0615 - val_loss: 0.0548\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0603 - val_loss: 0.0521\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0534\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0613 - val_loss: 0.0554\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0612 - val_loss: 0.0534\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0606 - val_loss: 0.0530\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0617 - val_loss: 0.0523\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0610 - val_loss: 0.0543\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0611 - val_loss: 0.0546\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0610 - val_loss: 0.0518\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0629 - val_loss: 0.0525\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0535\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0520\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0626 - val_loss: 0.0540\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0605 - val_loss: 0.0542\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0598 - val_loss: 0.0525\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0617 - val_loss: 0.0562\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0648 - val_loss: 0.0544\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0597 - val_loss: 0.0522\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0605 - val_loss: 0.0532\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 74). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 14:59:41,285]\u001b[0m Trial 4 finished with value: 0.06351078797144726 and parameters: {'learning_rate': 0.0006378214461455954, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 0 with value: 0.061310371235159956.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 155ms/step - loss: 0.2582 - val_loss: 0.1874\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.1791 - val_loss: 0.1288\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.1358 - val_loss: 0.0975\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.1184 - val_loss: 0.0847\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.1185 - val_loss: 0.0809\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1108 - val_loss: 0.0795\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.1103 - val_loss: 0.0799\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1069 - val_loss: 0.0790\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.1041 - val_loss: 0.0778\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1010 - val_loss: 0.0763\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0972 - val_loss: 0.0751\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0961 - val_loss: 0.0733\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0923 - val_loss: 0.0721\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0929 - val_loss: 0.0712\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0901 - val_loss: 0.0701\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0893 - val_loss: 0.0691\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0870 - val_loss: 0.0677\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0825 - val_loss: 0.0666\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0815 - val_loss: 0.0659\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0827 - val_loss: 0.0656\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0791 - val_loss: 0.0650\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0790 - val_loss: 0.0642\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0755 - val_loss: 0.0639\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0763 - val_loss: 0.0633\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0755 - val_loss: 0.0625\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0749 - val_loss: 0.0621\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0730 - val_loss: 0.0617\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0744 - val_loss: 0.0612\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0719 - val_loss: 0.0610\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0719 - val_loss: 0.0607\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0713 - val_loss: 0.0603\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0702 - val_loss: 0.0603\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0702 - val_loss: 0.0601\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0687 - val_loss: 0.0598\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0669 - val_loss: 0.0596\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0679 - val_loss: 0.0593\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0674 - val_loss: 0.0595\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0689 - val_loss: 0.0593\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0688 - val_loss: 0.0591\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0689 - val_loss: 0.0589\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0666 - val_loss: 0.0589\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0674 - val_loss: 0.0593\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0671 - val_loss: 0.0592\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0674 - val_loss: 0.0588\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0671 - val_loss: 0.0587\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0670 - val_loss: 0.0587\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0675 - val_loss: 0.0588\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0663 - val_loss: 0.0588\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0674 - val_loss: 0.0587\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0673 - val_loss: 0.0588\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0666 - val_loss: 0.0588\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0669 - val_loss: 0.0588\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0661 - val_loss: 0.0590\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0668 - val_loss: 0.0591\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0660 - val_loss: 0.0589\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0673 - val_loss: 0.0587\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0670 - val_loss: 0.0587\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0658 - val_loss: 0.0588\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0682 - val_loss: 0.0588\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0655 - val_loss: 0.0589\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0664 - val_loss: 0.0590\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0665 - val_loss: 0.0588\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0663 - val_loss: 0.0589\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0663 - val_loss: 0.0588\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0663 - val_loss: 0.0589\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0669 - val_loss: 0.0590\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0658 - val_loss: 0.0590\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0655 - val_loss: 0.0592\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0658 - val_loss: 0.0587\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0666 - val_loss: 0.0587\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0665 - val_loss: 0.0589\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0658 - val_loss: 0.0589\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0656 - val_loss: 0.0591\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0656 - val_loss: 0.0590\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0656 - val_loss: 0.0588\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0656 - val_loss: 0.0589\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0661 - val_loss: 0.0589\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0660 - val_loss: 0.0587\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0669 - val_loss: 0.0586\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0590\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0660 - val_loss: 0.0587\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0666 - val_loss: 0.0587\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0658 - val_loss: 0.0586\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0652 - val_loss: 0.0588\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0662 - val_loss: 0.0589\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0655 - val_loss: 0.0587\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0656 - val_loss: 0.0586\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0660 - val_loss: 0.0586\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0671 - val_loss: 0.0588\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0666 - val_loss: 0.0586\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0658 - val_loss: 0.0587\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0652 - val_loss: 0.0589\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0668 - val_loss: 0.0586\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0657 - val_loss: 0.0586\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0649 - val_loss: 0.0587\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0655 - val_loss: 0.0588\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0654 - val_loss: 0.0587\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0585\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:01:23,020]\u001b[0m Trial 5 finished with value: 0.06270774247215814 and parameters: {'learning_rate': 7.926972549929831e-05, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'LeakyReLU', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 0 with value: 0.061310371235159956.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 150ms/step - loss: 0.1277 - val_loss: 0.0757\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0971 - val_loss: 0.0724\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0842 - val_loss: 0.0631\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0763 - val_loss: 0.0614\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0705 - val_loss: 0.0585\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0677 - val_loss: 0.0582\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0673 - val_loss: 0.0578\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0652 - val_loss: 0.0581\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0663 - val_loss: 0.0585\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0655 - val_loss: 0.0591\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0660 - val_loss: 0.0585\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0657 - val_loss: 0.0583\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0661 - val_loss: 0.0584\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0655 - val_loss: 0.0581\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0666 - val_loss: 0.0582\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0658 - val_loss: 0.0590\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0663 - val_loss: 0.0588\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0649 - val_loss: 0.0595\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0655 - val_loss: 0.0586\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0634 - val_loss: 0.0592\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0638 - val_loss: 0.0595\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0634 - val_loss: 0.0596\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0596\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0650 - val_loss: 0.0598\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0637 - val_loss: 0.0600\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0601\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0638 - val_loss: 0.0611\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0648 - val_loss: 0.0605\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0610 - val_loss: 0.0605\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0636 - val_loss: 0.0617\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0643 - val_loss: 0.0602\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0605\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0637 - val_loss: 0.0597\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0641 - val_loss: 0.0609\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0654 - val_loss: 0.0619\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0621 - val_loss: 0.0618\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0648 - val_loss: 0.0613\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0634 - val_loss: 0.0602\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0634 - val_loss: 0.0605\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0609\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0625 - val_loss: 0.0613\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0624 - val_loss: 0.0618\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0612\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0611\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0636 - val_loss: 0.0624\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0625 - val_loss: 0.0612\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0617\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0617\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0638 - val_loss: 0.0615\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0614 - val_loss: 0.0608\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0642 - val_loss: 0.0616\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0626\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0623\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0611\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0593 - val_loss: 0.0602\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0616 - val_loss: 0.0607\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0620 - val_loss: 0.0619\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0618\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0604\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0629 - val_loss: 0.0610\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0661 - val_loss: 0.0613\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0624 - val_loss: 0.0616\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0632 - val_loss: 0.0642\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0615 - val_loss: 0.0615\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0615 - val_loss: 0.0608\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0639 - val_loss: 0.0597\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0621 - val_loss: 0.0607\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0614 - val_loss: 0.0619\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0611\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0622 - val_loss: 0.0606\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0607\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0613 - val_loss: 0.0603\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0635 - val_loss: 0.0605\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0607\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0607\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0628 - val_loss: 0.0620\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0631 - val_loss: 0.0611\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0626 - val_loss: 0.0602\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0594\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0607\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0619 - val_loss: 0.0608\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0617 - val_loss: 0.0606\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0609 - val_loss: 0.0594\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0628 - val_loss: 0.0591\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0632 - val_loss: 0.0609\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0608\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0606\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0612 - val_loss: 0.0605\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0595 - val_loss: 0.0603\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0633 - val_loss: 0.0602\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0606 - val_loss: 0.0611\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0602 - val_loss: 0.0610\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0608 - val_loss: 0.0607\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0608 - val_loss: 0.0596\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0606 - val_loss: 0.0588\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0609 - val_loss: 0.0595\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0607 - val_loss: 0.0609\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0629\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0610\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0645 - val_loss: 0.0615\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0621\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0604 - val_loss: 0.0614\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0612\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0616\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0596\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0598 - val_loss: 0.0594\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0610 - val_loss: 0.0600\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0622 - val_loss: 0.0599\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0611 - val_loss: 0.0592\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0595\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0597\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0598 - val_loss: 0.0591\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0610\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0608 - val_loss: 0.0596\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0614 - val_loss: 0.0601\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0619 - val_loss: 0.0606\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0595 - val_loss: 0.0605\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0611 - val_loss: 0.0603\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0610 - val_loss: 0.0594\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0619 - val_loss: 0.0598\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0601 - val_loss: 0.0603\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0604 - val_loss: 0.0611\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0597 - val_loss: 0.0611\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0615 - val_loss: 0.0601\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0627 - val_loss: 0.0602\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0615 - val_loss: 0.0585\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0611 - val_loss: 0.0596\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0608 - val_loss: 0.0609\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0611 - val_loss: 0.0607\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0610 - val_loss: 0.0593\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0611 - val_loss: 0.0594\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0602\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0586 - val_loss: 0.0598\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0615 - val_loss: 0.0608\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0601 - val_loss: 0.0610\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0619 - val_loss: 0.0607\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0596 - val_loss: 0.0603\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0607 - val_loss: 0.0613\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0594 - val_loss: 0.0594\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0607 - val_loss: 0.0602\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0595 - val_loss: 0.0609\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0610 - val_loss: 0.0606\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 77). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:03:51,873]\u001b[0m Trial 6 finished with value: 0.06112011983093863 and parameters: {'learning_rate': 0.0009176058843603533, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 1, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 143ms/step - loss: 0.1747 - val_loss: 0.0776\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.1163 - val_loss: 0.0745\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0966 - val_loss: 0.0734\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0874 - val_loss: 0.0686\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0790 - val_loss: 0.0634\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0743 - val_loss: 0.0620\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0724 - val_loss: 0.0619\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0681 - val_loss: 0.0607\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0681 - val_loss: 0.0606\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0669 - val_loss: 0.0611\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0667 - val_loss: 0.0596\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0674 - val_loss: 0.0593\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0681 - val_loss: 0.0593\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0664 - val_loss: 0.0590\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0663 - val_loss: 0.0596\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0665 - val_loss: 0.0596\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0667 - val_loss: 0.0588\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0650 - val_loss: 0.0613\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0661 - val_loss: 0.0591\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0650 - val_loss: 0.0604\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0646 - val_loss: 0.0598\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0637 - val_loss: 0.0603\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0635 - val_loss: 0.0596\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0642 - val_loss: 0.0589\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0654 - val_loss: 0.0592\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0653 - val_loss: 0.0591\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0655 - val_loss: 0.0595\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0641 - val_loss: 0.0597\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0589\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0645 - val_loss: 0.0595\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0653 - val_loss: 0.0610\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0647 - val_loss: 0.0594\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0596\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0634 - val_loss: 0.0597\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0609\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0594\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0601\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0661 - val_loss: 0.0602\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0619\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0649 - val_loss: 0.0603\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0643 - val_loss: 0.0602\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0605\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0651 - val_loss: 0.0606\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0632 - val_loss: 0.0604\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0638 - val_loss: 0.0617\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0611\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0611\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0643 - val_loss: 0.0626\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0607\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0632 - val_loss: 0.0611\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0631 - val_loss: 0.0615\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0640 - val_loss: 0.0608\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0601\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0641 - val_loss: 0.0610\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0617\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0625 - val_loss: 0.0618\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0640 - val_loss: 0.0606\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0614 - val_loss: 0.0601\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0623 - val_loss: 0.0610\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0626 - val_loss: 0.0613\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0636 - val_loss: 0.0609\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0633 - val_loss: 0.0601\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0633 - val_loss: 0.0613\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0663 - val_loss: 0.0610\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0630 - val_loss: 0.0602\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0630 - val_loss: 0.0612\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0620 - val_loss: 0.0606\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0624 - val_loss: 0.0606\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0645 - val_loss: 0.0605\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0612\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0618 - val_loss: 0.0618\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0623 - val_loss: 0.0612\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0622 - val_loss: 0.0601\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0628 - val_loss: 0.0608\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0623 - val_loss: 0.0606\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0638 - val_loss: 0.0604\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0604\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0635 - val_loss: 0.0608\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0620 - val_loss: 0.0614\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0637 - val_loss: 0.0609\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0630 - val_loss: 0.0607\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0637 - val_loss: 0.0598\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0625 - val_loss: 0.0612\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0624 - val_loss: 0.0610\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0616 - val_loss: 0.0608\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0604\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0624 - val_loss: 0.0606\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0610\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0630 - val_loss: 0.0601\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0621 - val_loss: 0.0613\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0611 - val_loss: 0.0603\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0606 - val_loss: 0.0604\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0633 - val_loss: 0.0603\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0598 - val_loss: 0.0608\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0603 - val_loss: 0.0605\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0610 - val_loss: 0.0606\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0608 - val_loss: 0.0602\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0610 - val_loss: 0.0597\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 77). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:05:32,409]\u001b[0m Trial 7 finished with value: 0.06217703616460952 and parameters: {'learning_rate': 0.0009258713666959175, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'LeakyReLU', 'activation2': 'linear', 'layers1': 1, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 140ms/step - loss: 0.1738 - val_loss: 0.1532\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1615 - val_loss: 0.1390\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.1491 - val_loss: 0.1264\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.1415 - val_loss: 0.1152\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.1321 - val_loss: 0.1056\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.1207 - val_loss: 0.0974\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.1166 - val_loss: 0.0912\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1141 - val_loss: 0.0864\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.1102 - val_loss: 0.0834\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1066 - val_loss: 0.0812\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.1032 - val_loss: 0.0792\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.1035 - val_loss: 0.0778\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.1003 - val_loss: 0.0768\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.1023 - val_loss: 0.0761\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0977 - val_loss: 0.0754\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0992 - val_loss: 0.0744\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0988 - val_loss: 0.0733\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0933 - val_loss: 0.0722\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0942 - val_loss: 0.0716\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0942 - val_loss: 0.0714\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0917 - val_loss: 0.0710\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0901 - val_loss: 0.0701\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0885 - val_loss: 0.0696\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0876 - val_loss: 0.0687\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0867 - val_loss: 0.0680\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0862 - val_loss: 0.0675\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0849 - val_loss: 0.0667\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0848 - val_loss: 0.0661\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0817 - val_loss: 0.0656\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0808 - val_loss: 0.0652\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0826 - val_loss: 0.0646\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0802 - val_loss: 0.0643\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0789 - val_loss: 0.0637\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0787 - val_loss: 0.0636\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0785 - val_loss: 0.0632\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0761 - val_loss: 0.0626\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0751 - val_loss: 0.0623\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0763 - val_loss: 0.0621\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0759 - val_loss: 0.0618\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0763 - val_loss: 0.0616\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0723 - val_loss: 0.0612\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0718 - val_loss: 0.0607\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0712 - val_loss: 0.0604\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0724 - val_loss: 0.0600\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0711 - val_loss: 0.0600\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0707 - val_loss: 0.0598\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0703 - val_loss: 0.0595\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0684 - val_loss: 0.0592\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0702 - val_loss: 0.0591\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0695 - val_loss: 0.0590\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0683 - val_loss: 0.0589\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0693 - val_loss: 0.0588\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0680 - val_loss: 0.0588\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0682 - val_loss: 0.0586\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0666 - val_loss: 0.0586\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0685 - val_loss: 0.0586\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0678 - val_loss: 0.0585\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0666 - val_loss: 0.0586\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0682 - val_loss: 0.0585\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0651 - val_loss: 0.0584\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0660 - val_loss: 0.0584\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0661 - val_loss: 0.0584\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0656 - val_loss: 0.0583\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0662 - val_loss: 0.0583\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0656 - val_loss: 0.0582\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0671 - val_loss: 0.0583\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0660 - val_loss: 0.0583\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0653 - val_loss: 0.0584\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0649 - val_loss: 0.0583\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0660 - val_loss: 0.0582\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0653 - val_loss: 0.0582\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0653 - val_loss: 0.0582\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0650 - val_loss: 0.0582\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0649 - val_loss: 0.0583\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0583\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0645 - val_loss: 0.0583\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0650 - val_loss: 0.0583\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0651 - val_loss: 0.0583\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0659 - val_loss: 0.0582\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0648 - val_loss: 0.0583\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0652 - val_loss: 0.0583\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0649 - val_loss: 0.0582\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0644 - val_loss: 0.0583\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0647 - val_loss: 0.0583\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0647 - val_loss: 0.0583\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0649 - val_loss: 0.0582\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0662 - val_loss: 0.0583\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0656 - val_loss: 0.0583\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0583\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0633 - val_loss: 0.0583\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0653 - val_loss: 0.0583\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0583\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0636 - val_loss: 0.0582\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0639 - val_loss: 0.0583\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0636 - val_loss: 0.0583\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0655 - val_loss: 0.0582\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0658 - val_loss: 0.0584\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0638 - val_loss: 0.0585\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0642 - val_loss: 0.0585\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0647 - val_loss: 0.0584\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0648 - val_loss: 0.0584\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0584\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0649 - val_loss: 0.0583\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0636 - val_loss: 0.0583\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0647 - val_loss: 0.0583\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0636 - val_loss: 0.0583\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0639 - val_loss: 0.0583\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0641 - val_loss: 0.0583\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0641 - val_loss: 0.0583\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0636 - val_loss: 0.0583\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0634 - val_loss: 0.0583\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0643 - val_loss: 0.0584\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0634 - val_loss: 0.0584\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0644 - val_loss: 0.0584\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0644 - val_loss: 0.0585\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0642 - val_loss: 0.0584\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0644 - val_loss: 0.0584\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0637 - val_loss: 0.0584\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0651 - val_loss: 0.0583\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0659 - val_loss: 0.0582\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0582\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0582\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0650 - val_loss: 0.0582\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0632 - val_loss: 0.0582\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0634 - val_loss: 0.0582\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0639 - val_loss: 0.0581\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0581\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0582\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0582\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0639 - val_loss: 0.0582\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0632 - val_loss: 0.0583\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0584\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0583\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0638 - val_loss: 0.0582\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0582\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0582\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:08:01,593]\u001b[0m Trial 8 finished with value: 0.061993390933001366 and parameters: {'learning_rate': 7.206229750730598e-05, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 1, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 140ms/step - loss: 0.2142 - val_loss: 0.1019\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.1203 - val_loss: 0.0753\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0985 - val_loss: 0.0774\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0891 - val_loss: 0.0687\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0819 - val_loss: 0.0643\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0750 - val_loss: 0.0632\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0733 - val_loss: 0.0626\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0692 - val_loss: 0.0606\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0694 - val_loss: 0.0600\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0665 - val_loss: 0.0601\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0666 - val_loss: 0.0592\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0667 - val_loss: 0.0587\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0666 - val_loss: 0.0594\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0665 - val_loss: 0.0586\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0670 - val_loss: 0.0585\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0669 - val_loss: 0.0605\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0665 - val_loss: 0.0588\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0653 - val_loss: 0.0603\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0645 - val_loss: 0.0597\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0655 - val_loss: 0.0590\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0648 - val_loss: 0.0598\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0596\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0637 - val_loss: 0.0600\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0635 - val_loss: 0.0600\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0645 - val_loss: 0.0596\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0596\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0653 - val_loss: 0.0597\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0595\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0596\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0609\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0613 - val_loss: 0.0597\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0597\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0636 - val_loss: 0.0594\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0609\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0637 - val_loss: 0.0596\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0603\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0663 - val_loss: 0.0597\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0623 - val_loss: 0.0610\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0648 - val_loss: 0.0598\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0635 - val_loss: 0.0595\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0599\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0601\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0611\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0599\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0632 - val_loss: 0.0597\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0640 - val_loss: 0.0604\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0593\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0605\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0633 - val_loss: 0.0607\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0596\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0617 - val_loss: 0.0592\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0649 - val_loss: 0.0598\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0648 - val_loss: 0.0603\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0629 - val_loss: 0.0604\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0595\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0607 - val_loss: 0.0591\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0597\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0596\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0600\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0594\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0634 - val_loss: 0.0602\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0669 - val_loss: 0.0602\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0633 - val_loss: 0.0601\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0612\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0621 - val_loss: 0.0597\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0622 - val_loss: 0.0597\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0648 - val_loss: 0.0594\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0624 - val_loss: 0.0597\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0604\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0602\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0602\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0603\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0624 - val_loss: 0.0595\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0641 - val_loss: 0.0591\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0628 - val_loss: 0.0593\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0597\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0611\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0598\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0599\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0592\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0631 - val_loss: 0.0606\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0601\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0598\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0599\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0634 - val_loss: 0.0593\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0601\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0605\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0617\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0597\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0603 - val_loss: 0.0587\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0601\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0614 - val_loss: 0.0600\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0613 - val_loss: 0.0600\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0613 - val_loss: 0.0597\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 0.0587\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 87). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:09:36,005]\u001b[0m Trial 9 finished with value: 0.062351122734517345 and parameters: {'learning_rate': 0.0008143313682980463, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'LeakyReLU', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 100}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 156ms/step - loss: 0.1239 - val_loss: 0.0764\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0886 - val_loss: 0.0676\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0904 - val_loss: 0.0667\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0859 - val_loss: 0.0662\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0824 - val_loss: 0.0648\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0795 - val_loss: 0.0637\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0781 - val_loss: 0.0636\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0796 - val_loss: 0.0635\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0792 - val_loss: 0.0617\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0765 - val_loss: 0.0623\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0772 - val_loss: 0.0627\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0754 - val_loss: 0.0619\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0749 - val_loss: 0.0614\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0744 - val_loss: 0.0610\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0763 - val_loss: 0.0626\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0766 - val_loss: 0.0621\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0724 - val_loss: 0.0599\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0722 - val_loss: 0.0610\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0717 - val_loss: 0.0600\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0715 - val_loss: 0.0597\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0688 - val_loss: 0.0592\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0718 - val_loss: 0.0597\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0691 - val_loss: 0.0598\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0685 - val_loss: 0.0591\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0679 - val_loss: 0.0589\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0688 - val_loss: 0.0595\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0683 - val_loss: 0.0587\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0682 - val_loss: 0.0585\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0677 - val_loss: 0.0588\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0676 - val_loss: 0.0585\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0682 - val_loss: 0.0586\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0674 - val_loss: 0.0598\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0665 - val_loss: 0.0580\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0702 - val_loss: 0.0592\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0665 - val_loss: 0.0584\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0663 - val_loss: 0.0577\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0670 - val_loss: 0.0602\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0668 - val_loss: 0.0586\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0638 - val_loss: 0.0579\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0660 - val_loss: 0.0573\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0668 - val_loss: 0.0586\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0671 - val_loss: 0.0593\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0653 - val_loss: 0.0575\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0661 - val_loss: 0.0577\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0685 - val_loss: 0.0590\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0642 - val_loss: 0.0580\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0625 - val_loss: 0.0583\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0673 - val_loss: 0.0592\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0678 - val_loss: 0.0591\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0658 - val_loss: 0.0586\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0644 - val_loss: 0.0575\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0653 - val_loss: 0.0588\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0640 - val_loss: 0.0600\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0665 - val_loss: 0.0582\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0667 - val_loss: 0.0578\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0654 - val_loss: 0.0596\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0641 - val_loss: 0.0577\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0655 - val_loss: 0.0579\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0639 - val_loss: 0.0585\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0637 - val_loss: 0.0588\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0644 - val_loss: 0.0584\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0647 - val_loss: 0.0576\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0643 - val_loss: 0.0580\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0607 - val_loss: 0.0569\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0632 - val_loss: 0.0584\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0629 - val_loss: 0.0590\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0643 - val_loss: 0.0578\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0612 - val_loss: 0.0593\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0640 - val_loss: 0.0576\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0633 - val_loss: 0.0581\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0643 - val_loss: 0.0581\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0630 - val_loss: 0.0582\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0645 - val_loss: 0.0585\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0624 - val_loss: 0.0578\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0628 - val_loss: 0.0574\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0632 - val_loss: 0.0585\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0634 - val_loss: 0.0572\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0634 - val_loss: 0.0576\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0640 - val_loss: 0.0574\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0656 - val_loss: 0.0583\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0624 - val_loss: 0.0564\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0664 - val_loss: 0.0577\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0633 - val_loss: 0.0566\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0633 - val_loss: 0.0573\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0645 - val_loss: 0.0586\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0638 - val_loss: 0.0564\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0622 - val_loss: 0.0571\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0631 - val_loss: 0.0575\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0640 - val_loss: 0.0585\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0631 - val_loss: 0.0568\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0655 - val_loss: 0.0580\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0629 - val_loss: 0.0576\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0638 - val_loss: 0.0570\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0641 - val_loss: 0.0580\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0642 - val_loss: 0.0578\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0625 - val_loss: 0.0577\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0641 - val_loss: 0.0568\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0617 - val_loss: 0.0579\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0614 - val_loss: 0.0578\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0637 - val_loss: 0.0580\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0626 - val_loss: 0.0564\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0627 - val_loss: 0.0573\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0616 - val_loss: 0.0583\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0618 - val_loss: 0.0589\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0612 - val_loss: 0.0573\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0621 - val_loss: 0.0570\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0663 - val_loss: 0.0569\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0626 - val_loss: 0.0589\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0627 - val_loss: 0.0561\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0620 - val_loss: 0.0580\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0635 - val_loss: 0.0590\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0643 - val_loss: 0.0574\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0636 - val_loss: 0.0571\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0621 - val_loss: 0.0575\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0624 - val_loss: 0.0570\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0646 - val_loss: 0.0569\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0605 - val_loss: 0.0570\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0642 - val_loss: 0.0574\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0623 - val_loss: 0.0566\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0626 - val_loss: 0.0572\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0622 - val_loss: 0.0577\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0629 - val_loss: 0.0577\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0646 - val_loss: 0.0574\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0628 - val_loss: 0.0563\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0640 - val_loss: 0.0567\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0625 - val_loss: 0.0563\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0635 - val_loss: 0.0580\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0611 - val_loss: 0.0581\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0616 - val_loss: 0.0571\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0621 - val_loss: 0.0561\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0631 - val_loss: 0.0562\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0624 - val_loss: 0.0584\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0625 - val_loss: 0.0584\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0612 - val_loss: 0.0579\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0630 - val_loss: 0.0565\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0622 - val_loss: 0.0564\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0630 - val_loss: 0.0583\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0626 - val_loss: 0.0561\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0622 - val_loss: 0.0573\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0632 - val_loss: 0.0567\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0620 - val_loss: 0.0573\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0627 - val_loss: 0.0573\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0619 - val_loss: 0.0559\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0578\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0649 - val_loss: 0.0578\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0570\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0568\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 74). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:12:25,599]\u001b[0m Trial 10 finished with value: 0.06342583965605045 and parameters: {'learning_rate': 0.0003972346538015031, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'relu', 'layers1': 3, 'layers2': 1, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 4s 178ms/step - loss: 0.1054 - val_loss: 0.0714\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0902 - val_loss: 0.0678\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0915 - val_loss: 0.0686\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0877 - val_loss: 0.0676\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0837 - val_loss: 0.0651\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0807 - val_loss: 0.0645\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0799 - val_loss: 0.0647\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0808 - val_loss: 0.0641\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0800 - val_loss: 0.0624\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 145ms/step - loss: 0.0772 - val_loss: 0.0626\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0779 - val_loss: 0.0632\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0761 - val_loss: 0.0622\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0756 - val_loss: 0.0616\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0758 - val_loss: 0.0613\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0780 - val_loss: 0.0625\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0781 - val_loss: 0.0625\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0730 - val_loss: 0.0601\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0731 - val_loss: 0.0620\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0740 - val_loss: 0.0605\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0733 - val_loss: 0.0602\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0707 - val_loss: 0.0602\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0739 - val_loss: 0.0602\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0712 - val_loss: 0.0604\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0707 - val_loss: 0.0598\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0697 - val_loss: 0.0595\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0714 - val_loss: 0.0606\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0715 - val_loss: 0.0597\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0702 - val_loss: 0.0594\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0701 - val_loss: 0.0599\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0698 - val_loss: 0.0595\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0706 - val_loss: 0.0595\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0701 - val_loss: 0.0604\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0691 - val_loss: 0.0587\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 0.0720 - val_loss: 0.0598\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0692 - val_loss: 0.0592\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0693 - val_loss: 0.0584\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0685 - val_loss: 0.0609\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 151ms/step - loss: 0.0692 - val_loss: 0.0592\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0662 - val_loss: 0.0585\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0681 - val_loss: 0.0584\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0681 - val_loss: 0.0587\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0692 - val_loss: 0.0598\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0670 - val_loss: 0.0582\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0679 - val_loss: 0.0582\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0698 - val_loss: 0.0594\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0658 - val_loss: 0.0586\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0645 - val_loss: 0.0589\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0692 - val_loss: 0.0596\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0689 - val_loss: 0.0591\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0672 - val_loss: 0.0592\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0666 - val_loss: 0.0582\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0672 - val_loss: 0.0589\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0655 - val_loss: 0.0599\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0674 - val_loss: 0.0585\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0682 - val_loss: 0.0582\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0667 - val_loss: 0.0597\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0650 - val_loss: 0.0585\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0669 - val_loss: 0.0585\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0662 - val_loss: 0.0587\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0650 - val_loss: 0.0594\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0661 - val_loss: 0.0590\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0657 - val_loss: 0.0583\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0658 - val_loss: 0.0589\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0624 - val_loss: 0.0577\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0648 - val_loss: 0.0586\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0646 - val_loss: 0.0591\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0656 - val_loss: 0.0584\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0631 - val_loss: 0.0599\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0656 - val_loss: 0.0578\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0651 - val_loss: 0.0585\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0663 - val_loss: 0.0584\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0640 - val_loss: 0.0584\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0645 - val_loss: 0.0593\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0651 - val_loss: 0.0579\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0650 - val_loss: 0.0579\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0653 - val_loss: 0.0584\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0669 - val_loss: 0.0593\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0630 - val_loss: 0.0576\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0670 - val_loss: 0.0585\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0641 - val_loss: 0.0578\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0649 - val_loss: 0.0587\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0654 - val_loss: 0.0595\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0652 - val_loss: 0.0577\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0638 - val_loss: 0.0581\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0645 - val_loss: 0.0591\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0649 - val_loss: 0.0594\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0647 - val_loss: 0.0576\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0665 - val_loss: 0.0586\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0634 - val_loss: 0.0587\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0650 - val_loss: 0.0577\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0654 - val_loss: 0.0581\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0652 - val_loss: 0.0585\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0635 - val_loss: 0.0591\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0652 - val_loss: 0.0579\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0633 - val_loss: 0.0585\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0648 - val_loss: 0.0585\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0632 - val_loss: 0.0572\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0645 - val_loss: 0.0585\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0633 - val_loss: 0.0584\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0627 - val_loss: 0.0591\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0625 - val_loss: 0.0582\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0635 - val_loss: 0.0576\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0678 - val_loss: 0.0571\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0660 - val_loss: 0.0595\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0637 - val_loss: 0.0601\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0645 - val_loss: 0.0569\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0633 - val_loss: 0.0577\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0644 - val_loss: 0.0595\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0662 - val_loss: 0.0580\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0646 - val_loss: 0.0573\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0632 - val_loss: 0.0580\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0630 - val_loss: 0.0577\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0659 - val_loss: 0.0573\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0620 - val_loss: 0.0576\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0640 - val_loss: 0.0569\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0642 - val_loss: 0.0573\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0638 - val_loss: 0.0586\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0639 - val_loss: 0.0584\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0650 - val_loss: 0.0582\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0636 - val_loss: 0.0567\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0648 - val_loss: 0.0576\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0631 - val_loss: 0.0573\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0632 - val_loss: 0.0580\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0630 - val_loss: 0.0567\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0644 - val_loss: 0.0565\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0632 - val_loss: 0.0584\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0639 - val_loss: 0.0586\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0629 - val_loss: 0.0582\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0631 - val_loss: 0.0567\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0635 - val_loss: 0.0568\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0634 - val_loss: 0.0586\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0636 - val_loss: 0.0586\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0634 - val_loss: 0.0567\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0632 - val_loss: 0.0574\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0640 - val_loss: 0.0572\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0630 - val_loss: 0.0580\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0642 - val_loss: 0.0574\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0629 - val_loss: 0.0562\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0634 - val_loss: 0.0585\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0656 - val_loss: 0.0585\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0574\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0616 - val_loss: 0.0574\n",
            "2/2 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:15:29,143]\u001b[0m Trial 11 finished with value: 0.06203197164850083 and parameters: {'learning_rate': 0.00025584799798269975, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 1, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 189ms/step - loss: 0.1382 - val_loss: 0.0650\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0899 - val_loss: 0.0677\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0825 - val_loss: 0.0641\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0829 - val_loss: 0.0641\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 145ms/step - loss: 0.0778 - val_loss: 0.0659\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0748 - val_loss: 0.0608\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0722 - val_loss: 0.0612\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0734 - val_loss: 0.0605\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0712 - val_loss: 0.0611\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0690 - val_loss: 0.0602\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0721 - val_loss: 0.0609\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0717 - val_loss: 0.0615\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0711 - val_loss: 0.0591\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0690 - val_loss: 0.0601\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0709 - val_loss: 0.0611\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.0713 - val_loss: 0.0599\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 148ms/step - loss: 0.0714 - val_loss: 0.0596\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0693 - val_loss: 0.0660\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0696 - val_loss: 0.0590\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0677 - val_loss: 0.0613\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0664 - val_loss: 0.0595\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0691 - val_loss: 0.0598\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 148ms/step - loss: 0.0668 - val_loss: 0.0596\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0666 - val_loss: 0.0594\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0656 - val_loss: 0.0595\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0666 - val_loss: 0.0598\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0666 - val_loss: 0.0591\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0663 - val_loss: 0.0599\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0661 - val_loss: 0.0593\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 153ms/step - loss: 0.0684 - val_loss: 0.0594\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0673 - val_loss: 0.0615\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0670 - val_loss: 0.0605\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0676 - val_loss: 0.0594\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0691 - val_loss: 0.0612\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0656 - val_loss: 0.0577\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0652 - val_loss: 0.0599\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0656 - val_loss: 0.0619\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0653 - val_loss: 0.0573\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0633 - val_loss: 0.0589\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 0.0656 - val_loss: 0.0580\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 167ms/step - loss: 0.0680 - val_loss: 0.0577\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 160ms/step - loss: 0.0640 - val_loss: 0.0568\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0669 - val_loss: 0.0599\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 155ms/step - loss: 0.0688 - val_loss: 0.0575\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0633 - val_loss: 0.0570\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0622 - val_loss: 0.0609\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0679 - val_loss: 0.0580\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0674 - val_loss: 0.0564\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0657 - val_loss: 0.0576\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 145ms/step - loss: 0.0629 - val_loss: 0.0557\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0652 - val_loss: 0.0584\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 148ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 145ms/step - loss: 0.0663 - val_loss: 0.0560\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0674 - val_loss: 0.0565\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0647 - val_loss: 0.0578\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 151ms/step - loss: 0.0635 - val_loss: 0.0557\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0650 - val_loss: 0.0570\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0629 - val_loss: 0.0565\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 0.0633 - val_loss: 0.0564\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0655 - val_loss: 0.0562\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0642 - val_loss: 0.0559\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0631 - val_loss: 0.0563\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0608 - val_loss: 0.0551\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0630 - val_loss: 0.0570\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0625 - val_loss: 0.0575\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0644 - val_loss: 0.0549\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 0.0625 - val_loss: 0.0582\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 145ms/step - loss: 0.0627 - val_loss: 0.0560\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 0.0641 - val_loss: 0.0548\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 151ms/step - loss: 0.0635 - val_loss: 0.0563\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 0.0646 - val_loss: 0.0571\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0635 - val_loss: 0.0570\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 148ms/step - loss: 0.0638 - val_loss: 0.0573\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 153ms/step - loss: 0.0622 - val_loss: 0.0560\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 0.0624 - val_loss: 0.0553\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 159ms/step - loss: 0.0607 - val_loss: 0.0568\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 2s 169ms/step - loss: 0.0624 - val_loss: 0.0559\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 162ms/step - loss: 0.0643 - val_loss: 0.0560\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.0630 - val_loss: 0.0559\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 161ms/step - loss: 0.0656 - val_loss: 0.0571\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 160ms/step - loss: 0.0612 - val_loss: 0.0550\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 165ms/step - loss: 0.0645 - val_loss: 0.0564\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.0624 - val_loss: 0.0551\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 165ms/step - loss: 0.0629 - val_loss: 0.0565\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 159ms/step - loss: 0.0635 - val_loss: 0.0576\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 159ms/step - loss: 0.0632 - val_loss: 0.0548\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 0.0624 - val_loss: 0.0567\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 155ms/step - loss: 0.0630 - val_loss: 0.0570\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0631 - val_loss: 0.0567\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0630 - val_loss: 0.0547\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 157ms/step - loss: 0.0637 - val_loss: 0.0558\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0612 - val_loss: 0.0557\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0643 - val_loss: 0.0557\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0625 - val_loss: 0.0567\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 158ms/step - loss: 0.0636 - val_loss: 0.0561\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0609 - val_loss: 0.0560\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 2s 175ms/step - loss: 0.0648 - val_loss: 0.0559\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0610 - val_loss: 0.0570\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 0.0605 - val_loss: 0.0553\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 162ms/step - loss: 0.0630 - val_loss: 0.0562\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 158ms/step - loss: 0.0605 - val_loss: 0.0550\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 159ms/step - loss: 0.0619 - val_loss: 0.0559\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.0629 - val_loss: 0.0566\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0625 - val_loss: 0.0571\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 156ms/step - loss: 0.0616 - val_loss: 0.0554\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 151ms/step - loss: 0.0608 - val_loss: 0.0555\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 151ms/step - loss: 0.0638 - val_loss: 0.0545\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0639 - val_loss: 0.0569\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 151ms/step - loss: 0.0611 - val_loss: 0.0567\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0636 - val_loss: 0.0543\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 167ms/step - loss: 0.0612 - val_loss: 0.0571\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 158ms/step - loss: 0.0629 - val_loss: 0.0570\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 160ms/step - loss: 0.0626 - val_loss: 0.0550\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0624 - val_loss: 0.0551\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 154ms/step - loss: 0.0611 - val_loss: 0.0565\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.0619 - val_loss: 0.0554\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0630 - val_loss: 0.0546\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0593 - val_loss: 0.0550\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 156ms/step - loss: 0.0634 - val_loss: 0.0555\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0622 - val_loss: 0.0550\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 153ms/step - loss: 0.0616 - val_loss: 0.0550\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 154ms/step - loss: 0.0620 - val_loss: 0.0553\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0622 - val_loss: 0.0552\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 0.0626 - val_loss: 0.0556\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0616 - val_loss: 0.0543\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0631 - val_loss: 0.0546\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 156ms/step - loss: 0.0618 - val_loss: 0.0536\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0624 - val_loss: 0.0554\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0608 - val_loss: 0.0551\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 153ms/step - loss: 0.0600 - val_loss: 0.0553\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0600 - val_loss: 0.0542\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 0.0616 - val_loss: 0.0542\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0610 - val_loss: 0.0565\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 148ms/step - loss: 0.0612 - val_loss: 0.0551\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 154ms/step - loss: 0.0605 - val_loss: 0.0546\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 157ms/step - loss: 0.0606 - val_loss: 0.0536\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 160ms/step - loss: 0.0607 - val_loss: 0.0542\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0609 - val_loss: 0.0568\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 155ms/step - loss: 0.0613 - val_loss: 0.0545\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.0619 - val_loss: 0.0533\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.0611 - val_loss: 0.0549\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 0.0632 - val_loss: 0.0543\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 154ms/step - loss: 0.0618 - val_loss: 0.0553\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 155ms/step - loss: 0.0604 - val_loss: 0.0546\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 0.0587 - val_loss: 0.0537\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0615 - val_loss: 0.0564\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0650 - val_loss: 0.0554\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0593 - val_loss: 0.0538\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0598 - val_loss: 0.0542\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 76). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:18:54,061]\u001b[0m Trial 12 finished with value: 0.06312248363439851 and parameters: {'learning_rate': 0.000786149085625244, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 1, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 169ms/step - loss: 0.0999 - val_loss: 0.0664\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0831 - val_loss: 0.0661\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0805 - val_loss: 0.0619\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0796 - val_loss: 0.0622\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0764 - val_loss: 0.0609\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0743 - val_loss: 0.0625\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0729 - val_loss: 0.0605\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0734 - val_loss: 0.0597\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0714 - val_loss: 0.0628\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0698 - val_loss: 0.0592\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0730 - val_loss: 0.0605\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0725 - val_loss: 0.0624\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0727 - val_loss: 0.0591\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0676 - val_loss: 0.0591\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0689 - val_loss: 0.0593\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0700 - val_loss: 0.0591\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0693 - val_loss: 0.0579\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0666 - val_loss: 0.0648\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0681 - val_loss: 0.0576\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0661 - val_loss: 0.0589\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0648 - val_loss: 0.0581\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0684 - val_loss: 0.0590\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0653 - val_loss: 0.0582\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0647 - val_loss: 0.0576\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0639 - val_loss: 0.0580\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0643 - val_loss: 0.0581\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0646 - val_loss: 0.0577\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0644 - val_loss: 0.0571\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0641 - val_loss: 0.0576\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0666 - val_loss: 0.0560\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0662 - val_loss: 0.0609\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0653 - val_loss: 0.0563\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0662 - val_loss: 0.0580\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0676 - val_loss: 0.0576\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0639 - val_loss: 0.0558\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0627 - val_loss: 0.0577\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0641 - val_loss: 0.0581\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0635 - val_loss: 0.0551\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0602 - val_loss: 0.0554\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0634 - val_loss: 0.0578\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0647 - val_loss: 0.0549\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0664 - val_loss: 0.0567\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0622 - val_loss: 0.0558\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0653 - val_loss: 0.0585\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0677 - val_loss: 0.0552\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0614 - val_loss: 0.0564\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0604 - val_loss: 0.0592\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0651 - val_loss: 0.0563\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0662 - val_loss: 0.0576\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0643 - val_loss: 0.0567\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0613 - val_loss: 0.0551\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0635 - val_loss: 0.0572\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0621 - val_loss: 0.0567\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0654 - val_loss: 0.0546\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0651 - val_loss: 0.0560\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0631 - val_loss: 0.0560\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0617 - val_loss: 0.0556\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0633 - val_loss: 0.0562\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0622 - val_loss: 0.0552\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0627 - val_loss: 0.0554\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0631 - val_loss: 0.0541\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0634 - val_loss: 0.0557\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0617 - val_loss: 0.0540\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0598 - val_loss: 0.0538\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0614 - val_loss: 0.0571\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0606 - val_loss: 0.0555\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0618 - val_loss: 0.0537\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0617 - val_loss: 0.0567\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0615 - val_loss: 0.0545\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0623 - val_loss: 0.0544\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0617 - val_loss: 0.0543\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0623 - val_loss: 0.0565\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0622 - val_loss: 0.0560\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0621 - val_loss: 0.0567\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0618 - val_loss: 0.0541\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0605 - val_loss: 0.0562\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0611 - val_loss: 0.0548\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0612 - val_loss: 0.0534\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0619 - val_loss: 0.0556\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0619 - val_loss: 0.0524\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0652 - val_loss: 0.0562\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0601 - val_loss: 0.0536\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0634 - val_loss: 0.0556\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0619 - val_loss: 0.0533\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0613 - val_loss: 0.0572\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0635 - val_loss: 0.0548\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0617 - val_loss: 0.0540\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0609 - val_loss: 0.0580\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0617 - val_loss: 0.0539\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0626 - val_loss: 0.0576\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0618 - val_loss: 0.0532\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0628 - val_loss: 0.0551\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0605 - val_loss: 0.0541\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0637 - val_loss: 0.0548\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0608 - val_loss: 0.0561\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0635 - val_loss: 0.0544\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0608 - val_loss: 0.0552\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0636 - val_loss: 0.0555\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0602 - val_loss: 0.0551\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0595 - val_loss: 0.0546\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0618 - val_loss: 0.0546\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0605 - val_loss: 0.0539\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0612 - val_loss: 0.0553\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0612 - val_loss: 0.0543\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0597 - val_loss: 0.0555\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0599 - val_loss: 0.0541\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0596 - val_loss: 0.0541\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0623 - val_loss: 0.0525\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0623 - val_loss: 0.0571\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0608 - val_loss: 0.0530\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0618 - val_loss: 0.0549\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0605 - val_loss: 0.0556\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0608 - val_loss: 0.0538\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0608 - val_loss: 0.0543\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0629 - val_loss: 0.0528\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0603 - val_loss: 0.0552\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0602 - val_loss: 0.0532\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0613 - val_loss: 0.0527\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0580 - val_loss: 0.0527\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0610 - val_loss: 0.0527\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0605 - val_loss: 0.0548\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0607 - val_loss: 0.0527\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0606 - val_loss: 0.0539\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0610 - val_loss: 0.0544\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0633 - val_loss: 0.0540\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0611 - val_loss: 0.0521\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0617 - val_loss: 0.0525\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0599 - val_loss: 0.0522\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0615 - val_loss: 0.0526\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0587 - val_loss: 0.0528\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0592 - val_loss: 0.0542\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0591 - val_loss: 0.0510\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0594 - val_loss: 0.0538\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0607 - val_loss: 0.0543\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0599 - val_loss: 0.0529\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0594 - val_loss: 0.0536\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0589 - val_loss: 0.0516\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0596 - val_loss: 0.0545\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0593 - val_loss: 0.0547\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0593 - val_loss: 0.0525\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0625 - val_loss: 0.0533\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0619 - val_loss: 0.0536\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0613 - val_loss: 0.0514\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0608 - val_loss: 0.0539\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0583 - val_loss: 0.0533\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0595 - val_loss: 0.0518\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0602 - val_loss: 0.0557\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0631 - val_loss: 0.0546\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0587 - val_loss: 0.0529\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0596 - val_loss: 0.0532\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:21:56,800]\u001b[0m Trial 13 finished with value: 0.0630532154945284 and parameters: {'learning_rate': 0.0009927023326204427, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 1, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 166ms/step - loss: 0.0989 - val_loss: 0.0711\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0873 - val_loss: 0.0679\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0846 - val_loss: 0.0664\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0841 - val_loss: 0.0637\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0803 - val_loss: 0.0640\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0790 - val_loss: 0.0635\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0767 - val_loss: 0.0628\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0798 - val_loss: 0.0629\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0775 - val_loss: 0.0613\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0752 - val_loss: 0.0620\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0769 - val_loss: 0.0629\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0740 - val_loss: 0.0616\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0737 - val_loss: 0.0609\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0740 - val_loss: 0.0612\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0765 - val_loss: 0.0616\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0763 - val_loss: 0.0615\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0710 - val_loss: 0.0597\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0715 - val_loss: 0.0619\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0723 - val_loss: 0.0600\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0723 - val_loss: 0.0601\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0692 - val_loss: 0.0597\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0727 - val_loss: 0.0600\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0695 - val_loss: 0.0600\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0696 - val_loss: 0.0594\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0687 - val_loss: 0.0594\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0701 - val_loss: 0.0601\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0695 - val_loss: 0.0590\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0682 - val_loss: 0.0590\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0682 - val_loss: 0.0592\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0688 - val_loss: 0.0588\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0694 - val_loss: 0.0586\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0690 - val_loss: 0.0598\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0681 - val_loss: 0.0584\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0709 - val_loss: 0.0592\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0674 - val_loss: 0.0586\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0674 - val_loss: 0.0578\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0668 - val_loss: 0.0605\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0675 - val_loss: 0.0585\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0641 - val_loss: 0.0578\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0666 - val_loss: 0.0576\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0669 - val_loss: 0.0582\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0681 - val_loss: 0.0589\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0659 - val_loss: 0.0574\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0673 - val_loss: 0.0577\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0692 - val_loss: 0.0586\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0649 - val_loss: 0.0576\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0635 - val_loss: 0.0587\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0695 - val_loss: 0.0592\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0682 - val_loss: 0.0581\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0666 - val_loss: 0.0582\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0657 - val_loss: 0.0573\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0666 - val_loss: 0.0583\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0649 - val_loss: 0.0588\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0668 - val_loss: 0.0575\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0677 - val_loss: 0.0572\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0659 - val_loss: 0.0588\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0650 - val_loss: 0.0576\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0664 - val_loss: 0.0577\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0657 - val_loss: 0.0579\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0645 - val_loss: 0.0584\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0657 - val_loss: 0.0581\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0652 - val_loss: 0.0576\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0655 - val_loss: 0.0583\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0624 - val_loss: 0.0572\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0644 - val_loss: 0.0590\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0650 - val_loss: 0.0591\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0660 - val_loss: 0.0582\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0636 - val_loss: 0.0598\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0653 - val_loss: 0.0582\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0654 - val_loss: 0.0572\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0640 - val_loss: 0.0578\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0650 - val_loss: 0.0579\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0641 - val_loss: 0.0578\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0670 - val_loss: 0.0579\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0643 - val_loss: 0.0576\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0648 - val_loss: 0.0572\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0645 - val_loss: 0.0585\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0653 - val_loss: 0.0569\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0650 - val_loss: 0.0572\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0653 - val_loss: 0.0576\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0671 - val_loss: 0.0582\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0630 - val_loss: 0.0564\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0673 - val_loss: 0.0577\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0641 - val_loss: 0.0567\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0650 - val_loss: 0.0580\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0649 - val_loss: 0.0564\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0639 - val_loss: 0.0574\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0648 - val_loss: 0.0582\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0651 - val_loss: 0.0582\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0649 - val_loss: 0.0564\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0663 - val_loss: 0.0579\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0636 - val_loss: 0.0578\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0649 - val_loss: 0.0567\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0653 - val_loss: 0.0572\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0649 - val_loss: 0.0577\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0633 - val_loss: 0.0582\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0654 - val_loss: 0.0571\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0636 - val_loss: 0.0579\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0632 - val_loss: 0.0579\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0647 - val_loss: 0.0579\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0631 - val_loss: 0.0564\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0645 - val_loss: 0.0584\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0638 - val_loss: 0.0578\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0626 - val_loss: 0.0574\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0639 - val_loss: 0.0569\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0677 - val_loss: 0.0565\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0661 - val_loss: 0.0594\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0649 - val_loss: 0.0560\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0636 - val_loss: 0.0576\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0644 - val_loss: 0.0593\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0661 - val_loss: 0.0573\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0644 - val_loss: 0.0569\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0630 - val_loss: 0.0574\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0634 - val_loss: 0.0571\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0660 - val_loss: 0.0568\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0621 - val_loss: 0.0571\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0656 - val_loss: 0.0577\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0639 - val_loss: 0.0562\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0642 - val_loss: 0.0568\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0640 - val_loss: 0.0578\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0648 - val_loss: 0.0573\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0634 - val_loss: 0.0560\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0653 - val_loss: 0.0572\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0635 - val_loss: 0.0566\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0651 - val_loss: 0.0580\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0631 - val_loss: 0.0579\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0632 - val_loss: 0.0574\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0631 - val_loss: 0.0563\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0643 - val_loss: 0.0562\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0637 - val_loss: 0.0585\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0645 - val_loss: 0.0580\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0636 - val_loss: 0.0574\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0627 - val_loss: 0.0558\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0639 - val_loss: 0.0564\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0639 - val_loss: 0.0583\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0637 - val_loss: 0.0578\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0641 - val_loss: 0.0560\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0638 - val_loss: 0.0572\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0642 - val_loss: 0.0565\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0635 - val_loss: 0.0574\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0642 - val_loss: 0.0567\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0632 - val_loss: 0.0559\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0592\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0664 - val_loss: 0.0581\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0634 - val_loss: 0.0568\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0567\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:24:56,081]\u001b[0m Trial 14 finished with value: 0.06201794639372511 and parameters: {'learning_rate': 0.00024174164850567577, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'LeakyReLU', 'layers1': 1, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 145ms/step - loss: 0.1255 - val_loss: 0.0786\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0958 - val_loss: 0.0688\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0828 - val_loss: 0.0622\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0744 - val_loss: 0.0601\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0699 - val_loss: 0.0585\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0677 - val_loss: 0.0582\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0678 - val_loss: 0.0581\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0658 - val_loss: 0.0585\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0667 - val_loss: 0.0590\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0651 - val_loss: 0.0599\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0659 - val_loss: 0.0587\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0659 - val_loss: 0.0585\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0665 - val_loss: 0.0586\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0655 - val_loss: 0.0583\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0666 - val_loss: 0.0582\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0662 - val_loss: 0.0590\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0670 - val_loss: 0.0588\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0653 - val_loss: 0.0601\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0652 - val_loss: 0.0587\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0653 - val_loss: 0.0596\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0589\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0595\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0592\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0588\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0647 - val_loss: 0.0590\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0590\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0652 - val_loss: 0.0593\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0640 - val_loss: 0.0597\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0644 - val_loss: 0.0611\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0613 - val_loss: 0.0596\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0600\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0625 - val_loss: 0.0606\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0599\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0638 - val_loss: 0.0607\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0650 - val_loss: 0.0612\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0614\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0601\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0633 - val_loss: 0.0591\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0592\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0647 - val_loss: 0.0602\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0609\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0619 - val_loss: 0.0614\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0615 - val_loss: 0.0607\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0625 - val_loss: 0.0606\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0635 - val_loss: 0.0620\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0622 - val_loss: 0.0600\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0626 - val_loss: 0.0599\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0608\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0610\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0611 - val_loss: 0.0601\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0631 - val_loss: 0.0615\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0629\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0617 - val_loss: 0.0623\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0623 - val_loss: 0.0606\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0590 - val_loss: 0.0602\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0614 - val_loss: 0.0606\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0612 - val_loss: 0.0624\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0622 - val_loss: 0.0608\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0623 - val_loss: 0.0606\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0652 - val_loss: 0.0613\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0616\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0648\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0606 - val_loss: 0.0610\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0602\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0635 - val_loss: 0.0596\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0611 - val_loss: 0.0615\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0610 - val_loss: 0.0621\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0607 - val_loss: 0.0611\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0614 - val_loss: 0.0601\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0614 - val_loss: 0.0606\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0605 - val_loss: 0.0613\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0625 - val_loss: 0.0615\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0619 - val_loss: 0.0617\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0619 - val_loss: 0.0620\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0622 - val_loss: 0.0629\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0634 - val_loss: 0.0611\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0607\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0628 - val_loss: 0.0599\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0615 - val_loss: 0.0600\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0607 - val_loss: 0.0614\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0604 - val_loss: 0.0614\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0600 - val_loss: 0.0600\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0619 - val_loss: 0.0595\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0621\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0615\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0606\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0600 - val_loss: 0.0604\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0595 - val_loss: 0.0607\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0616\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0594 - val_loss: 0.0623\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0594 - val_loss: 0.0609\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0600 - val_loss: 0.0604\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0598 - val_loss: 0.0602\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0608 - val_loss: 0.0587\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:26:36,687]\u001b[0m Trial 15 finished with value: 0.0617800260366049 and parameters: {'learning_rate': 0.000764099416651172, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 134ms/step - loss: 0.1989 - val_loss: 0.1141\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1227 - val_loss: 0.0784\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1141 - val_loss: 0.0763\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1028 - val_loss: 0.0754\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0981 - val_loss: 0.0747\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0910 - val_loss: 0.0708\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0883 - val_loss: 0.0685\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0844 - val_loss: 0.0663\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0811 - val_loss: 0.0657\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0778 - val_loss: 0.0647\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0765 - val_loss: 0.0639\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0758 - val_loss: 0.0627\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0735 - val_loss: 0.0618\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0724 - val_loss: 0.0614\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0709 - val_loss: 0.0603\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0714 - val_loss: 0.0606\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0693 - val_loss: 0.0599\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0676 - val_loss: 0.0601\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0678 - val_loss: 0.0602\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0677 - val_loss: 0.0596\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0657 - val_loss: 0.0598\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0661 - val_loss: 0.0598\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0648 - val_loss: 0.0605\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0650 - val_loss: 0.0602\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0654 - val_loss: 0.0598\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0657 - val_loss: 0.0603\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0657 - val_loss: 0.0599\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0663 - val_loss: 0.0598\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0652 - val_loss: 0.0601\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0655 - val_loss: 0.0598\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0598\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0655 - val_loss: 0.0613\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0655 - val_loss: 0.0600\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0626 - val_loss: 0.0598\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0601\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0611\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0601\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0642 - val_loss: 0.0598\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0670 - val_loss: 0.0597\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0611\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0660 - val_loss: 0.0606\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0600\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0645 - val_loss: 0.0599\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0647 - val_loss: 0.0603\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0603\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0607\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0634 - val_loss: 0.0605\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0648 - val_loss: 0.0604\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0609\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0605\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0610\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0641 - val_loss: 0.0611\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0654 - val_loss: 0.0604\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0603\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0655 - val_loss: 0.0605\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0659 - val_loss: 0.0607\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0638 - val_loss: 0.0609\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0652 - val_loss: 0.0605\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0604\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0607\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0605\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0608\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0648 - val_loss: 0.0606\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0613\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0675 - val_loss: 0.0615\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0613\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0638 - val_loss: 0.0617\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0610\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0607\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0660 - val_loss: 0.0611\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0636 - val_loss: 0.0609\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0629 - val_loss: 0.0611\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0640 - val_loss: 0.0612\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0641 - val_loss: 0.0611\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0608\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0614\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0651 - val_loss: 0.0608\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0602\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0663 - val_loss: 0.0605\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0631 - val_loss: 0.0619\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0648 - val_loss: 0.0605\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0604\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0600\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0616\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0608\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0602\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0645 - val_loss: 0.0603\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0609\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0654 - val_loss: 0.0609\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0651 - val_loss: 0.0600\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0611\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0612\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0605\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0658 - val_loss: 0.0603\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0609\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0609\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0609\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0635 - val_loss: 0.0608\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0603\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 77). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:28:11,572]\u001b[0m Trial 16 finished with value: 0.06280246736142317 and parameters: {'learning_rate': 0.0004769469192790273, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'LeakyReLU', 'layers1': 1, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 167ms/step - loss: 0.1099 - val_loss: 0.0747\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0854 - val_loss: 0.0649\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0867 - val_loss: 0.0652\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0863 - val_loss: 0.0670\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0825 - val_loss: 0.0645\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0798 - val_loss: 0.0633\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0794 - val_loss: 0.0637\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0803 - val_loss: 0.0635\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0795 - val_loss: 0.0623\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0776 - val_loss: 0.0623\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0777 - val_loss: 0.0628\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0758 - val_loss: 0.0626\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0761 - val_loss: 0.0614\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0762 - val_loss: 0.0615\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0767 - val_loss: 0.0626\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0773 - val_loss: 0.0618\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0735 - val_loss: 0.0609\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0743 - val_loss: 0.0613\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0742 - val_loss: 0.0611\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0742 - val_loss: 0.0612\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0724 - val_loss: 0.0607\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0740 - val_loss: 0.0606\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0723 - val_loss: 0.0609\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0715 - val_loss: 0.0606\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0710 - val_loss: 0.0603\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0722 - val_loss: 0.0607\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0728 - val_loss: 0.0605\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0713 - val_loss: 0.0604\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0715 - val_loss: 0.0603\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0697 - val_loss: 0.0604\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0711 - val_loss: 0.0602\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0702 - val_loss: 0.0607\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0694 - val_loss: 0.0601\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0716 - val_loss: 0.0602\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0697 - val_loss: 0.0601\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0702 - val_loss: 0.0596\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0698 - val_loss: 0.0607\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0697 - val_loss: 0.0606\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0676 - val_loss: 0.0598\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0688 - val_loss: 0.0594\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0687 - val_loss: 0.0596\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0698 - val_loss: 0.0609\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0683 - val_loss: 0.0598\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0684 - val_loss: 0.0590\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0697 - val_loss: 0.0597\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0663 - val_loss: 0.0599\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0657 - val_loss: 0.0598\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0693 - val_loss: 0.0601\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0691 - val_loss: 0.0598\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0676 - val_loss: 0.0597\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0675 - val_loss: 0.0590\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0669 - val_loss: 0.0595\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0663 - val_loss: 0.0602\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0678 - val_loss: 0.0592\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0682 - val_loss: 0.0587\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0665 - val_loss: 0.0599\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0655 - val_loss: 0.0590\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0669 - val_loss: 0.0589\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0669 - val_loss: 0.0590\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0654 - val_loss: 0.0595\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0660 - val_loss: 0.0594\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0662 - val_loss: 0.0586\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0663 - val_loss: 0.0591\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0630 - val_loss: 0.0582\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0644 - val_loss: 0.0595\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0656 - val_loss: 0.0590\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0636 - val_loss: 0.0604\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0658 - val_loss: 0.0589\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0666 - val_loss: 0.0580\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0665 - val_loss: 0.0590\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0642 - val_loss: 0.0590\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0650 - val_loss: 0.0585\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0653 - val_loss: 0.0595\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0652 - val_loss: 0.0584\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0649 - val_loss: 0.0581\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0667 - val_loss: 0.0598\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0633 - val_loss: 0.0578\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0674 - val_loss: 0.0586\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0644 - val_loss: 0.0579\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0648 - val_loss: 0.0590\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0654 - val_loss: 0.0599\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0645 - val_loss: 0.0578\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0644 - val_loss: 0.0591\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0651 - val_loss: 0.0596\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0647 - val_loss: 0.0576\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0665 - val_loss: 0.0589\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0650 - val_loss: 0.0579\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0652 - val_loss: 0.0584\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0649 - val_loss: 0.0589\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0631 - val_loss: 0.0596\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0637 - val_loss: 0.0587\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0649 - val_loss: 0.0589\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0632 - val_loss: 0.0575\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0643 - val_loss: 0.0592\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0631 - val_loss: 0.0589\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0623 - val_loss: 0.0597\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0625 - val_loss: 0.0587\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0634 - val_loss: 0.0580\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0678 - val_loss: 0.0576\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0654 - val_loss: 0.0602\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0638 - val_loss: 0.0605\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0639 - val_loss: 0.0572\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0632 - val_loss: 0.0582\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0639 - val_loss: 0.0601\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0662 - val_loss: 0.0586\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0647 - val_loss: 0.0577\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0631 - val_loss: 0.0585\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0631 - val_loss: 0.0582\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0663 - val_loss: 0.0580\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0619 - val_loss: 0.0582\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0654 - val_loss: 0.0590\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0637 - val_loss: 0.0574\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0638 - val_loss: 0.0577\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0637 - val_loss: 0.0593\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0652 - val_loss: 0.0586\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0633 - val_loss: 0.0571\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0650 - val_loss: 0.0581\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0633 - val_loss: 0.0577\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0647 - val_loss: 0.0590\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0621 - val_loss: 0.0591\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0631 - val_loss: 0.0586\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0629 - val_loss: 0.0574\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0642 - val_loss: 0.0572\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0636 - val_loss: 0.0593\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0625 - val_loss: 0.0591\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0631 - val_loss: 0.0573\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0633 - val_loss: 0.0574\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0633 - val_loss: 0.0597\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0645 - val_loss: 0.0595\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0643 - val_loss: 0.0573\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0630 - val_loss: 0.0582\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0643 - val_loss: 0.0579\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0633 - val_loss: 0.0586\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0635 - val_loss: 0.0581\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0631 - val_loss: 0.0569\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0629 - val_loss: 0.0594\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0590\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0630 - val_loss: 0.0581\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0620 - val_loss: 0.0579\n",
            "2/2 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:30:59,404]\u001b[0m Trial 17 finished with value: 0.0624878005827534 and parameters: {'learning_rate': 0.000214494829115593, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 196ms/step - loss: 0.1349 - val_loss: 0.1107\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 160ms/step - loss: 0.1238 - val_loss: 0.1009\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.1166 - val_loss: 0.0928\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.1074 - val_loss: 0.0860\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 161ms/step - loss: 0.1009 - val_loss: 0.0804\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0943 - val_loss: 0.0763\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0897 - val_loss: 0.0734\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0907 - val_loss: 0.0713\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0923 - val_loss: 0.0697\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.0870 - val_loss: 0.0687\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0864 - val_loss: 0.0679\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0819 - val_loss: 0.0675\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0853 - val_loss: 0.0670\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0863 - val_loss: 0.0666\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0883 - val_loss: 0.0664\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0865 - val_loss: 0.0664\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0829 - val_loss: 0.0661\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0821 - val_loss: 0.0661\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0844 - val_loss: 0.0659\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0849 - val_loss: 0.0659\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0817 - val_loss: 0.0656\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0824 - val_loss: 0.0653\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0813 - val_loss: 0.0653\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0814 - val_loss: 0.0652\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0811 - val_loss: 0.0650\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0811 - val_loss: 0.0649\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 145ms/step - loss: 0.0832 - val_loss: 0.0650\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0803 - val_loss: 0.0650\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 144ms/step - loss: 0.0787 - val_loss: 0.0648\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0804 - val_loss: 0.0646\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 159ms/step - loss: 0.0788 - val_loss: 0.0645\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 165ms/step - loss: 0.0789 - val_loss: 0.0644\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 2s 179ms/step - loss: 0.0816 - val_loss: 0.0643\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 159ms/step - loss: 0.0790 - val_loss: 0.0644\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 145ms/step - loss: 0.0806 - val_loss: 0.0644\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0782 - val_loss: 0.0642\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0800 - val_loss: 0.0641\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0797 - val_loss: 0.0639\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0775 - val_loss: 0.0638\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0795 - val_loss: 0.0637\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0787 - val_loss: 0.0637\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 0.0795 - val_loss: 0.0636\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 148ms/step - loss: 0.0790 - val_loss: 0.0635\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.0796 - val_loss: 0.0633\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.0784 - val_loss: 0.0633\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0775 - val_loss: 0.0633\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.0754 - val_loss: 0.0633\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 0.0808 - val_loss: 0.0632\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0784 - val_loss: 0.0630\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0760 - val_loss: 0.0629\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0776 - val_loss: 0.0626\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0784 - val_loss: 0.0625\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0766 - val_loss: 0.0627\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0787 - val_loss: 0.0626\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0787 - val_loss: 0.0625\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 0.0757 - val_loss: 0.0624\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.0760 - val_loss: 0.0624\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 142ms/step - loss: 0.0790 - val_loss: 0.0625\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 145ms/step - loss: 0.0785 - val_loss: 0.0626\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0778 - val_loss: 0.0625\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0768 - val_loss: 0.0625\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0763 - val_loss: 0.0624\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0760 - val_loss: 0.0622\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0740 - val_loss: 0.0622\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.0761 - val_loss: 0.0622\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0762 - val_loss: 0.0622\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0776 - val_loss: 0.0622\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.0744 - val_loss: 0.0623\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0782 - val_loss: 0.0624\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0765 - val_loss: 0.0623\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0747 - val_loss: 0.0621\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0756 - val_loss: 0.0620\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0735 - val_loss: 0.0619\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0797 - val_loss: 0.0617\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0760 - val_loss: 0.0616\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0751 - val_loss: 0.0615\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 0.0745 - val_loss: 0.0616\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0770 - val_loss: 0.0616\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0765 - val_loss: 0.0616\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 0.0766 - val_loss: 0.0616\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0789 - val_loss: 0.0616\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 0.0730 - val_loss: 0.0616\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0777 - val_loss: 0.0616\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0754 - val_loss: 0.0616\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0760 - val_loss: 0.0616\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0751 - val_loss: 0.0616\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 0.0746 - val_loss: 0.0616\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.0732 - val_loss: 0.0615\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0758 - val_loss: 0.0616\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0749 - val_loss: 0.0616\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0760 - val_loss: 0.0614\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0751 - val_loss: 0.0613\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.0732 - val_loss: 0.0613\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.0766 - val_loss: 0.0612\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0744 - val_loss: 0.0611\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0759 - val_loss: 0.0611\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0725 - val_loss: 0.0612\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0760 - val_loss: 0.0611\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0743 - val_loss: 0.0612\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0737 - val_loss: 0.0611\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 74). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:33:12,242]\u001b[0m Trial 18 finished with value: 0.06302349286653905 and parameters: {'learning_rate': 3.7624386676822334e-05, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 1, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 136ms/step - loss: 0.1345 - val_loss: 0.0883\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1119 - val_loss: 0.0779\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.1023 - val_loss: 0.0752\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0936 - val_loss: 0.0686\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0872 - val_loss: 0.0658\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0799 - val_loss: 0.0634\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0780 - val_loss: 0.0612\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0738 - val_loss: 0.0600\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0719 - val_loss: 0.0595\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0680 - val_loss: 0.0589\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0697 - val_loss: 0.0590\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0681 - val_loss: 0.0584\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0674 - val_loss: 0.0582\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0669 - val_loss: 0.0583\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0673 - val_loss: 0.0580\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0664 - val_loss: 0.0583\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0668 - val_loss: 0.0581\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0659 - val_loss: 0.0584\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0647 - val_loss: 0.0585\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0664 - val_loss: 0.0584\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0654 - val_loss: 0.0586\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0648 - val_loss: 0.0585\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0650 - val_loss: 0.0587\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0586\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0650 - val_loss: 0.0584\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0654 - val_loss: 0.0586\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0657 - val_loss: 0.0584\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0650 - val_loss: 0.0584\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0650 - val_loss: 0.0582\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0650 - val_loss: 0.0582\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0652 - val_loss: 0.0583\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0627 - val_loss: 0.0582\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0586\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0645 - val_loss: 0.0581\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0623 - val_loss: 0.0587\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0652 - val_loss: 0.0582\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0651 - val_loss: 0.0581\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0663 - val_loss: 0.0584\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0658 - val_loss: 0.0589\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0581\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0648 - val_loss: 0.0583\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0634 - val_loss: 0.0584\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0630 - val_loss: 0.0583\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0652 - val_loss: 0.0587\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0648 - val_loss: 0.0584\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0652 - val_loss: 0.0583\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0636 - val_loss: 0.0579\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0656 - val_loss: 0.0582\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0648 - val_loss: 0.0585\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0586\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0648 - val_loss: 0.0584\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0582\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0582\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0639 - val_loss: 0.0583\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0581\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0668 - val_loss: 0.0582\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0580\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0626 - val_loss: 0.0582\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0644 - val_loss: 0.0583\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0635 - val_loss: 0.0584\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0640 - val_loss: 0.0587\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0631 - val_loss: 0.0587\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0638 - val_loss: 0.0586\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0580\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0640 - val_loss: 0.0580\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0579\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0579\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0579\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0586\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0581\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0585\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0635 - val_loss: 0.0582\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0623 - val_loss: 0.0581\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0638 - val_loss: 0.0582\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0647 - val_loss: 0.0582\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0586\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0588\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0584\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0580\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0640 - val_loss: 0.0580\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0627 - val_loss: 0.0581\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0621 - val_loss: 0.0579\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0624 - val_loss: 0.0579\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0623 - val_loss: 0.0581\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0620 - val_loss: 0.0577\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0578\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0584\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0638 - val_loss: 0.0581\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0650 - val_loss: 0.0581\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0586\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0583\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0588\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0593\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0613 - val_loss: 0.0582\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0621 - val_loss: 0.0587\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0625 - val_loss: 0.0583\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0582\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0583\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0628 - val_loss: 0.0581\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0616 - val_loss: 0.0579\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0622 - val_loss: 0.0581\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0582\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0582\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0584\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0584\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0619 - val_loss: 0.0584\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0586\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0625 - val_loss: 0.0590\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0624 - val_loss: 0.0582\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0614 - val_loss: 0.0582\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0632 - val_loss: 0.0580\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0577\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0614 - val_loss: 0.0581\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0630 - val_loss: 0.0584\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0587\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0583\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0577\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0632 - val_loss: 0.0577\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0606 - val_loss: 0.0579\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0617 - val_loss: 0.0582\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0615 - val_loss: 0.0584\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0584\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0615 - val_loss: 0.0581\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0579\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0591\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0585\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0583\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0589\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:35:38,379]\u001b[0m Trial 19 finished with value: 0.06192365791049718 and parameters: {'learning_rate': 0.0003406074824443018, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 1, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 6 with value: 0.06112011983093863.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 142ms/step - loss: 0.2568 - val_loss: 0.1676\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1414 - val_loss: 0.0853\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.1073 - val_loss: 0.0734\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0967 - val_loss: 0.0711\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0899 - val_loss: 0.0710\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0821 - val_loss: 0.0667\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0798 - val_loss: 0.0645\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0752 - val_loss: 0.0627\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0738 - val_loss: 0.0621\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0700 - val_loss: 0.0617\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0687 - val_loss: 0.0610\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0681 - val_loss: 0.0597\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0666 - val_loss: 0.0596\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0666 - val_loss: 0.0593\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0670 - val_loss: 0.0587\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0660 - val_loss: 0.0597\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0664 - val_loss: 0.0586\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0596\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0595\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0650 - val_loss: 0.0596\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0592\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0589\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0587\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0656 - val_loss: 0.0589\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0649 - val_loss: 0.0587\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0643 - val_loss: 0.0586\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0600\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0647 - val_loss: 0.0592\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0617 - val_loss: 0.0593\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0638 - val_loss: 0.0593\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0620 - val_loss: 0.0600\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0588\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0646 - val_loss: 0.0589\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0662 - val_loss: 0.0592\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0620 - val_loss: 0.0598\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0651 - val_loss: 0.0594\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0639 - val_loss: 0.0590\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0637 - val_loss: 0.0587\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0629 - val_loss: 0.0592\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0623 - val_loss: 0.0587\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0648 - val_loss: 0.0595\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0631 - val_loss: 0.0592\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0587\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0623 - val_loss: 0.0580\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0651 - val_loss: 0.0595\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0642 - val_loss: 0.0605\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0628 - val_loss: 0.0592\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0644 - val_loss: 0.0593\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0604 - val_loss: 0.0582\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0627 - val_loss: 0.0597\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0628 - val_loss: 0.0600\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0582\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0667 - val_loss: 0.0596\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0632 - val_loss: 0.0594\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0603\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0614 - val_loss: 0.0592\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0613 - val_loss: 0.0586\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0586\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0619 - val_loss: 0.0596\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0635 - val_loss: 0.0595\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0595\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0595\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0628 - val_loss: 0.0592\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0623 - val_loss: 0.0584\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0640 - val_loss: 0.0586\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0635 - val_loss: 0.0590\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0637 - val_loss: 0.0599\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0636 - val_loss: 0.0603\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0633 - val_loss: 0.0601\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0630 - val_loss: 0.0591\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0638 - val_loss: 0.0586\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0617 - val_loss: 0.0603\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0621 - val_loss: 0.0598\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0605 - val_loss: 0.0582\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0647 - val_loss: 0.0603\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0623 - val_loss: 0.0597\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0612 - val_loss: 0.0594\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0607 - val_loss: 0.0582\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0637 - val_loss: 0.0602\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0616 - val_loss: 0.0596\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0607 - val_loss: 0.0599\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0608 - val_loss: 0.0592\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0607 - val_loss: 0.0601\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0582\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0619 - val_loss: 0.0612\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0617\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0653 - val_loss: 0.0613\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0645 - val_loss: 0.0606\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0644 - val_loss: 0.0612\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0620 - val_loss: 0.0612\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0615 - val_loss: 0.0611\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0628 - val_loss: 0.0603\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0620 - val_loss: 0.0602\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0625 - val_loss: 0.0588\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0595 - val_loss: 0.0593\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0614 - val_loss: 0.0604\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0615 - val_loss: 0.0605\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0612 - val_loss: 0.0578\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0593\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0631 - val_loss: 0.0587\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0603 - val_loss: 0.0589\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0612 - val_loss: 0.0599\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0603\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0596\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0634 - val_loss: 0.0606\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0600 - val_loss: 0.0613\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0614 - val_loss: 0.0599\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0621 - val_loss: 0.0600\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0616 - val_loss: 0.0595\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0612 - val_loss: 0.0614\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0607 - val_loss: 0.0594\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0599 - val_loss: 0.0613\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0627 - val_loss: 0.0588\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0629 - val_loss: 0.0608\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0579\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0611 - val_loss: 0.0605\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0624 - val_loss: 0.0612\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0626 - val_loss: 0.0604\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0622 - val_loss: 0.0596\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0618 - val_loss: 0.0588\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0601\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0585 - val_loss: 0.0607\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0611 - val_loss: 0.0604\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0606 - val_loss: 0.0603\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0611\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0607 - val_loss: 0.0608\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0617 - val_loss: 0.0610\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0606 - val_loss: 0.0582\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0601\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0605 - val_loss: 0.0617\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0600\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0611 - val_loss: 0.0614\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:38:07,704]\u001b[0m Trial 20 finished with value: 0.060385942772235406 and parameters: {'learning_rate': 0.0005335152627838241, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 20 with value: 0.060385942772235406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 4s 149ms/step - loss: 0.2623 - val_loss: 0.1772\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.1507 - val_loss: 0.0933\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1078 - val_loss: 0.0745\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0998 - val_loss: 0.0709\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0921 - val_loss: 0.0716\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0838 - val_loss: 0.0681\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0813 - val_loss: 0.0652\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0766 - val_loss: 0.0632\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0749 - val_loss: 0.0625\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0706 - val_loss: 0.0617\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0695 - val_loss: 0.0613\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0686 - val_loss: 0.0600\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0671 - val_loss: 0.0599\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0669 - val_loss: 0.0597\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0670 - val_loss: 0.0589\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0661 - val_loss: 0.0599\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0663 - val_loss: 0.0587\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0596\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0652 - val_loss: 0.0590\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0650 - val_loss: 0.0596\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0593\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0594\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0591\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0648 - val_loss: 0.0588\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0649 - val_loss: 0.0589\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0640 - val_loss: 0.0586\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0653 - val_loss: 0.0586\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0585\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0652 - val_loss: 0.0587\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0598\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0646 - val_loss: 0.0587\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0588\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0588\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0584\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0584\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0645 - val_loss: 0.0584\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0662 - val_loss: 0.0587\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0653 - val_loss: 0.0589\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0637 - val_loss: 0.0585\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0636 - val_loss: 0.0582\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0648 - val_loss: 0.0582\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0632 - val_loss: 0.0584\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0625 - val_loss: 0.0589\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0620 - val_loss: 0.0584\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0624 - val_loss: 0.0584\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0647 - val_loss: 0.0590\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0590\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0588\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0575\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0650 - val_loss: 0.0588\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0643 - val_loss: 0.0600\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0629 - val_loss: 0.0596\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0603 - val_loss: 0.0579\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0618 - val_loss: 0.0581\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0623 - val_loss: 0.0592\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0634 - val_loss: 0.0583\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0627 - val_loss: 0.0594\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0628 - val_loss: 0.0577\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0669 - val_loss: 0.0587\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0632 - val_loss: 0.0594\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0642 - val_loss: 0.0607\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0614 - val_loss: 0.0593\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0615 - val_loss: 0.0589\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0637 - val_loss: 0.0582\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0618 - val_loss: 0.0589\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0587\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0587\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0621 - val_loss: 0.0580\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0638 - val_loss: 0.0583\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0638 - val_loss: 0.0590\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0635 - val_loss: 0.0591\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0596\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0633 - val_loss: 0.0600\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0592\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0586\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0583\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0617 - val_loss: 0.0598\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0620 - val_loss: 0.0596\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0603 - val_loss: 0.0579\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0600\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0624 - val_loss: 0.0603\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0596\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0600\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0607 - val_loss: 0.0585\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0635 - val_loss: 0.0597\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0615 - val_loss: 0.0593\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0608 - val_loss: 0.0600\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0607 - val_loss: 0.0596\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0607 - val_loss: 0.0595\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0616 - val_loss: 0.0585\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0604\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0618 - val_loss: 0.0616\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0653 - val_loss: 0.0611\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0607\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0642 - val_loss: 0.0612\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0619 - val_loss: 0.0612\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0610 - val_loss: 0.0612\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0628 - val_loss: 0.0589\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0627 - val_loss: 0.0601\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0616 - val_loss: 0.0606\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0595 - val_loss: 0.0603\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0611\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0613 - val_loss: 0.0604\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0613 - val_loss: 0.0584\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0598\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0591\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0600 - val_loss: 0.0591\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0610 - val_loss: 0.0602\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0607\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0594\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0638 - val_loss: 0.0601\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0602 - val_loss: 0.0619\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0611 - val_loss: 0.0606\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0600\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0612 - val_loss: 0.0602\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0607 - val_loss: 0.0616\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0604 - val_loss: 0.0604\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0598 - val_loss: 0.0617\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0621 - val_loss: 0.0598\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0628 - val_loss: 0.0609\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0618 - val_loss: 0.0572\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0613 - val_loss: 0.0616\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0622\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0624 - val_loss: 0.0614\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0598\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0589\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0607\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0585 - val_loss: 0.0615\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0618\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0605 - val_loss: 0.0610\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0612 - val_loss: 0.0615\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0604 - val_loss: 0.0611\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0612 - val_loss: 0.0617\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0604 - val_loss: 0.0596\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0611 - val_loss: 0.0612\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0600 - val_loss: 0.0616\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0608\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0614\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:40:35,690]\u001b[0m Trial 21 finished with value: 0.06028892838355286 and parameters: {'learning_rate': 0.0004871789363673086, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 21 with value: 0.06028892838355286.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 154ms/step - loss: 0.2562 - val_loss: 0.1664\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.1404 - val_loss: 0.0846\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.1073 - val_loss: 0.0733\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0964 - val_loss: 0.0711\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0897 - val_loss: 0.0709\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0819 - val_loss: 0.0665\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0795 - val_loss: 0.0644\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0750 - val_loss: 0.0626\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0736 - val_loss: 0.0620\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0698 - val_loss: 0.0615\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0686 - val_loss: 0.0609\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0680 - val_loss: 0.0596\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0666 - val_loss: 0.0597\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0665 - val_loss: 0.0593\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0670 - val_loss: 0.0587\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0660 - val_loss: 0.0597\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0664 - val_loss: 0.0586\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0639 - val_loss: 0.0596\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0650 - val_loss: 0.0597\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0593\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0589\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0656 - val_loss: 0.0589\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0648 - val_loss: 0.0588\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0652 - val_loss: 0.0589\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0645 - val_loss: 0.0600\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0647 - val_loss: 0.0593\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0593\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0638 - val_loss: 0.0592\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0599\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0644 - val_loss: 0.0589\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0661 - val_loss: 0.0592\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0620 - val_loss: 0.0597\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0653 - val_loss: 0.0592\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0638 - val_loss: 0.0590\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0587\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0588\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0634 - val_loss: 0.0591\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0630 - val_loss: 0.0594\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0623 - val_loss: 0.0587\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0648 - val_loss: 0.0595\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0592\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0588\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0588\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0580\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0594\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0603\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0592\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0605 - val_loss: 0.0581\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0584\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0628 - val_loss: 0.0597\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0589\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0597\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0629 - val_loss: 0.0577\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0667 - val_loss: 0.0590\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0632 - val_loss: 0.0593\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0606\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0617 - val_loss: 0.0594\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0615 - val_loss: 0.0585\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0640 - val_loss: 0.0584\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0596\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0636 - val_loss: 0.0596\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0619 - val_loss: 0.0592\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0633 - val_loss: 0.0593\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0592\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0640 - val_loss: 0.0587\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0636 - val_loss: 0.0593\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0637 - val_loss: 0.0600\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0637 - val_loss: 0.0599\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0635 - val_loss: 0.0599\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0591\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0639 - val_loss: 0.0588\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0583\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0594\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0605 - val_loss: 0.0579\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0583\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0598\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0624 - val_loss: 0.0601\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0592\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0598\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0610 - val_loss: 0.0581\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0635 - val_loss: 0.0596\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0614 - val_loss: 0.0589\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0609 - val_loss: 0.0595\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0609 - val_loss: 0.0593\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0608 - val_loss: 0.0596\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0617 - val_loss: 0.0581\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0606\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0624 - val_loss: 0.0611\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0652 - val_loss: 0.0605\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0607\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0607\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0619 - val_loss: 0.0613\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0613 - val_loss: 0.0605\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0605\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0601\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0595 - val_loss: 0.0593\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 0.0600\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0614 - val_loss: 0.0606\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0614 - val_loss: 0.0579\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0599\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0632 - val_loss: 0.0587\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0601 - val_loss: 0.0589\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0611 - val_loss: 0.0599\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0599\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0591\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0600\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0602 - val_loss: 0.0611\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0613 - val_loss: 0.0599\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0596\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0616 - val_loss: 0.0588\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0611 - val_loss: 0.0610\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0608 - val_loss: 0.0595\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0599 - val_loss: 0.0612\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0628 - val_loss: 0.0584\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0611\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0579\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0610 - val_loss: 0.0609\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0625 - val_loss: 0.0614\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0628 - val_loss: 0.0606\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0586\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0602\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0586 - val_loss: 0.0603\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0610 - val_loss: 0.0606\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0607 - val_loss: 0.0602\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0606\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0604 - val_loss: 0.0605\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0616 - val_loss: 0.0606\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0606 - val_loss: 0.0585\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0613 - val_loss: 0.0603\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0605 - val_loss: 0.0610\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0601\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0611 - val_loss: 0.0612\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:43:03,153]\u001b[0m Trial 22 finished with value: 0.06026837469723022 and parameters: {'learning_rate': 0.0005389909790080782, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 22 with value: 0.06026837469723022.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 147ms/step - loss: 0.2581 - val_loss: 0.1698\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.1434 - val_loss: 0.0870\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.1074 - val_loss: 0.0738\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0975 - val_loss: 0.0710\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0904 - val_loss: 0.0713\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0827 - val_loss: 0.0671\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0802 - val_loss: 0.0647\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0758 - val_loss: 0.0630\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0742 - val_loss: 0.0622\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0702 - val_loss: 0.0617\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0689 - val_loss: 0.0610\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0682 - val_loss: 0.0598\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0667 - val_loss: 0.0597\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0667 - val_loss: 0.0593\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0670 - val_loss: 0.0587\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0661 - val_loss: 0.0598\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0664 - val_loss: 0.0586\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0652 - val_loss: 0.0596\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0595\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0650 - val_loss: 0.0595\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0593\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0643 - val_loss: 0.0591\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0647 - val_loss: 0.0588\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0649 - val_loss: 0.0590\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0587\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0654 - val_loss: 0.0588\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0584\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0651 - val_loss: 0.0587\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0644 - val_loss: 0.0598\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0647 - val_loss: 0.0589\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0617 - val_loss: 0.0589\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0584\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0621 - val_loss: 0.0596\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0661 - val_loss: 0.0588\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0619 - val_loss: 0.0595\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0654 - val_loss: 0.0590\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0587\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0586\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0590\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0585\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0648 - val_loss: 0.0591\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0591\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0578\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0652 - val_loss: 0.0592\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0602\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0597\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0644 - val_loss: 0.0591\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0603 - val_loss: 0.0581\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0619 - val_loss: 0.0583\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0596\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0639 - val_loss: 0.0587\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0628 - val_loss: 0.0595\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0629 - val_loss: 0.0578\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0669 - val_loss: 0.0587\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0634 - val_loss: 0.0593\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0642 - val_loss: 0.0605\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0614 - val_loss: 0.0595\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0589\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0584\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0593\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0637 - val_loss: 0.0593\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0631 - val_loss: 0.0592\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0626 - val_loss: 0.0588\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0579\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0584\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0638 - val_loss: 0.0598\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0639 - val_loss: 0.0599\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0599\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0632 - val_loss: 0.0595\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0638 - val_loss: 0.0585\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0628 - val_loss: 0.0581\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0618 - val_loss: 0.0598\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0622 - val_loss: 0.0596\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0604 - val_loss: 0.0583\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0632 - val_loss: 0.0580\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0648 - val_loss: 0.0598\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0625 - val_loss: 0.0602\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0594\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0598\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0609 - val_loss: 0.0583\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0594\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0589\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0608 - val_loss: 0.0598\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0608 - val_loss: 0.0595\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0608 - val_loss: 0.0596\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0616 - val_loss: 0.0581\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0618 - val_loss: 0.0603\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0610\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0655 - val_loss: 0.0603\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0644 - val_loss: 0.0607\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0644 - val_loss: 0.0612\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0622 - val_loss: 0.0609\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0613 - val_loss: 0.0608\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0606\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0620 - val_loss: 0.0602\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0596 - val_loss: 0.0595\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0613 - val_loss: 0.0602\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0614 - val_loss: 0.0608\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0617 - val_loss: 0.0582\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0603\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0589\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0604 - val_loss: 0.0589\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0611 - val_loss: 0.0603\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0609\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0636 - val_loss: 0.0603\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0603 - val_loss: 0.0616\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0613 - val_loss: 0.0606\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0602\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0614 - val_loss: 0.0595\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0611 - val_loss: 0.0613\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0606 - val_loss: 0.0596\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0601 - val_loss: 0.0612\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0590\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0629 - val_loss: 0.0611\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0580\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0613 - val_loss: 0.0612\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0621\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0613\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0594\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0619 - val_loss: 0.0583\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0619 - val_loss: 0.0600\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0586 - val_loss: 0.0607\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0612 - val_loss: 0.0606\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0608 - val_loss: 0.0601\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0615 - val_loss: 0.0613\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0607 - val_loss: 0.0608\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0612\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0608 - val_loss: 0.0589\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0613 - val_loss: 0.0607\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0603 - val_loss: 0.0605\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0602\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0609 - val_loss: 0.0611\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:45:29,822]\u001b[0m Trial 23 finished with value: 0.06000529532369251 and parameters: {'learning_rate': 0.000522435086611151, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 139ms/step - loss: 0.2385 - val_loss: 0.1360\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.1214 - val_loss: 0.0758\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.1035 - val_loss: 0.0709\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0891 - val_loss: 0.0711\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0835 - val_loss: 0.0664\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0765 - val_loss: 0.0630\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0750 - val_loss: 0.0633\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0709 - val_loss: 0.0615\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0706 - val_loss: 0.0609\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0674 - val_loss: 0.0610\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0665 - val_loss: 0.0599\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0666 - val_loss: 0.0591\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0663 - val_loss: 0.0598\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0660 - val_loss: 0.0587\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0671 - val_loss: 0.0588\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0665 - val_loss: 0.0606\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0668 - val_loss: 0.0588\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0653 - val_loss: 0.0601\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0599\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0653 - val_loss: 0.0590\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0647 - val_loss: 0.0598\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0638 - val_loss: 0.0594\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0637 - val_loss: 0.0599\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0593\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0648 - val_loss: 0.0591\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0647 - val_loss: 0.0591\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0657 - val_loss: 0.0594\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0642 - val_loss: 0.0593\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0646 - val_loss: 0.0594\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0646 - val_loss: 0.0595\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0646 - val_loss: 0.0603\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0647 - val_loss: 0.0595\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0614 - val_loss: 0.0602\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0637 - val_loss: 0.0604\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0640 - val_loss: 0.0597\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0622 - val_loss: 0.0612\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0644 - val_loss: 0.0601\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0659 - val_loss: 0.0604\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0625 - val_loss: 0.0614\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0650 - val_loss: 0.0603\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0636 - val_loss: 0.0597\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0635 - val_loss: 0.0602\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0643 - val_loss: 0.0602\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0629 - val_loss: 0.0603\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0627 - val_loss: 0.0611\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0624 - val_loss: 0.0601\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0632 - val_loss: 0.0600\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0639 - val_loss: 0.0608\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0632 - val_loss: 0.0600\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0628 - val_loss: 0.0609\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0631 - val_loss: 0.0606\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0618 - val_loss: 0.0596\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0645 - val_loss: 0.0602\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0648 - val_loss: 0.0610\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0607\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0638 - val_loss: 0.0596\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0602 - val_loss: 0.0591\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0624 - val_loss: 0.0592\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0628 - val_loss: 0.0602\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0632 - val_loss: 0.0608\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0630 - val_loss: 0.0606\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0630 - val_loss: 0.0607\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0672 - val_loss: 0.0610\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0602\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0615\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0618 - val_loss: 0.0599\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0617 - val_loss: 0.0594\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0625 - val_loss: 0.0597\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0617 - val_loss: 0.0612\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0624 - val_loss: 0.0601\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0631 - val_loss: 0.0605\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0623 - val_loss: 0.0600\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0619 - val_loss: 0.0594\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0593\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0600\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0638 - val_loss: 0.0596\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0605\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0600\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0597\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0628 - val_loss: 0.0598\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0619 - val_loss: 0.0600\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0625 - val_loss: 0.0598\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0611 - val_loss: 0.0594\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0604\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0607\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0617 - val_loss: 0.0602\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0593\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0601 - val_loss: 0.0589\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0598\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0614 - val_loss: 0.0610\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0607 - val_loss: 0.0602\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0608 - val_loss: 0.0600\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0610 - val_loss: 0.0592\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0615 - val_loss: 0.0586\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0600\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0627 - val_loss: 0.0622\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0659 - val_loss: 0.0631\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0636 - val_loss: 0.0599\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0647 - val_loss: 0.0610\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0620 - val_loss: 0.0608\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0611 - val_loss: 0.0601\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0585\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0610\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0608\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0607 - val_loss: 0.0597\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0616 - val_loss: 0.0604\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0600\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0612 - val_loss: 0.0586\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0624 - val_loss: 0.0596\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0607 - val_loss: 0.0600\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0626 - val_loss: 0.0600\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0585\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0619 - val_loss: 0.0601\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0631 - val_loss: 0.0610\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0599 - val_loss: 0.0599\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0614 - val_loss: 0.0594\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0616 - val_loss: 0.0594\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0599\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0604 - val_loss: 0.0603\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0603 - val_loss: 0.0597\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0599 - val_loss: 0.0605\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0625 - val_loss: 0.0592\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0629 - val_loss: 0.0603\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0581\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0608 - val_loss: 0.0603\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0617\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0627 - val_loss: 0.0606\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0611 - val_loss: 0.0581\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0620 - val_loss: 0.0581\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0620 - val_loss: 0.0608\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0588 - val_loss: 0.0599\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0614 - val_loss: 0.0597\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0601 - val_loss: 0.0606\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0618 - val_loss: 0.0604\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0597 - val_loss: 0.0600\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0608 - val_loss: 0.0604\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0596 - val_loss: 0.0585\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0607\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0599 - val_loss: 0.0615\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0616 - val_loss: 0.0603\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0607 - val_loss: 0.0615\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:48:02,593]\u001b[0m Trial 24 finished with value: 0.06050282274723499 and parameters: {'learning_rate': 0.0006999539231930655, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 146ms/step - loss: 0.2597 - val_loss: 0.1728\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1462 - val_loss: 0.0893\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1075 - val_loss: 0.0741\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0984 - val_loss: 0.0709\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0910 - val_loss: 0.0714\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0829 - val_loss: 0.0674\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0804 - val_loss: 0.0647\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0757 - val_loss: 0.0628\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0742 - val_loss: 0.0621\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0700 - val_loss: 0.0616\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0690 - val_loss: 0.0610\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0682 - val_loss: 0.0599\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0668 - val_loss: 0.0598\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0667 - val_loss: 0.0595\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0670 - val_loss: 0.0588\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0660 - val_loss: 0.0599\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0662 - val_loss: 0.0586\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0596\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0652 - val_loss: 0.0589\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0650 - val_loss: 0.0596\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0645 - val_loss: 0.0592\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0643 - val_loss: 0.0590\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0647 - val_loss: 0.0588\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0649 - val_loss: 0.0589\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0653 - val_loss: 0.0587\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0645 - val_loss: 0.0585\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0652 - val_loss: 0.0587\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0645 - val_loss: 0.0597\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0646 - val_loss: 0.0588\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0616 - val_loss: 0.0589\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0588\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0620 - val_loss: 0.0596\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0584\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0661 - val_loss: 0.0588\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0619 - val_loss: 0.0592\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0652 - val_loss: 0.0588\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0638 - val_loss: 0.0586\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0635 - val_loss: 0.0584\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0648 - val_loss: 0.0583\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0585\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0625 - val_loss: 0.0589\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0585\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0592\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0591\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0587\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0625 - val_loss: 0.0584\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0621 - val_loss: 0.0575\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0649 - val_loss: 0.0591\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0642 - val_loss: 0.0602\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0627 - val_loss: 0.0594\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0642 - val_loss: 0.0588\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0604 - val_loss: 0.0579\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0618 - val_loss: 0.0585\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0626 - val_loss: 0.0596\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0637 - val_loss: 0.0585\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0627 - val_loss: 0.0594\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0629 - val_loss: 0.0576\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0668 - val_loss: 0.0585\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0593\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0644 - val_loss: 0.0604\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0613 - val_loss: 0.0592\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0615 - val_loss: 0.0584\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0619 - val_loss: 0.0590\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0637 - val_loss: 0.0591\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0590\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0625 - val_loss: 0.0587\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0579\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0638 - val_loss: 0.0590\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0637 - val_loss: 0.0593\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0638 - val_loss: 0.0598\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0633 - val_loss: 0.0597\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0638 - val_loss: 0.0582\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0625 - val_loss: 0.0580\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0618 - val_loss: 0.0597\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0603 - val_loss: 0.0579\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0629 - val_loss: 0.0579\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0650 - val_loss: 0.0598\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0626 - val_loss: 0.0603\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0622 - val_loss: 0.0592\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0609 - val_loss: 0.0593\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0608 - val_loss: 0.0578\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0638 - val_loss: 0.0597\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0617 - val_loss: 0.0594\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0611 - val_loss: 0.0593\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0608 - val_loss: 0.0591\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0608 - val_loss: 0.0592\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0617 - val_loss: 0.0585\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0616 - val_loss: 0.0598\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0618 - val_loss: 0.0609\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0651 - val_loss: 0.0603\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0642 - val_loss: 0.0605\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0642 - val_loss: 0.0608\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0619 - val_loss: 0.0611\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0612 - val_loss: 0.0607\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0628 - val_loss: 0.0601\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0617 - val_loss: 0.0603\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0621 - val_loss: 0.0587\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0592 - val_loss: 0.0594\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0613 - val_loss: 0.0604\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0613 - val_loss: 0.0606\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0611 - val_loss: 0.0575\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0627 - val_loss: 0.0581\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0600 - val_loss: 0.0586\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0609 - val_loss: 0.0596\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0628 - val_loss: 0.0600\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0590\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0620 - val_loss: 0.0591\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0635 - val_loss: 0.0605\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0603 - val_loss: 0.0618\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0613 - val_loss: 0.0601\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0615 - val_loss: 0.0592\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0609 - val_loss: 0.0612\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0605 - val_loss: 0.0595\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0599 - val_loss: 0.0614\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0623 - val_loss: 0.0590\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0630 - val_loss: 0.0608\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0575\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0613\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0623 - val_loss: 0.0619\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0623 - val_loss: 0.0608\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0593\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0615 - val_loss: 0.0581\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0618 - val_loss: 0.0601\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0584 - val_loss: 0.0604\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0614 - val_loss: 0.0604\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0605 - val_loss: 0.0607\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0614 - val_loss: 0.0611\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0603 - val_loss: 0.0603\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0617 - val_loss: 0.0611\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0607 - val_loss: 0.0586\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0609 - val_loss: 0.0606\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0599 - val_loss: 0.0607\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0615 - val_loss: 0.0603\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0609 - val_loss: 0.0610\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:50:36,072]\u001b[0m Trial 25 finished with value: 0.06018717694693776 and parameters: {'learning_rate': 0.0005087890456388174, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 163ms/step - loss: 0.2556 - val_loss: 0.1656\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.1396 - val_loss: 0.0840\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.1073 - val_loss: 0.0732\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0961 - val_loss: 0.0711\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0895 - val_loss: 0.0708\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0817 - val_loss: 0.0664\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0793 - val_loss: 0.0643\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0748 - val_loss: 0.0626\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0735 - val_loss: 0.0619\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0698 - val_loss: 0.0615\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0686 - val_loss: 0.0609\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0679 - val_loss: 0.0596\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0665 - val_loss: 0.0596\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0665 - val_loss: 0.0593\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0670 - val_loss: 0.0587\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0660 - val_loss: 0.0598\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0664 - val_loss: 0.0586\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0596\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0596\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0650 - val_loss: 0.0597\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0594\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0594\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0648 - val_loss: 0.0590\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0650 - val_loss: 0.0591\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0656 - val_loss: 0.0590\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0648 - val_loss: 0.0588\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0587\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0645 - val_loss: 0.0601\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0592\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0592\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0592\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0601\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0646 - val_loss: 0.0589\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0662 - val_loss: 0.0592\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0620 - val_loss: 0.0598\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0652 - val_loss: 0.0593\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0636 - val_loss: 0.0585\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0593\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0631 - val_loss: 0.0591\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0588\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0640 - val_loss: 0.0585\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0578\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0650 - val_loss: 0.0594\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0603\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0629 - val_loss: 0.0595\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0643 - val_loss: 0.0590\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0603 - val_loss: 0.0579\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0620 - val_loss: 0.0582\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0628 - val_loss: 0.0596\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0588\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0594\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0629 - val_loss: 0.0577\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0667 - val_loss: 0.0589\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0632 - val_loss: 0.0592\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0643 - val_loss: 0.0605\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0614 - val_loss: 0.0591\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0615 - val_loss: 0.0584\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0640 - val_loss: 0.0582\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0619 - val_loss: 0.0592\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0637 - val_loss: 0.0592\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0591\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0631 - val_loss: 0.0591\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0623 - val_loss: 0.0580\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0640 - val_loss: 0.0586\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0637 - val_loss: 0.0593\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0637 - val_loss: 0.0598\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0634 - val_loss: 0.0598\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0631 - val_loss: 0.0590\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0640 - val_loss: 0.0585\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0581\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0618 - val_loss: 0.0598\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0606 - val_loss: 0.0580\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0630 - val_loss: 0.0582\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0646 - val_loss: 0.0598\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0623 - val_loss: 0.0597\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0624 - val_loss: 0.0590\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0613 - val_loss: 0.0596\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0607 - val_loss: 0.0579\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0637 - val_loss: 0.0599\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0617 - val_loss: 0.0596\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0609 - val_loss: 0.0595\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0608 - val_loss: 0.0592\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0608 - val_loss: 0.0596\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0616 - val_loss: 0.0581\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0618 - val_loss: 0.0607\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0609\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0653 - val_loss: 0.0604\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0607\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0608\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0620 - val_loss: 0.0608\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0613 - val_loss: 0.0605\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0587\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0628 - val_loss: 0.0608\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0620 - val_loss: 0.0603\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0596 - val_loss: 0.0593\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0614 - val_loss: 0.0602\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0615 - val_loss: 0.0605\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0614 - val_loss: 0.0578\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0591\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0630 - val_loss: 0.0586\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0603 - val_loss: 0.0587\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0611 - val_loss: 0.0599\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0602\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0621 - val_loss: 0.0591\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0623 - val_loss: 0.0594\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0636 - val_loss: 0.0601\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0603 - val_loss: 0.0613\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0614 - val_loss: 0.0603\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0596\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0616 - val_loss: 0.0591\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0611 - val_loss: 0.0613\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0608 - val_loss: 0.0600\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0600 - val_loss: 0.0610\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0633 - val_loss: 0.0613\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0621 - val_loss: 0.0580\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0611 - val_loss: 0.0611\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0624 - val_loss: 0.0617\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0630 - val_loss: 0.0609\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0619 - val_loss: 0.0586\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0603\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0587 - val_loss: 0.0605\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0612 - val_loss: 0.0608\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0607 - val_loss: 0.0602\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0615 - val_loss: 0.0609\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0607 - val_loss: 0.0608\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0608\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0606 - val_loss: 0.0582\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0615 - val_loss: 0.0599\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0607 - val_loss: 0.0614\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0611 - val_loss: 0.0614\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:53:06,121]\u001b[0m Trial 26 finished with value: 0.06037283386720821 and parameters: {'learning_rate': 0.0005433808578059376, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 135ms/step - loss: 0.2693 - val_loss: 0.1890\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.1640 - val_loss: 0.1068\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1105 - val_loss: 0.0759\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1027 - val_loss: 0.0718\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0962 - val_loss: 0.0720\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0865 - val_loss: 0.0704\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0843 - val_loss: 0.0672\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0796 - val_loss: 0.0643\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0775 - val_loss: 0.0634\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0730 - val_loss: 0.0628\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0716 - val_loss: 0.0619\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0702 - val_loss: 0.0605\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0683 - val_loss: 0.0602\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0680 - val_loss: 0.0599\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0676 - val_loss: 0.0590\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0665 - val_loss: 0.0598\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0664 - val_loss: 0.0586\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0653 - val_loss: 0.0595\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0654 - val_loss: 0.0589\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0650 - val_loss: 0.0595\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0592\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0593\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0591\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0588\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0655 - val_loss: 0.0587\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0652 - val_loss: 0.0587\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0597\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0618 - val_loss: 0.0589\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0585\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0622 - val_loss: 0.0596\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0645 - val_loss: 0.0585\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0664 - val_loss: 0.0586\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0656 - val_loss: 0.0591\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0639 - val_loss: 0.0587\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0585\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0649 - val_loss: 0.0585\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0635 - val_loss: 0.0585\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0584\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0649 - val_loss: 0.0589\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0647 - val_loss: 0.0589\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0584\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0628 - val_loss: 0.0579\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0656 - val_loss: 0.0585\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0634 - val_loss: 0.0593\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0613 - val_loss: 0.0582\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0582\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0626 - val_loss: 0.0589\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0637 - val_loss: 0.0585\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0592\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0636 - val_loss: 0.0581\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0669 - val_loss: 0.0584\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0642 - val_loss: 0.0588\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0646 - val_loss: 0.0596\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0619 - val_loss: 0.0588\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0582\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0591\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0585\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0585\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0631 - val_loss: 0.0581\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0578\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0638 - val_loss: 0.0582\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0638 - val_loss: 0.0584\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0586\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0639 - val_loss: 0.0589\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0635 - val_loss: 0.0588\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0586\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0639 - val_loss: 0.0585\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0582\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0589\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0589\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0609 - val_loss: 0.0580\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0633 - val_loss: 0.0578\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0629 - val_loss: 0.0594\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0588\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0586\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0618 - val_loss: 0.0577\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0636 - val_loss: 0.0586\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0623 - val_loss: 0.0584\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0616 - val_loss: 0.0585\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0617 - val_loss: 0.0584\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0614 - val_loss: 0.0584\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0583\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0587\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0626 - val_loss: 0.0594\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0653 - val_loss: 0.0589\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0596\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0626 - val_loss: 0.0596\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0615 - val_loss: 0.0597\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0630 - val_loss: 0.0581\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0587\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0590\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0631 - val_loss: 0.0585\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0602 - val_loss: 0.0579\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0586\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0617 - val_loss: 0.0594\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0621 - val_loss: 0.0573\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0578\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0627 - val_loss: 0.0585\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0610 - val_loss: 0.0577\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0611 - val_loss: 0.0590\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0591\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0582\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0636 - val_loss: 0.0587\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0608 - val_loss: 0.0599\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0614 - val_loss: 0.0589\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0581\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0612 - val_loss: 0.0594\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0613 - val_loss: 0.0584\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0608 - val_loss: 0.0594\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0633 - val_loss: 0.0581\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0632 - val_loss: 0.0592\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0570\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0611 - val_loss: 0.0588\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0628 - val_loss: 0.0600\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0626 - val_loss: 0.0596\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0588\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0576\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0585\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0591 - val_loss: 0.0597\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0616 - val_loss: 0.0600\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0609 - val_loss: 0.0591\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0618 - val_loss: 0.0598\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0604 - val_loss: 0.0594\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0616 - val_loss: 0.0598\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0610 - val_loss: 0.0577\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0591\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0609 - val_loss: 0.0601\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0592\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0613 - val_loss: 0.0601\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:55:33,000]\u001b[0m Trial 27 finished with value: 0.060633639855959195 and parameters: {'learning_rate': 0.0004304609221735288, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 138ms/step - loss: 0.1673 - val_loss: 0.0820\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1031 - val_loss: 0.0767\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0886 - val_loss: 0.0671\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0759 - val_loss: 0.0609\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0698 - val_loss: 0.0601\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0671 - val_loss: 0.0582\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0671 - val_loss: 0.0579\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0657 - val_loss: 0.0589\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0659 - val_loss: 0.0595\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0657 - val_loss: 0.0584\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0644 - val_loss: 0.0579\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0648 - val_loss: 0.0580\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0658 - val_loss: 0.0584\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0656 - val_loss: 0.0578\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0655 - val_loss: 0.0577\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0655 - val_loss: 0.0594\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0666 - val_loss: 0.0584\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0664 - val_loss: 0.0582\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0658 - val_loss: 0.0585\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0582\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0647 - val_loss: 0.0585\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0647 - val_loss: 0.0579\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0637 - val_loss: 0.0578\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0580\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0643 - val_loss: 0.0580\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0578\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0583\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0653 - val_loss: 0.0580\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0575\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0648 - val_loss: 0.0586\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0644 - val_loss: 0.0585\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0661 - val_loss: 0.0579\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0579\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0639 - val_loss: 0.0578\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0634 - val_loss: 0.0577\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0583\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0586\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0660 - val_loss: 0.0584\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0619 - val_loss: 0.0582\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0589\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0636 - val_loss: 0.0579\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0578\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0582\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0584\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0614 - val_loss: 0.0582\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0614 - val_loss: 0.0580\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0588\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0641 - val_loss: 0.0581\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0631 - val_loss: 0.0575\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0618 - val_loss: 0.0582\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0578\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 0.0574\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0649 - val_loss: 0.0589\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0639 - val_loss: 0.0597\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0628 - val_loss: 0.0589\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0638 - val_loss: 0.0580\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0598 - val_loss: 0.0575\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0619 - val_loss: 0.0581\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0582\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0574\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0573\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0670 - val_loss: 0.0579\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0593\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0645 - val_loss: 0.0611\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0590\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0585\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0637 - val_loss: 0.0584\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0593\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0613 - val_loss: 0.0598\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0597\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0580\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0641 - val_loss: 0.0587\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0595\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0638 - val_loss: 0.0594\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0602\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0636 - val_loss: 0.0599\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0635 - val_loss: 0.0599\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0589\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0589\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0602\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0626 - val_loss: 0.0596\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0603 - val_loss: 0.0581\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0629 - val_loss: 0.0584\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0650 - val_loss: 0.0602\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0607\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0601\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0610 - val_loss: 0.0596\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0604 - val_loss: 0.0583\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0636 - val_loss: 0.0602\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0595\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0609 - val_loss: 0.0601\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0608 - val_loss: 0.0597\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0608 - val_loss: 0.0599\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0619 - val_loss: 0.0574\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0621\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0627\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0652 - val_loss: 0.0608\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0657 - val_loss: 0.0592\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0647 - val_loss: 0.0620\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0618 - val_loss: 0.0626\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0613\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0624 - val_loss: 0.0597\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0613\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0615 - val_loss: 0.0619\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0596\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0592 - val_loss: 0.0622\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0614 - val_loss: 0.0618\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0602\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0611 - val_loss: 0.0597\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0606\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0597 - val_loss: 0.0604\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0611 - val_loss: 0.0612\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0615\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0615 - val_loss: 0.0595\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0605\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0632 - val_loss: 0.0612\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0597 - val_loss: 0.0619\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0626\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0607\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0608 - val_loss: 0.0617\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0607 - val_loss: 0.0622\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0604 - val_loss: 0.0614\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0591 - val_loss: 0.0635\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0617\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0628 - val_loss: 0.0618\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0586\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0607 - val_loss: 0.0648\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0622 - val_loss: 0.0623\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0614\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0591\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0617 - val_loss: 0.0612\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0616 - val_loss: 0.0642\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0576 - val_loss: 0.0609\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0614 - val_loss: 0.0615\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0599 - val_loss: 0.0635\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0622\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0602 - val_loss: 0.0624\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0609 - val_loss: 0.0631\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0601 - val_loss: 0.0607\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0604 - val_loss: 0.0642\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0593 - val_loss: 0.0603\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0615 - val_loss: 0.0643\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0613 - val_loss: 0.0611\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 15:57:52,535]\u001b[0m Trial 28 finished with value: 0.0605476770794937 and parameters: {'learning_rate': 0.000688950510246715, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 139ms/step - loss: 0.2795 - val_loss: 0.2350\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.2310 - val_loss: 0.1950\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1881 - val_loss: 0.1527\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1448 - val_loss: 0.1036\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1107 - val_loss: 0.0768\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1002 - val_loss: 0.0724\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0967 - val_loss: 0.0736\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0903 - val_loss: 0.0709\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0866 - val_loss: 0.0674\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0809 - val_loss: 0.0662\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0788 - val_loss: 0.0651\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0760 - val_loss: 0.0627\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0729 - val_loss: 0.0616\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0717 - val_loss: 0.0609\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0701 - val_loss: 0.0598\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0690 - val_loss: 0.0601\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0681 - val_loss: 0.0589\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0664 - val_loss: 0.0597\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0655 - val_loss: 0.0598\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0665 - val_loss: 0.0591\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0653 - val_loss: 0.0595\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0649 - val_loss: 0.0594\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0590\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0657 - val_loss: 0.0594\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0662 - val_loss: 0.0588\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0652 - val_loss: 0.0587\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0651 - val_loss: 0.0586\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0653 - val_loss: 0.0588\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0602\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0591\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0646 - val_loss: 0.0589\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0623 - val_loss: 0.0604\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0655 - val_loss: 0.0593\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0648 - val_loss: 0.0590\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0668 - val_loss: 0.0589\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0597\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0657 - val_loss: 0.0602\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0589\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0649 - val_loss: 0.0592\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0632 - val_loss: 0.0592\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0638 - val_loss: 0.0591\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0654 - val_loss: 0.0595\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0649 - val_loss: 0.0592\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0645 - val_loss: 0.0594\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0600\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0635 - val_loss: 0.0585\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0659 - val_loss: 0.0591\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0651 - val_loss: 0.0593\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0638 - val_loss: 0.0592\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0651 - val_loss: 0.0591\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0593\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0634 - val_loss: 0.0592\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0648 - val_loss: 0.0592\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0591\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0590\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0668 - val_loss: 0.0591\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0592\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0604\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0591\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0628 - val_loss: 0.0591\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0646 - val_loss: 0.0593\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0631 - val_loss: 0.0593\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0595\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0588\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0636 - val_loss: 0.0588\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0586\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0651 - val_loss: 0.0587\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0597\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0588\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0641 - val_loss: 0.0585\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0633 - val_loss: 0.0594\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0635 - val_loss: 0.0587\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0589\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0592\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0652 - val_loss: 0.0588\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0598\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0585\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0630 - val_loss: 0.0592\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0588\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0623 - val_loss: 0.0588\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0588\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0583\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0633 - val_loss: 0.0584\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0590\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0654 - val_loss: 0.0598\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0588\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0632 - val_loss: 0.0592\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0592\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0638 - val_loss: 0.0586\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0597\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0591\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0586\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0611 - val_loss: 0.0583\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0589\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0623 - val_loss: 0.0590\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0586\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0583\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0582\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0577\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0617 - val_loss: 0.0581\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0633 - val_loss: 0.0589\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0586\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0589\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0585\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0630 - val_loss: 0.0586\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0620 - val_loss: 0.0591\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0626 - val_loss: 0.0592\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0588\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0582\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0586\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0579\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0582\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0592\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0633 - val_loss: 0.0586\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0625 - val_loss: 0.0581\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0583\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0604 - val_loss: 0.0585\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0588\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0611 - val_loss: 0.0587\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 0.0584\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0594\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0621 - val_loss: 0.0598\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0635 - val_loss: 0.0597\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0632 - val_loss: 0.0598\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:00:16,121]\u001b[0m Trial 29 finished with value: 0.061067948439516184 and parameters: {'learning_rate': 0.000334864988034125, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 143ms/step - loss: 0.2527 - val_loss: 0.1603\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1353 - val_loss: 0.0812\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.1070 - val_loss: 0.0724\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0944 - val_loss: 0.0712\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0884 - val_loss: 0.0701\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0807 - val_loss: 0.0656\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0784 - val_loss: 0.0639\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0739 - val_loss: 0.0623\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0729 - val_loss: 0.0616\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0691 - val_loss: 0.0612\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0681 - val_loss: 0.0604\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0676 - val_loss: 0.0592\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0664 - val_loss: 0.0595\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0665 - val_loss: 0.0590\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0671 - val_loss: 0.0586\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0662 - val_loss: 0.0601\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0666 - val_loss: 0.0587\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0597\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0596\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0593\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0594\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0590\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0642 - val_loss: 0.0587\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0657 - val_loss: 0.0589\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0652 - val_loss: 0.0590\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0644 - val_loss: 0.0600\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0649 - val_loss: 0.0592\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0593\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0591\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0643 - val_loss: 0.0587\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0620 - val_loss: 0.0601\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0647 - val_loss: 0.0590\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0661 - val_loss: 0.0594\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0598\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0651 - val_loss: 0.0592\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0637 - val_loss: 0.0587\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0585\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0649 - val_loss: 0.0586\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0588\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0627 - val_loss: 0.0592\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0621 - val_loss: 0.0583\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0649 - val_loss: 0.0593\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0593\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0631 - val_loss: 0.0590\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0640 - val_loss: 0.0584\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0622 - val_loss: 0.0579\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0650 - val_loss: 0.0592\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0642 - val_loss: 0.0602\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0629 - val_loss: 0.0591\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0642 - val_loss: 0.0589\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0604 - val_loss: 0.0579\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0619 - val_loss: 0.0580\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0628 - val_loss: 0.0594\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0642 - val_loss: 0.0588\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0628 - val_loss: 0.0592\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0631 - val_loss: 0.0577\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0667 - val_loss: 0.0592\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0635 - val_loss: 0.0593\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0602\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0615 - val_loss: 0.0591\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0616 - val_loss: 0.0585\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0640 - val_loss: 0.0582\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0591\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0637 - val_loss: 0.0594\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0591\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0585\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0625 - val_loss: 0.0581\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0588\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0638 - val_loss: 0.0592\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0598\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0587\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0641 - val_loss: 0.0583\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0622 - val_loss: 0.0589\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0603 - val_loss: 0.0577\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0578\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0645 - val_loss: 0.0593\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0624 - val_loss: 0.0593\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0596\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0608 - val_loss: 0.0581\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0638 - val_loss: 0.0596\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0609 - val_loss: 0.0595\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0608 - val_loss: 0.0591\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0610 - val_loss: 0.0593\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0580\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0619 - val_loss: 0.0602\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0623 - val_loss: 0.0613\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0656 - val_loss: 0.0609\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0647 - val_loss: 0.0599\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0607\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0612\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0607\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0584\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0629 - val_loss: 0.0603\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0602\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0622 - val_loss: 0.0589\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0595 - val_loss: 0.0592\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0614 - val_loss: 0.0600\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0616 - val_loss: 0.0601\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0615 - val_loss: 0.0575\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0628 - val_loss: 0.0589\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0604 - val_loss: 0.0585\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0612 - val_loss: 0.0597\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0630 - val_loss: 0.0600\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0624 - val_loss: 0.0592\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0638 - val_loss: 0.0603\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0603 - val_loss: 0.0614\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0615 - val_loss: 0.0600\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0595\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0593\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0611 - val_loss: 0.0612\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0610 - val_loss: 0.0596\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0601 - val_loss: 0.0609\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0627 - val_loss: 0.0585\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0633 - val_loss: 0.0607\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0578\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0613 - val_loss: 0.0609\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0626 - val_loss: 0.0614\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0628 - val_loss: 0.0605\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0587\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0605\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0587 - val_loss: 0.0602\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0612 - val_loss: 0.0605\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0607 - val_loss: 0.0606\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0615 - val_loss: 0.0604\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0607 - val_loss: 0.0606\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0620 - val_loss: 0.0610\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0609 - val_loss: 0.0584\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0614 - val_loss: 0.0602\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0605 - val_loss: 0.0605\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0617 - val_loss: 0.0600\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0612 - val_loss: 0.0610\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:02:45,696]\u001b[0m Trial 30 finished with value: 0.06009188676303226 and parameters: {'learning_rate': 0.0005691255886725072, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 145ms/step - loss: 0.2519 - val_loss: 0.1589\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.1342 - val_loss: 0.0805\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.1068 - val_loss: 0.0722\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0939 - val_loss: 0.0713\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0881 - val_loss: 0.0701\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0805 - val_loss: 0.0655\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0782 - val_loss: 0.0639\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0737 - val_loss: 0.0624\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0726 - val_loss: 0.0619\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0692 - val_loss: 0.0613\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0680 - val_loss: 0.0607\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0676 - val_loss: 0.0595\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0664 - val_loss: 0.0595\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0664 - val_loss: 0.0590\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0671 - val_loss: 0.0587\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0662 - val_loss: 0.0601\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0667 - val_loss: 0.0588\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0650 - val_loss: 0.0596\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0595\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0590\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0589\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0658 - val_loss: 0.0590\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0648 - val_loss: 0.0589\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0588\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0652 - val_loss: 0.0591\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0644 - val_loss: 0.0600\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0650 - val_loss: 0.0593\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0594\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0594\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0590\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0605\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0649 - val_loss: 0.0593\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0665 - val_loss: 0.0595\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0603\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0597\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0640 - val_loss: 0.0590\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0590\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0637 - val_loss: 0.0593\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0598\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0592\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0630 - val_loss: 0.0591\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0651 - val_loss: 0.0598\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0591\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0590\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0623 - val_loss: 0.0582\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0651 - val_loss: 0.0595\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0608\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0632 - val_loss: 0.0595\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0605 - val_loss: 0.0582\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0621 - val_loss: 0.0587\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0627 - val_loss: 0.0599\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0592\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0627 - val_loss: 0.0594\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0585\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0665 - val_loss: 0.0608\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0601\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0637 - val_loss: 0.0607\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0616 - val_loss: 0.0597\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0610 - val_loss: 0.0594\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0640 - val_loss: 0.0590\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0619 - val_loss: 0.0600\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0600\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0616 - val_loss: 0.0600\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0605\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0631 - val_loss: 0.0596\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0590\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0634 - val_loss: 0.0596\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0637 - val_loss: 0.0607\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0635 - val_loss: 0.0612\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0635 - val_loss: 0.0605\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0629 - val_loss: 0.0593\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0639 - val_loss: 0.0590\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0627 - val_loss: 0.0596\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0618 - val_loss: 0.0605\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0602\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0607 - val_loss: 0.0581\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0646 - val_loss: 0.0611\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0623 - val_loss: 0.0602\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0625 - val_loss: 0.0596\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0613 - val_loss: 0.0602\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0603 - val_loss: 0.0589\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0636 - val_loss: 0.0604\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0615 - val_loss: 0.0597\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0607 - val_loss: 0.0600\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0606 - val_loss: 0.0599\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0608 - val_loss: 0.0604\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0586\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0614\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0625 - val_loss: 0.0622\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0655 - val_loss: 0.0610\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0651 - val_loss: 0.0597\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0645 - val_loss: 0.0609\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0618 - val_loss: 0.0619\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0618 - val_loss: 0.0613\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0587\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0610\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0620 - val_loss: 0.0607\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0593\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0594 - val_loss: 0.0604\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0616 - val_loss: 0.0609\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0618 - val_loss: 0.0603\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0613 - val_loss: 0.0582\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0601\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0630 - val_loss: 0.0587\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0604 - val_loss: 0.0597\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0616 - val_loss: 0.0611\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0622 - val_loss: 0.0616\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0621 - val_loss: 0.0594\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0638 - val_loss: 0.0607\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0600 - val_loss: 0.0616\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0614 - val_loss: 0.0609\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0621 - val_loss: 0.0600\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0614 - val_loss: 0.0601\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0613 - val_loss: 0.0627\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0608 - val_loss: 0.0605\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0599 - val_loss: 0.0617\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0597\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0621\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0622 - val_loss: 0.0582\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0615 - val_loss: 0.0626\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0620\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0626 - val_loss: 0.0608\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0618 - val_loss: 0.0589\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0622 - val_loss: 0.0614\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0586 - val_loss: 0.0610\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0609\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0605 - val_loss: 0.0611\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0617 - val_loss: 0.0617\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0609 - val_loss: 0.0612\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0617 - val_loss: 0.0608\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0605 - val_loss: 0.0588\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0612\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0603 - val_loss: 0.0620\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0609\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0619\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:05:12,487]\u001b[0m Trial 31 finished with value: 0.060343494142338236 and parameters: {'learning_rate': 0.0005758672607801627, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 158ms/step - loss: 0.2640 - val_loss: 0.1800\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.1537 - val_loss: 0.0962\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1081 - val_loss: 0.0748\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.1007 - val_loss: 0.0711\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0930 - val_loss: 0.0718\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0845 - val_loss: 0.0687\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0821 - val_loss: 0.0657\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0774 - val_loss: 0.0633\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0756 - val_loss: 0.0626\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0712 - val_loss: 0.0619\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0701 - val_loss: 0.0612\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0690 - val_loss: 0.0601\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0674 - val_loss: 0.0599\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0671 - val_loss: 0.0594\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0672 - val_loss: 0.0588\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0664 - val_loss: 0.0598\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0665 - val_loss: 0.0587\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0599\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0652 - val_loss: 0.0589\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0652 - val_loss: 0.0598\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0592\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0592\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0648 - val_loss: 0.0589\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0587\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0652 - val_loss: 0.0588\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0653 - val_loss: 0.0587\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0647 - val_loss: 0.0599\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0646 - val_loss: 0.0588\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0615 - val_loss: 0.0588\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0640 - val_loss: 0.0587\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0642 - val_loss: 0.0584\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0596\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0585\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0662 - val_loss: 0.0589\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0620 - val_loss: 0.0596\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0639 - val_loss: 0.0587\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0636 - val_loss: 0.0585\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0633 - val_loss: 0.0586\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0590\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0621 - val_loss: 0.0585\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0648 - val_loss: 0.0591\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0591\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0589\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0582\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0622 - val_loss: 0.0576\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0653 - val_loss: 0.0585\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0644 - val_loss: 0.0597\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0593\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0585\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0607 - val_loss: 0.0580\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0581\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0625 - val_loss: 0.0591\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0635 - val_loss: 0.0584\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0629 - val_loss: 0.0591\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0578\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0669 - val_loss: 0.0584\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0636 - val_loss: 0.0591\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0600\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0588\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0617 - val_loss: 0.0582\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0636 - val_loss: 0.0580\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0586\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0589\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0587\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0587\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0623 - val_loss: 0.0578\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0580\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0585\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0639 - val_loss: 0.0589\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0635 - val_loss: 0.0594\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0630 - val_loss: 0.0587\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0637 - val_loss: 0.0582\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0622 - val_loss: 0.0581\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0623 - val_loss: 0.0589\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0605 - val_loss: 0.0578\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0629 - val_loss: 0.0578\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0628 - val_loss: 0.0596\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0587\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0610 - val_loss: 0.0588\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0613 - val_loss: 0.0577\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0636 - val_loss: 0.0588\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0614 - val_loss: 0.0586\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0613 - val_loss: 0.0583\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0611 - val_loss: 0.0584\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0578\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0590\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0624 - val_loss: 0.0595\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0654 - val_loss: 0.0594\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0600\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0642 - val_loss: 0.0600\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0599\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0613 - val_loss: 0.0600\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0628 - val_loss: 0.0581\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0591\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0594\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0580\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0599 - val_loss: 0.0584\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0614 - val_loss: 0.0591\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0612 - val_loss: 0.0600\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0615 - val_loss: 0.0575\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0626 - val_loss: 0.0578\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0604 - val_loss: 0.0579\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0609 - val_loss: 0.0592\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0595\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0635 - val_loss: 0.0594\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0603 - val_loss: 0.0605\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0611 - val_loss: 0.0591\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0619 - val_loss: 0.0590\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0587\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0610 - val_loss: 0.0601\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0609 - val_loss: 0.0590\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0603 - val_loss: 0.0603\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0628 - val_loss: 0.0598\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0617 - val_loss: 0.0574\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0609 - val_loss: 0.0599\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0607\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0623 - val_loss: 0.0604\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0580\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0615 - val_loss: 0.0595\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0587 - val_loss: 0.0600\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0613 - val_loss: 0.0604\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0606 - val_loss: 0.0596\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0615 - val_loss: 0.0603\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0601 - val_loss: 0.0603\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0613 - val_loss: 0.0602\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0607 - val_loss: 0.0587\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0615 - val_loss: 0.0604\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0603 - val_loss: 0.0607\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0615 - val_loss: 0.0607\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0612 - val_loss: 0.0613\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:07:41,655]\u001b[0m Trial 32 finished with value: 0.060489937697731755 and parameters: {'learning_rate': 0.000473255558922315, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 4s 143ms/step - loss: 0.2426 - val_loss: 0.1429\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.1243 - val_loss: 0.0764\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1048 - val_loss: 0.0709\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0903 - val_loss: 0.0714\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0849 - val_loss: 0.0675\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0775 - val_loss: 0.0635\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0757 - val_loss: 0.0634\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0717 - val_loss: 0.0619\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0711 - val_loss: 0.0611\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0679 - val_loss: 0.0610\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0669 - val_loss: 0.0605\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0668 - val_loss: 0.0595\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0661 - val_loss: 0.0598\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0661 - val_loss: 0.0592\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0670 - val_loss: 0.0589\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0663 - val_loss: 0.0603\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0665 - val_loss: 0.0588\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0652 - val_loss: 0.0600\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0641 - val_loss: 0.0598\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0652 - val_loss: 0.0590\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0597\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0594\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0598\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0637 - val_loss: 0.0600\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0593\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0591\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0591\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0655 - val_loss: 0.0594\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0595\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0646 - val_loss: 0.0596\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0645 - val_loss: 0.0606\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0646 - val_loss: 0.0597\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0612 - val_loss: 0.0602\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0602\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0595\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0612\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0602\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0658 - val_loss: 0.0602\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0612\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0649 - val_loss: 0.0600\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0594\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0597\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0599\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0603\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0626 - val_loss: 0.0612\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0622 - val_loss: 0.0599\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0596\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0638 - val_loss: 0.0607\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0631 - val_loss: 0.0599\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0609\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0630 - val_loss: 0.0602\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0599\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0616 - val_loss: 0.0595\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0644 - val_loss: 0.0602\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0614\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0606\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0637 - val_loss: 0.0597\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0602 - val_loss: 0.0590\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0595\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0607\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0634 - val_loss: 0.0606\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0629 - val_loss: 0.0603\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0631 - val_loss: 0.0602\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0674 - val_loss: 0.0614\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0603\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0612\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0619 - val_loss: 0.0600\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0597\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0600\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0614\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0605\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0603\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0623 - val_loss: 0.0599\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0645 - val_loss: 0.0600\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0604\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0627 - val_loss: 0.0611\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0637 - val_loss: 0.0607\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0635 - val_loss: 0.0603\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0633 - val_loss: 0.0588\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0629 - val_loss: 0.0599\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0602\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0602\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0611 - val_loss: 0.0595\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0606\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0621 - val_loss: 0.0601\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0616 - val_loss: 0.0597\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0598 - val_loss: 0.0594\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0613 - val_loss: 0.0613\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0608 - val_loss: 0.0599\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0607 - val_loss: 0.0594\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0611 - val_loss: 0.0589\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0617 - val_loss: 0.0590\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0601\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0626 - val_loss: 0.0616\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0657 - val_loss: 0.0630\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0636 - val_loss: 0.0594\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0649 - val_loss: 0.0607\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0619 - val_loss: 0.0610\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0601\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0621 - val_loss: 0.0582\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0607\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0615 - val_loss: 0.0603\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0627 - val_loss: 0.0575\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0606 - val_loss: 0.0591\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0604\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0622 - val_loss: 0.0602\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0580\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0589\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0596\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0604 - val_loss: 0.0598\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0618 - val_loss: 0.0588\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0626 - val_loss: 0.0593\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0613 - val_loss: 0.0581\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0635 - val_loss: 0.0603\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0597 - val_loss: 0.0590\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0593\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0618 - val_loss: 0.0597\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0606\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0607 - val_loss: 0.0599\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0605 - val_loss: 0.0596\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0600 - val_loss: 0.0604\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0594\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0631 - val_loss: 0.0596\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0619 - val_loss: 0.0577\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0607 - val_loss: 0.0605\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0619\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0601\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0613 - val_loss: 0.0578\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0576\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0604\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0590 - val_loss: 0.0589\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0592\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0604 - val_loss: 0.0604\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0598\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0598 - val_loss: 0.0586\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0607 - val_loss: 0.0586\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0596 - val_loss: 0.0582\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0608\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0600 - val_loss: 0.0604\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0611 - val_loss: 0.0600\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:09:58,580]\u001b[0m Trial 33 finished with value: 0.060287951164876674 and parameters: {'learning_rate': 0.0006601525833805744, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 23 with value: 0.06000529532369251.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 147ms/step - loss: 0.2522 - val_loss: 0.1594\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.1347 - val_loss: 0.0808\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.1069 - val_loss: 0.0723\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0941 - val_loss: 0.0713\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0882 - val_loss: 0.0701\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0806 - val_loss: 0.0656\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0783 - val_loss: 0.0639\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0739 - val_loss: 0.0626\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0728 - val_loss: 0.0619\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0692 - val_loss: 0.0614\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0681 - val_loss: 0.0608\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0676 - val_loss: 0.0596\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0664 - val_loss: 0.0595\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0664 - val_loss: 0.0591\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0670 - val_loss: 0.0587\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0662 - val_loss: 0.0601\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0666 - val_loss: 0.0587\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0650 - val_loss: 0.0595\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0645 - val_loss: 0.0593\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0647 - val_loss: 0.0589\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0650 - val_loss: 0.0589\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0641 - val_loss: 0.0587\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0656 - val_loss: 0.0588\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0643 - val_loss: 0.0585\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0652 - val_loss: 0.0588\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0597\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0590\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0591\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0589\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0585\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0599\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0648 - val_loss: 0.0590\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0661 - val_loss: 0.0593\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0619 - val_loss: 0.0597\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0652 - val_loss: 0.0591\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0638 - val_loss: 0.0588\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0634 - val_loss: 0.0586\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0649 - val_loss: 0.0585\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0633 - val_loss: 0.0588\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0626 - val_loss: 0.0592\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0585\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0593\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0630 - val_loss: 0.0591\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0586\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0578\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0600\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0591\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0591\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0605 - val_loss: 0.0579\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0583\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0629 - val_loss: 0.0597\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0589\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0628 - val_loss: 0.0594\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0631 - val_loss: 0.0577\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0669 - val_loss: 0.0591\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0592\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0603\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0615 - val_loss: 0.0596\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0615 - val_loss: 0.0586\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0584\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0637 - val_loss: 0.0597\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0581\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0587\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0637 - val_loss: 0.0586\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0595\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0600\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0600\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0631 - val_loss: 0.0587\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0581\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0628 - val_loss: 0.0581\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0622 - val_loss: 0.0590\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0605 - val_loss: 0.0576\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0578\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0597\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0592\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0613 - val_loss: 0.0593\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0610 - val_loss: 0.0577\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0638 - val_loss: 0.0593\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0620 - val_loss: 0.0592\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0612 - val_loss: 0.0594\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0610 - val_loss: 0.0592\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0612 - val_loss: 0.0594\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0583\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0597\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0606\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0653 - val_loss: 0.0602\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0647 - val_loss: 0.0604\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0645 - val_loss: 0.0607\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0622 - val_loss: 0.0610\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0616 - val_loss: 0.0604\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0630 - val_loss: 0.0586\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0628 - val_loss: 0.0604\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0600\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0625 - val_loss: 0.0584\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0595 - val_loss: 0.0590\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0614 - val_loss: 0.0602\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0616 - val_loss: 0.0603\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0614 - val_loss: 0.0578\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0624 - val_loss: 0.0592\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0578\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0604 - val_loss: 0.0585\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0614 - val_loss: 0.0598\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0629 - val_loss: 0.0603\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0591\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0623 - val_loss: 0.0590\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0637 - val_loss: 0.0603\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0605 - val_loss: 0.0612\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0599\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0589\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0613 - val_loss: 0.0612\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0611 - val_loss: 0.0594\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0602 - val_loss: 0.0606\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0582\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0632 - val_loss: 0.0605\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0580\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0606\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0626 - val_loss: 0.0611\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0628 - val_loss: 0.0602\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0624 - val_loss: 0.0591\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0620 - val_loss: 0.0583\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0622 - val_loss: 0.0598\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0612 - val_loss: 0.0604\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0609 - val_loss: 0.0603\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0609\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0608 - val_loss: 0.0604\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0602\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0607 - val_loss: 0.0582\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0614 - val_loss: 0.0600\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0607 - val_loss: 0.0615\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0594\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0613 - val_loss: 0.0608\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:12:24,615]\u001b[0m Trial 34 finished with value: 0.059985352049217906 and parameters: {'learning_rate': 0.0005731777406687427, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 34 with value: 0.059985352049217906.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 149ms/step - loss: 0.2355 - val_loss: 0.1351\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1236 - val_loss: 0.0779\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1060 - val_loss: 0.0730\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0923 - val_loss: 0.0728\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0869 - val_loss: 0.0677\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0795 - val_loss: 0.0646\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0770 - val_loss: 0.0642\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0727 - val_loss: 0.0620\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0715 - val_loss: 0.0611\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0682 - val_loss: 0.0613\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0675 - val_loss: 0.0604\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0674 - val_loss: 0.0592\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0671 - val_loss: 0.0595\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0667 - val_loss: 0.0588\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0671 - val_loss: 0.0587\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0668 - val_loss: 0.0603\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0664 - val_loss: 0.0588\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0654 - val_loss: 0.0601\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0597\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0657 - val_loss: 0.0590\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0648 - val_loss: 0.0597\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0637 - val_loss: 0.0599\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0635 - val_loss: 0.0600\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0643 - val_loss: 0.0592\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0645 - val_loss: 0.0593\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0651 - val_loss: 0.0595\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0655 - val_loss: 0.0596\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0598\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0597\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0613\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0652 - val_loss: 0.0596\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0599\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0638 - val_loss: 0.0602\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0611\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0595\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0602\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0663 - val_loss: 0.0598\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0624 - val_loss: 0.0610\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0650 - val_loss: 0.0597\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0637 - val_loss: 0.0594\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0601\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0598\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0601\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0612\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0600\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0598\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0640 - val_loss: 0.0606\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0632 - val_loss: 0.0596\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0632 - val_loss: 0.0609\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0606\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0599\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0619 - val_loss: 0.0597\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0598\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0651 - val_loss: 0.0607\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0628 - val_loss: 0.0605\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0596\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0607 - val_loss: 0.0592\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0596\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0633 - val_loss: 0.0602\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0638 - val_loss: 0.0605\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0633 - val_loss: 0.0602\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0604\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0669 - val_loss: 0.0607\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0598\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0638 - val_loss: 0.0611\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0622 - val_loss: 0.0597\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0596\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0650 - val_loss: 0.0588\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0598\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0618 - val_loss: 0.0611\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0625 - val_loss: 0.0603\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0633 - val_loss: 0.0606\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0628 - val_loss: 0.0598\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0589\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0595\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0627 - val_loss: 0.0599\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0645 - val_loss: 0.0599\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0612\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0598\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0638 - val_loss: 0.0598\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0636 - val_loss: 0.0591\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0608\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0623 - val_loss: 0.0604\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0630 - val_loss: 0.0599\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0600\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0587\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0603\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0631 - val_loss: 0.0606\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0623 - val_loss: 0.0606\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0592\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0605 - val_loss: 0.0587\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0596\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0607\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0599\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0600\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0616 - val_loss: 0.0592\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0588\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0604\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0623\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0661 - val_loss: 0.0630\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0654 - val_loss: 0.0620\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0623 - val_loss: 0.0616\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0616 - val_loss: 0.0600\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0627 - val_loss: 0.0585\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0635 - val_loss: 0.0611\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0608\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0636 - val_loss: 0.0583\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0592\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0621 - val_loss: 0.0608\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0631 - val_loss: 0.0602\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0595\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0636 - val_loss: 0.0597\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0624 - val_loss: 0.0593\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0610 - val_loss: 0.0589\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0591\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0600\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0587\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0598\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0636 - val_loss: 0.0612\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0608 - val_loss: 0.0601\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0621 - val_loss: 0.0595\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0623 - val_loss: 0.0592\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0628 - val_loss: 0.0603\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0612 - val_loss: 0.0598\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0615 - val_loss: 0.0601\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0609 - val_loss: 0.0602\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0631 - val_loss: 0.0590\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0638 - val_loss: 0.0601\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0595\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0613 - val_loss: 0.0603\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0613\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0604\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0605\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0600 - val_loss: 0.0597\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0599\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0607 - val_loss: 0.0602\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0593\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0608 - val_loss: 0.0591\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0607\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0606 - val_loss: 0.0590\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0603\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0605 - val_loss: 0.0603\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0596\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0608\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 87). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:14:51,119]\u001b[0m Trial 35 finished with value: 0.0604126576961287 and parameters: {'learning_rate': 0.000607152249600669, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'LeakyReLU', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 34 with value: 0.059985352049217906.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 141ms/step - loss: 0.2368 - val_loss: 0.1331\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1204 - val_loss: 0.0757\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.1027 - val_loss: 0.0709\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0886 - val_loss: 0.0709\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0829 - val_loss: 0.0660\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0760 - val_loss: 0.0628\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0745 - val_loss: 0.0633\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0705 - val_loss: 0.0614\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0703 - val_loss: 0.0607\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0673 - val_loss: 0.0608\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0664 - val_loss: 0.0602\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0665 - val_loss: 0.0593\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0660 - val_loss: 0.0598\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0659 - val_loss: 0.0590\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0670 - val_loss: 0.0589\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0666 - val_loss: 0.0605\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0667 - val_loss: 0.0588\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0652 - val_loss: 0.0603\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0598\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0653 - val_loss: 0.0591\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0599\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0637 - val_loss: 0.0595\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0638 - val_loss: 0.0599\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0599\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0593\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0648 - val_loss: 0.0592\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0646 - val_loss: 0.0591\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0656 - val_loss: 0.0594\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0646 - val_loss: 0.0595\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0596\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0646 - val_loss: 0.0606\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0647 - val_loss: 0.0598\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0604\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0604\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0640 - val_loss: 0.0597\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0613\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0641 - val_loss: 0.0595\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0641 - val_loss: 0.0601\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0658 - val_loss: 0.0601\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0624 - val_loss: 0.0611\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0650 - val_loss: 0.0600\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0636 - val_loss: 0.0597\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0634 - val_loss: 0.0601\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0600\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0627 - val_loss: 0.0603\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0626 - val_loss: 0.0611\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0599\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0629 - val_loss: 0.0595\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0607\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0630 - val_loss: 0.0600\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0608\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0630 - val_loss: 0.0603\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0638 - val_loss: 0.0599\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0595\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0600\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0647 - val_loss: 0.0609\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0604\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0600 - val_loss: 0.0589\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0594\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0607\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0635 - val_loss: 0.0609\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0605\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0602\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0674 - val_loss: 0.0606\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0599\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0616\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0617 - val_loss: 0.0607\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0616 - val_loss: 0.0599\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0646 - val_loss: 0.0595\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0623 - val_loss: 0.0604\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0616\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0620 - val_loss: 0.0609\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0603\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0598\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0598\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0624 - val_loss: 0.0599\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0636 - val_loss: 0.0601\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0628 - val_loss: 0.0611\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0609\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0602\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0590\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0597\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0616 - val_loss: 0.0607\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0626 - val_loss: 0.0606\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0612 - val_loss: 0.0593\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0609\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0610\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0618 - val_loss: 0.0605\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0600\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0601 - val_loss: 0.0588\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0642 - val_loss: 0.0598\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0612 - val_loss: 0.0609\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0604 - val_loss: 0.0604\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0609 - val_loss: 0.0603\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0610 - val_loss: 0.0594\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0615 - val_loss: 0.0587\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0613 - val_loss: 0.0602\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0624\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0657 - val_loss: 0.0626\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0611\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0647 - val_loss: 0.0623\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0618 - val_loss: 0.0615\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0608 - val_loss: 0.0608\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0622 - val_loss: 0.0592\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0614\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0616 - val_loss: 0.0613\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0593\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0605 - val_loss: 0.0606\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0615 - val_loss: 0.0607\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0623 - val_loss: 0.0610\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0609 - val_loss: 0.0590\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0633 - val_loss: 0.0600\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0626 - val_loss: 0.0604\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0611 - val_loss: 0.0601\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0605\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0611\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0616 - val_loss: 0.0594\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0620 - val_loss: 0.0605\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0615\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0599 - val_loss: 0.0612\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0604\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0616 - val_loss: 0.0595\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0601\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0603 - val_loss: 0.0622\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0603 - val_loss: 0.0605\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0600 - val_loss: 0.0616\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0626 - val_loss: 0.0596\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0607\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0622 - val_loss: 0.0581\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0612\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0617 - val_loss: 0.0624\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0629 - val_loss: 0.0612\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0611 - val_loss: 0.0586\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0587\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0607\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0616 - val_loss: 0.0606\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0602 - val_loss: 0.0612\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0612\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0601 - val_loss: 0.0608\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0613 - val_loss: 0.0614\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0596 - val_loss: 0.0593\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0613 - val_loss: 0.0616\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0597 - val_loss: 0.0616\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0616 - val_loss: 0.0609\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0605 - val_loss: 0.0622\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:17:15,293]\u001b[0m Trial 36 finished with value: 0.061032757735291834 and parameters: {'learning_rate': 0.0007172315897093092, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 34 with value: 0.059985352049217906.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 141ms/step - loss: 0.2694 - val_loss: 0.1891\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.1641 - val_loss: 0.1069\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.1106 - val_loss: 0.0759\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1027 - val_loss: 0.0718\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0963 - val_loss: 0.0720\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0865 - val_loss: 0.0705\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0844 - val_loss: 0.0673\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0796 - val_loss: 0.0643\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0776 - val_loss: 0.0634\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0730 - val_loss: 0.0628\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0716 - val_loss: 0.0619\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0702 - val_loss: 0.0606\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0683 - val_loss: 0.0602\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0680 - val_loss: 0.0600\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0676 - val_loss: 0.0590\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0665 - val_loss: 0.0598\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0665 - val_loss: 0.0587\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0653 - val_loss: 0.0595\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0595\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0654 - val_loss: 0.0589\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0595\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0646 - val_loss: 0.0594\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0591\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0648 - val_loss: 0.0588\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0655 - val_loss: 0.0586\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0586\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0584\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0653 - val_loss: 0.0586\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0645 - val_loss: 0.0597\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0618 - val_loss: 0.0588\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0588\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0643 - val_loss: 0.0585\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0622 - val_loss: 0.0597\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0662 - val_loss: 0.0588\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0596\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0655 - val_loss: 0.0592\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0587\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0639 - val_loss: 0.0585\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0648 - val_loss: 0.0585\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0586\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0628 - val_loss: 0.0586\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0649 - val_loss: 0.0590\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0590\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0578\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0657 - val_loss: 0.0585\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0594\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0582\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0581\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0628 - val_loss: 0.0589\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0585\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0593\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0636 - val_loss: 0.0582\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0669 - val_loss: 0.0585\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0590\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0596\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0622 - val_loss: 0.0584\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0581\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0644 - val_loss: 0.0591\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0588\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0632 - val_loss: 0.0587\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0582\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0578\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0639 - val_loss: 0.0582\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0584\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0636 - val_loss: 0.0592\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0584\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0582\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0624 - val_loss: 0.0589\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0626 - val_loss: 0.0592\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0582\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0580\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0592\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0594\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0628 - val_loss: 0.0590\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0614 - val_loss: 0.0587\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0618 - val_loss: 0.0577\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0637 - val_loss: 0.0588\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0616 - val_loss: 0.0588\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0588\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0615 - val_loss: 0.0586\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0584\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0626 - val_loss: 0.0587\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0624 - val_loss: 0.0593\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0597\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0597\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0598\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0598\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0581\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0631 - val_loss: 0.0587\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0622 - val_loss: 0.0590\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0603 - val_loss: 0.0581\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0587\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0573\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0630 - val_loss: 0.0579\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0609 - val_loss: 0.0575\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0611 - val_loss: 0.0588\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0592\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0583\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0587\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0590\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0608 - val_loss: 0.0597\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0614 - val_loss: 0.0589\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0582\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0597\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0582\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0608 - val_loss: 0.0596\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0633 - val_loss: 0.0581\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0594\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0571\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0593\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0602\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0626 - val_loss: 0.0599\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0577\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0590 - val_loss: 0.0600\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0602\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0608 - val_loss: 0.0593\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0618 - val_loss: 0.0599\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0607 - val_loss: 0.0598\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0616 - val_loss: 0.0601\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0609 - val_loss: 0.0580\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0592\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0608 - val_loss: 0.0604\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0618 - val_loss: 0.0597\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0614 - val_loss: 0.0605\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:19:34,285]\u001b[0m Trial 37 finished with value: 0.060504387090303535 and parameters: {'learning_rate': 0.0004298422527239055, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 34 with value: 0.059985352049217906.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 154ms/step - loss: 0.2710 - val_loss: 0.1957\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.1734 - val_loss: 0.1187\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.1178 - val_loss: 0.0798\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1071 - val_loss: 0.0748\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.1032 - val_loss: 0.0748\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0926 - val_loss: 0.0738\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0902 - val_loss: 0.0707\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0863 - val_loss: 0.0676\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0832 - val_loss: 0.0664\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0790 - val_loss: 0.0652\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0761 - val_loss: 0.0642\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0744 - val_loss: 0.0624\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0722 - val_loss: 0.0616\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0713 - val_loss: 0.0610\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0698 - val_loss: 0.0599\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0690 - val_loss: 0.0600\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0681 - val_loss: 0.0590\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0662 - val_loss: 0.0593\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0656 - val_loss: 0.0594\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0666 - val_loss: 0.0589\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0653 - val_loss: 0.0591\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0653 - val_loss: 0.0589\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0653 - val_loss: 0.0591\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0588\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0653 - val_loss: 0.0586\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0656 - val_loss: 0.0589\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0647 - val_loss: 0.0586\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0663 - val_loss: 0.0586\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0656 - val_loss: 0.0584\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0655 - val_loss: 0.0584\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0656 - val_loss: 0.0585\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0650 - val_loss: 0.0594\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0655 - val_loss: 0.0587\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0583\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0625 - val_loss: 0.0591\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0654 - val_loss: 0.0586\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0652 - val_loss: 0.0585\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0670 - val_loss: 0.0587\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0628 - val_loss: 0.0591\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0663 - val_loss: 0.0593\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0645 - val_loss: 0.0586\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0646 - val_loss: 0.0583\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0650 - val_loss: 0.0584\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0643 - val_loss: 0.0585\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0638 - val_loss: 0.0588\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0631 - val_loss: 0.0585\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0638 - val_loss: 0.0586\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0653 - val_loss: 0.0588\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0651 - val_loss: 0.0588\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0646 - val_loss: 0.0588\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0589\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0651 - val_loss: 0.0583\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0637 - val_loss: 0.0580\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0660 - val_loss: 0.0584\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0650 - val_loss: 0.0589\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0642 - val_loss: 0.0589\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0653 - val_loss: 0.0585\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0583\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0632 - val_loss: 0.0584\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0591\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0642 - val_loss: 0.0584\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0671 - val_loss: 0.0583\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0644 - val_loss: 0.0584\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0648 - val_loss: 0.0591\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0628 - val_loss: 0.0586\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0645 - val_loss: 0.0582\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0646 - val_loss: 0.0589\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0632 - val_loss: 0.0585\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0637 - val_loss: 0.0588\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0634 - val_loss: 0.0584\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0637 - val_loss: 0.0579\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0642 - val_loss: 0.0578\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0580\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0649 - val_loss: 0.0582\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0642 - val_loss: 0.0585\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0586\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0582\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0580\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0631 - val_loss: 0.0580\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0633 - val_loss: 0.0586\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0632 - val_loss: 0.0588\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0581\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0639 - val_loss: 0.0579\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0654 - val_loss: 0.0586\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0588\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0583\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0627 - val_loss: 0.0576\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0579\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0577\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0581\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0582\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0580\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0624 - val_loss: 0.0577\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0639 - val_loss: 0.0582\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0632 - val_loss: 0.0589\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0650 - val_loss: 0.0591\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0591\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0592\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0591\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0636 - val_loss: 0.0579\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0578\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0579\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0639 - val_loss: 0.0578\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0612 - val_loss: 0.0574\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0620 - val_loss: 0.0578\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0576\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0573\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0631 - val_loss: 0.0577\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0623 - val_loss: 0.0569\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0580\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0634 - val_loss: 0.0582\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0578\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0633 - val_loss: 0.0584\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0583\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0622 - val_loss: 0.0586\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0622 - val_loss: 0.0580\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0581\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0630 - val_loss: 0.0573\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0629 - val_loss: 0.0587\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0578\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0581\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0574\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0646 - val_loss: 0.0584\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0569\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0577\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0588\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0586\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0630 - val_loss: 0.0582\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0632 - val_loss: 0.0577\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0635 - val_loss: 0.0574\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0608 - val_loss: 0.0585\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0622 - val_loss: 0.0577\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0626 - val_loss: 0.0577\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0617 - val_loss: 0.0579\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0591\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0572\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0580\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0623 - val_loss: 0.0584\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0587\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0586\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 87). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:22:04,786]\u001b[0m Trial 38 finished with value: 0.06099258572776439 and parameters: {'learning_rate': 0.00033754768637827594, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'LeakyReLU', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 34 with value: 0.059985352049217906.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 144ms/step - loss: 0.1690 - val_loss: 0.0831\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.1070 - val_loss: 0.0755\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0907 - val_loss: 0.0699\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0779 - val_loss: 0.0616\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0717 - val_loss: 0.0601\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0678 - val_loss: 0.0584\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0675 - val_loss: 0.0579\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0658 - val_loss: 0.0587\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0661 - val_loss: 0.0594\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0655 - val_loss: 0.0585\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0646 - val_loss: 0.0580\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0649 - val_loss: 0.0580\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0660 - val_loss: 0.0580\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0656 - val_loss: 0.0578\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0655 - val_loss: 0.0576\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0653 - val_loss: 0.0589\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0667 - val_loss: 0.0580\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0663 - val_loss: 0.0581\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0660 - val_loss: 0.0584\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0651 - val_loss: 0.0582\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0581\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0649 - val_loss: 0.0577\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0641 - val_loss: 0.0576\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0578\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0578\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0645 - val_loss: 0.0578\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0653 - val_loss: 0.0581\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0633 - val_loss: 0.0577\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0587\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0646 - val_loss: 0.0587\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0662 - val_loss: 0.0581\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0612 - val_loss: 0.0580\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0579\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0635 - val_loss: 0.0577\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0583\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0638 - val_loss: 0.0584\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0648 - val_loss: 0.0586\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0662 - val_loss: 0.0588\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0589\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0580\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0635 - val_loss: 0.0577\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0581\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0629 - val_loss: 0.0583\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0614 - val_loss: 0.0583\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0581\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0579\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0582\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0640 - val_loss: 0.0579\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0614 - val_loss: 0.0574\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0649 - val_loss: 0.0587\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0597\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0628 - val_loss: 0.0590\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0581\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0600 - val_loss: 0.0574\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0620 - val_loss: 0.0580\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0621 - val_loss: 0.0585\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0585\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0576\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0630 - val_loss: 0.0574\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0673 - val_loss: 0.0579\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0599\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0586\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0611 - val_loss: 0.0578\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0582\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0589\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0637 - val_loss: 0.0586\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0617 - val_loss: 0.0586\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0585\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0581\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0623 - val_loss: 0.0578\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0575\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0585\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0585\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0589\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0635 - val_loss: 0.0592\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0588\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0626 - val_loss: 0.0580\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0593\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0589\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0608 - val_loss: 0.0581\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0579\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0594\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0591\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0611 - val_loss: 0.0585\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0613 - val_loss: 0.0572\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0639 - val_loss: 0.0583\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0576\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0613 - val_loss: 0.0586\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0613 - val_loss: 0.0582\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0610 - val_loss: 0.0593\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0568\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0606\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0629 - val_loss: 0.0609\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0662 - val_loss: 0.0590\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0660 - val_loss: 0.0589\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0608\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0605\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0619 - val_loss: 0.0597\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0595\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0598\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0585\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0597 - val_loss: 0.0592\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0600\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0620 - val_loss: 0.0593\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0580\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0592\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0576\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0605 - val_loss: 0.0584\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0612 - val_loss: 0.0597\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0603\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0590\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0588\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0596\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0603 - val_loss: 0.0606\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0603\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0597\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0588\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0611 - val_loss: 0.0608\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0611 - val_loss: 0.0594\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0597 - val_loss: 0.0612\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0628 - val_loss: 0.0589\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0606\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0574\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0615 - val_loss: 0.0618\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0621\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0611\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0586\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0616\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0591 - val_loss: 0.0603\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0615 - val_loss: 0.0601\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0604 - val_loss: 0.0601\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0614 - val_loss: 0.0602\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0603 - val_loss: 0.0608\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0616 - val_loss: 0.0617\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0607 - val_loss: 0.0583\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0609 - val_loss: 0.0608\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0600 - val_loss: 0.0608\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0604\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 0.0602\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:24:27,490]\u001b[0m Trial 39 finished with value: 0.06009715360281694 and parameters: {'learning_rate': 0.0006317372350467565, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 34 with value: 0.059985352049217906.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 140ms/step - loss: 0.1635 - val_loss: 0.0763\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0959 - val_loss: 0.0767\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0824 - val_loss: 0.0623\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0722 - val_loss: 0.0594\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0670 - val_loss: 0.0593\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0660 - val_loss: 0.0587\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0665 - val_loss: 0.0580\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0658 - val_loss: 0.0598\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0662 - val_loss: 0.0599\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0661 - val_loss: 0.0579\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0643 - val_loss: 0.0577\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0579\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0656 - val_loss: 0.0590\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0656 - val_loss: 0.0579\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0657 - val_loss: 0.0577\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0656 - val_loss: 0.0604\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0669 - val_loss: 0.0593\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0666 - val_loss: 0.0583\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0658 - val_loss: 0.0587\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0648 - val_loss: 0.0585\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0647 - val_loss: 0.0586\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0639 - val_loss: 0.0584\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0644 - val_loss: 0.0580\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0635 - val_loss: 0.0581\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0579\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0588\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0658 - val_loss: 0.0583\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0629 - val_loss: 0.0576\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0647 - val_loss: 0.0597\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0593\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0664 - val_loss: 0.0581\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0582\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0638 - val_loss: 0.0580\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0591\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0635 - val_loss: 0.0586\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0587\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0657 - val_loss: 0.0589\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0584\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0594\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0585\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0581\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0647 - val_loss: 0.0589\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0590\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0612 - val_loss: 0.0584\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0613 - val_loss: 0.0583\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0643 - val_loss: 0.0597\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0633 - val_loss: 0.0583\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0579\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0637 - val_loss: 0.0582\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0612 - val_loss: 0.0575\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0648 - val_loss: 0.0604\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0637 - val_loss: 0.0613\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0626 - val_loss: 0.0592\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0640 - val_loss: 0.0585\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0591 - val_loss: 0.0587\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0593\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0615 - val_loss: 0.0603\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0570\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0627 - val_loss: 0.0590\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0662 - val_loss: 0.0610\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0633 - val_loss: 0.0605\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0612\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0612 - val_loss: 0.0594\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0608 - val_loss: 0.0596\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0590\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0612 - val_loss: 0.0604\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0597\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0612 - val_loss: 0.0602\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0600\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0620 - val_loss: 0.0591\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0616 - val_loss: 0.0597\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0590\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0633 - val_loss: 0.0598\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0630 - val_loss: 0.0607\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0619\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0636 - val_loss: 0.0608\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0629 - val_loss: 0.0612\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0585\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0587\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 0.0609\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0615 - val_loss: 0.0601\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0597 - val_loss: 0.0589\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0624 - val_loss: 0.0588\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0644 - val_loss: 0.0612\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0598\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0614 - val_loss: 0.0601\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0600 - val_loss: 0.0598\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0595 - val_loss: 0.0593\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0631 - val_loss: 0.0612\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0609 - val_loss: 0.0602\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0600 - val_loss: 0.0603\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0604 - val_loss: 0.0606\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0605 - val_loss: 0.0615\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0609 - val_loss: 0.0582\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0604 - val_loss: 0.0622\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0610 - val_loss: 0.0628\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0602\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0642 - val_loss: 0.0608\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0642 - val_loss: 0.0631\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0610 - val_loss: 0.0613\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0613 - val_loss: 0.0610\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0620 - val_loss: 0.0617\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0607 - val_loss: 0.0614\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0587 - val_loss: 0.0627\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0614 - val_loss: 0.0612\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0600\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0604 - val_loss: 0.0586\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0609 - val_loss: 0.0607\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0587\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0594 - val_loss: 0.0608\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0609 - val_loss: 0.0607\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0611\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0611 - val_loss: 0.0583\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0615 - val_loss: 0.0598\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0626 - val_loss: 0.0611\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0586 - val_loss: 0.0611\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0606 - val_loss: 0.0612\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0615 - val_loss: 0.0592\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0599 - val_loss: 0.0615\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0598 - val_loss: 0.0614\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0594 - val_loss: 0.0603\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0581 - val_loss: 0.0624\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0606 - val_loss: 0.0612\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0610\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0620 - val_loss: 0.0569\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0600 - val_loss: 0.0633\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0611\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0617\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0610 - val_loss: 0.0593\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0611 - val_loss: 0.0600\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0606 - val_loss: 0.0631\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0569 - val_loss: 0.0600\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0613 - val_loss: 0.0608\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0594 - val_loss: 0.0630\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0612 - val_loss: 0.0608\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0601 - val_loss: 0.0617\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0598 - val_loss: 0.0608\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0599 - val_loss: 0.0606\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0598 - val_loss: 0.0634\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0588 - val_loss: 0.0597\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0604 - val_loss: 0.0626\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0601 - val_loss: 0.0608\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:26:52,801]\u001b[0m Trial 40 finished with value: 0.06087349813757747 and parameters: {'learning_rate': 0.0008520951406175127, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 34 with value: 0.059985352049217906.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 136ms/step - loss: 0.1688 - val_loss: 0.0830\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1066 - val_loss: 0.0756\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0906 - val_loss: 0.0697\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0777 - val_loss: 0.0616\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0715 - val_loss: 0.0601\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0677 - val_loss: 0.0584\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0674 - val_loss: 0.0579\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0658 - val_loss: 0.0587\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0660 - val_loss: 0.0593\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0655 - val_loss: 0.0585\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0580\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0649 - val_loss: 0.0580\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0661 - val_loss: 0.0580\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0655 - val_loss: 0.0578\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0655 - val_loss: 0.0576\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0653 - val_loss: 0.0589\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0666 - val_loss: 0.0580\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0664 - val_loss: 0.0581\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0658 - val_loss: 0.0583\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0649 - val_loss: 0.0582\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0648 - val_loss: 0.0584\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0582\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0650 - val_loss: 0.0578\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0641 - val_loss: 0.0577\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0577\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0641 - val_loss: 0.0577\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0644 - val_loss: 0.0578\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0643 - val_loss: 0.0582\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0654 - val_loss: 0.0581\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0632 - val_loss: 0.0575\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0650 - val_loss: 0.0584\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0585\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0664 - val_loss: 0.0578\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0577\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0577\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0575\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0581\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0582\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0651 - val_loss: 0.0584\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0661 - val_loss: 0.0585\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0584\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0589\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0578\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0635 - val_loss: 0.0575\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0649 - val_loss: 0.0580\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0629 - val_loss: 0.0582\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0615 - val_loss: 0.0583\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0616 - val_loss: 0.0581\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0587\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0629 - val_loss: 0.0580\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0619 - val_loss: 0.0581\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0640 - val_loss: 0.0577\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0615 - val_loss: 0.0573\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0650 - val_loss: 0.0587\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0596\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0579\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0601 - val_loss: 0.0572\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0621 - val_loss: 0.0579\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0586\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0578\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0573\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0671 - val_loss: 0.0578\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0638 - val_loss: 0.0584\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0646 - val_loss: 0.0595\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0614 - val_loss: 0.0581\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0637 - val_loss: 0.0581\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0584\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0587\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0631 - val_loss: 0.0585\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0580\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0580\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0573\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0588\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0645 - val_loss: 0.0591\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0585\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0582\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0581\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0626 - val_loss: 0.0589\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0609 - val_loss: 0.0576\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0632 - val_loss: 0.0572\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0601\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0631 - val_loss: 0.0590\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0612 - val_loss: 0.0582\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0613 - val_loss: 0.0571\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0584\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0581\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0614 - val_loss: 0.0591\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0580\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0611 - val_loss: 0.0587\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0619 - val_loss: 0.0570\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0599\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0610\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0665 - val_loss: 0.0587\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0662 - val_loss: 0.0584\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0596\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0604\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0601\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0583\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0628 - val_loss: 0.0592\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0595\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0579\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0598 - val_loss: 0.0590\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0615 - val_loss: 0.0595\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0614 - val_loss: 0.0574\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0587\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0632 - val_loss: 0.0578\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0607 - val_loss: 0.0582\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0615 - val_loss: 0.0589\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0626 - val_loss: 0.0595\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0579\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0622 - val_loss: 0.0581\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0594\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0604 - val_loss: 0.0600\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0615 - val_loss: 0.0591\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0585\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0587\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0613 - val_loss: 0.0601\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0609 - val_loss: 0.0589\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0596 - val_loss: 0.0604\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0582\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0629 - val_loss: 0.0605\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0569\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0602\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0605\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0602\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0581\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0581\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0604\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0590 - val_loss: 0.0593\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0612 - val_loss: 0.0591\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0606 - val_loss: 0.0596\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0596\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0613 - val_loss: 0.0599\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0622 - val_loss: 0.0603\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0610 - val_loss: 0.0578\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0614 - val_loss: 0.0595\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0604 - val_loss: 0.0592\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0595\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0613 - val_loss: 0.0604\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:29:14,323]\u001b[0m Trial 41 finished with value: 0.060578331553446725 and parameters: {'learning_rate': 0.0006360388163061036, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 34 with value: 0.059985352049217906.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 190ms/step - loss: 0.1709 - val_loss: 0.0830\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.1110 - val_loss: 0.0742\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0925 - val_loss: 0.0730\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0801 - val_loss: 0.0623\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0737 - val_loss: 0.0602\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0684 - val_loss: 0.0591\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0680 - val_loss: 0.0581\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0660 - val_loss: 0.0586\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0662 - val_loss: 0.0592\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0588\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0581\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0651 - val_loss: 0.0581\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0662 - val_loss: 0.0578\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0656 - val_loss: 0.0578\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0656 - val_loss: 0.0577\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0653 - val_loss: 0.0586\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0667 - val_loss: 0.0579\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0663 - val_loss: 0.0583\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0655 - val_loss: 0.0581\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0647 - val_loss: 0.0581\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0649 - val_loss: 0.0583\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0645 - val_loss: 0.0582\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0652 - val_loss: 0.0578\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0578\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0643 - val_loss: 0.0578\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0642 - val_loss: 0.0578\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0645 - val_loss: 0.0578\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0644 - val_loss: 0.0582\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0654 - val_loss: 0.0580\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0633 - val_loss: 0.0576\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0650 - val_loss: 0.0583\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0584\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0665 - val_loss: 0.0579\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0614 - val_loss: 0.0578\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0640 - val_loss: 0.0577\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0636 - val_loss: 0.0574\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0619 - val_loss: 0.0579\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0640 - val_loss: 0.0580\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0653 - val_loss: 0.0582\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0662 - val_loss: 0.0584\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0590\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0579\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0636 - val_loss: 0.0576\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0648 - val_loss: 0.0579\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0581\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0582\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0617 - val_loss: 0.0581\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0642 - val_loss: 0.0584\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0579\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0579\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0577\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0616 - val_loss: 0.0574\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0648 - val_loss: 0.0583\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0586\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0641 - val_loss: 0.0583\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0602 - val_loss: 0.0572\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0621 - val_loss: 0.0579\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0582\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0624 - val_loss: 0.0575\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0630 - val_loss: 0.0574\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0672 - val_loss: 0.0579\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0639 - val_loss: 0.0587\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 0.0579\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0639 - val_loss: 0.0579\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0585\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0616 - val_loss: 0.0588\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0574\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0623 - val_loss: 0.0577\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0642 - val_loss: 0.0579\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0587\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0588\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0634 - val_loss: 0.0588\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0593\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0588\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0609 - val_loss: 0.0581\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0579\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0586\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0628 - val_loss: 0.0596\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0613 - val_loss: 0.0589\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0614 - val_loss: 0.0578\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0590\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0588\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0613 - val_loss: 0.0594\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0588\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0611 - val_loss: 0.0592\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0577\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0624 - val_loss: 0.0604\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0634 - val_loss: 0.0607\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0662 - val_loss: 0.0591\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0659 - val_loss: 0.0597\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0647 - val_loss: 0.0604\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0604\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0619 - val_loss: 0.0597\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0597\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0596\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0588\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0598 - val_loss: 0.0594\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0616 - val_loss: 0.0603\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0584\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0592\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0628 - val_loss: 0.0583\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0606 - val_loss: 0.0586\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0613 - val_loss: 0.0598\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0622 - val_loss: 0.0604\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0589\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0588\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0595\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0604 - val_loss: 0.0603\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0615 - val_loss: 0.0603\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0600\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0596\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0611 - val_loss: 0.0613\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0610 - val_loss: 0.0599\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0598 - val_loss: 0.0609\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0591\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0628 - val_loss: 0.0603\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0620 - val_loss: 0.0577\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0604\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0612\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0607\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0591\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0590\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0615 - val_loss: 0.0608\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0587 - val_loss: 0.0612\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0613 - val_loss: 0.0601\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0603 - val_loss: 0.0606\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0616 - val_loss: 0.0605\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0611 - val_loss: 0.0610\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0615\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0607 - val_loss: 0.0592\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0613 - val_loss: 0.0602\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0604 - val_loss: 0.0610\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0603\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0617\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:31:30,295]\u001b[0m Trial 42 finished with value: 0.05986814472207531 and parameters: {'learning_rate': 0.0005775057096459508, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 42 with value: 0.05986814472207531.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 140ms/step - loss: 0.1708 - val_loss: 0.0830\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.1107 - val_loss: 0.0743\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0923 - val_loss: 0.0728\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0799 - val_loss: 0.0623\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0736 - val_loss: 0.0602\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0683 - val_loss: 0.0590\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0679 - val_loss: 0.0581\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0660 - val_loss: 0.0587\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0662 - val_loss: 0.0592\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0653 - val_loss: 0.0587\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0581\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0650 - val_loss: 0.0581\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0662 - val_loss: 0.0579\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0656 - val_loss: 0.0578\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0655 - val_loss: 0.0577\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0652 - val_loss: 0.0586\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0667 - val_loss: 0.0578\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0663 - val_loss: 0.0582\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0656 - val_loss: 0.0582\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0648 - val_loss: 0.0581\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0649 - val_loss: 0.0583\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0582\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0578\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0641 - val_loss: 0.0577\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0577\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0577\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0578\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0582\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0654 - val_loss: 0.0580\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0576\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0650 - val_loss: 0.0583\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0647 - val_loss: 0.0584\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0664 - val_loss: 0.0578\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0613 - val_loss: 0.0578\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0577\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0575\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0580\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0581\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0652 - val_loss: 0.0581\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0661 - val_loss: 0.0584\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0621 - val_loss: 0.0583\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0578\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0635 - val_loss: 0.0575\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0649 - val_loss: 0.0578\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0580\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0584\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0615 - val_loss: 0.0580\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0579\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0584\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0577\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0579\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0640 - val_loss: 0.0575\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0572\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0649 - val_loss: 0.0583\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0641 - val_loss: 0.0581\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0602 - val_loss: 0.0574\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0621 - val_loss: 0.0578\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0624 - val_loss: 0.0583\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0585\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0581\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0572\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0673 - val_loss: 0.0575\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0598\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0612 - val_loss: 0.0580\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0582\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0587\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0590\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0590\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0623 - val_loss: 0.0580\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0578\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0643 - val_loss: 0.0587\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0588\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0634 - val_loss: 0.0591\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0588\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0642 - val_loss: 0.0587\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0594\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0626 - val_loss: 0.0587\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0608 - val_loss: 0.0580\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0630 - val_loss: 0.0577\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0586\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0628 - val_loss: 0.0593\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0587\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 0.0587\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0614 - val_loss: 0.0573\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0590\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0622 - val_loss: 0.0584\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0616 - val_loss: 0.0589\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0616 - val_loss: 0.0581\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0612 - val_loss: 0.0585\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0620 - val_loss: 0.0572\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0596\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0609\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0662 - val_loss: 0.0588\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0661 - val_loss: 0.0588\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0648 - val_loss: 0.0600\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0603\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0630 - val_loss: 0.0584\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0594\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0581\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0601 - val_loss: 0.0588\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0601\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0596\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0579\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0629 - val_loss: 0.0579\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0607 - val_loss: 0.0581\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0592\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0599\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0582\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0596\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0607 - val_loss: 0.0604\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0601\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0590\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0590\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0607\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0603\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0602 - val_loss: 0.0607\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0602\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0620 - val_loss: 0.0572\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0613 - val_loss: 0.0605\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0624 - val_loss: 0.0610\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0609\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0612\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0586 - val_loss: 0.0604\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0599\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0604 - val_loss: 0.0605\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0609 - val_loss: 0.0605\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0627\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0584\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0619 - val_loss: 0.0599\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0608 - val_loss: 0.0607\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0605\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0605\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:33:47,670]\u001b[0m Trial 43 finished with value: 0.06044665673239763 and parameters: {'learning_rate': 0.0005815783697432513, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 42 with value: 0.05986814472207531.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 140ms/step - loss: 0.1641 - val_loss: 0.0790\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.1005 - val_loss: 0.0789\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0883 - val_loss: 0.0655\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0771 - val_loss: 0.0614\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0710 - val_loss: 0.0607\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0681 - val_loss: 0.0590\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0685 - val_loss: 0.0581\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0679 - val_loss: 0.0598\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0677 - val_loss: 0.0596\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0658 - val_loss: 0.0594\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0655 - val_loss: 0.0584\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0659 - val_loss: 0.0592\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0675 - val_loss: 0.0590\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0670 - val_loss: 0.0588\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0669 - val_loss: 0.0583\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0671 - val_loss: 0.0591\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0676 - val_loss: 0.0591\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0666 - val_loss: 0.0589\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0662 - val_loss: 0.0591\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0663 - val_loss: 0.0586\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0653 - val_loss: 0.0589\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0651 - val_loss: 0.0582\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0643 - val_loss: 0.0580\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0581\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0654 - val_loss: 0.0583\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0652 - val_loss: 0.0586\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0658 - val_loss: 0.0585\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0661 - val_loss: 0.0588\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0577\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0654 - val_loss: 0.0594\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0589\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0669 - val_loss: 0.0583\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0626 - val_loss: 0.0581\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0643 - val_loss: 0.0580\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0646 - val_loss: 0.0577\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0626 - val_loss: 0.0588\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0648 - val_loss: 0.0581\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0661 - val_loss: 0.0586\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0678 - val_loss: 0.0588\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0594\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0647 - val_loss: 0.0585\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0583\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0579\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0656 - val_loss: 0.0581\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0585\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0637 - val_loss: 0.0594\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0628 - val_loss: 0.0586\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0584\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0583\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0646 - val_loss: 0.0577\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0572\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0658 - val_loss: 0.0584\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0651 - val_loss: 0.0598\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0639 - val_loss: 0.0588\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0576\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0613 - val_loss: 0.0575\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0579\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0593\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0573\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0643 - val_loss: 0.0574\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0669 - val_loss: 0.0580\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0647 - val_loss: 0.0581\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0654 - val_loss: 0.0592\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0628 - val_loss: 0.0581\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0580\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0643 - val_loss: 0.0575\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0627 - val_loss: 0.0583\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0638 - val_loss: 0.0588\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0584\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0576\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0573\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0632 - val_loss: 0.0577\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0579\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0637 - val_loss: 0.0584\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0581\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0646 - val_loss: 0.0584\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0635 - val_loss: 0.0583\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0582\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0596\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0589\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0588\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0613 - val_loss: 0.0583\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0635 - val_loss: 0.0573\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0636 - val_loss: 0.0585\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0635 - val_loss: 0.0584\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0580\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0581\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0585\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0615 - val_loss: 0.0585\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 0.0586\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0614 - val_loss: 0.0584\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0572\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0593\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0613\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0657 - val_loss: 0.0580\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0662 - val_loss: 0.0573\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0653 - val_loss: 0.0599\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0597\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0624 - val_loss: 0.0596\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0633 - val_loss: 0.0581\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0591\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0624 - val_loss: 0.0594\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0649 - val_loss: 0.0577\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0597 - val_loss: 0.0589\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0614 - val_loss: 0.0598\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0629 - val_loss: 0.0580\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0572\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0577\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0579\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0576\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0622 - val_loss: 0.0586\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0632 - val_loss: 0.0596\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0576\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0577\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0641 - val_loss: 0.0589\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0613 - val_loss: 0.0593\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0622 - val_loss: 0.0591\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0587\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0599\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0588\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0616 - val_loss: 0.0580\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0604 - val_loss: 0.0592\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0584\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0612 - val_loss: 0.0576\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0613 - val_loss: 0.0584\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0628 - val_loss: 0.0592\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0629 - val_loss: 0.0594\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0617 - val_loss: 0.0577\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0574\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0594 - val_loss: 0.0590\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0581\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0608 - val_loss: 0.0585\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0580\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0614 - val_loss: 0.0588\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0598\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0574\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0612 - val_loss: 0.0585\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0607 - val_loss: 0.0581\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0583\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0597\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:36:03,834]\u001b[0m Trial 44 finished with value: 0.062095964415632025 and parameters: {'learning_rate': 0.0006461826871784647, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'LeakyReLU', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 42 with value: 0.05986814472207531.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 136ms/step - loss: 0.1704 - val_loss: 0.0831\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.1100 - val_loss: 0.0745\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0920 - val_loss: 0.0723\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0795 - val_loss: 0.0621\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0732 - val_loss: 0.0601\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0682 - val_loss: 0.0589\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0679 - val_loss: 0.0581\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0660 - val_loss: 0.0586\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0662 - val_loss: 0.0592\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0653 - val_loss: 0.0587\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0647 - val_loss: 0.0581\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0651 - val_loss: 0.0581\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0663 - val_loss: 0.0578\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0656 - val_loss: 0.0578\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0655 - val_loss: 0.0577\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0652 - val_loss: 0.0586\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0667 - val_loss: 0.0578\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0663 - val_loss: 0.0582\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0655 - val_loss: 0.0581\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0581\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0648 - val_loss: 0.0583\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0582\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0651 - val_loss: 0.0577\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0642 - val_loss: 0.0576\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0643 - val_loss: 0.0576\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0642 - val_loss: 0.0577\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0578\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0582\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0654 - val_loss: 0.0580\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0576\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0651 - val_loss: 0.0584\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0584\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0661 - val_loss: 0.0579\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0613 - val_loss: 0.0578\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0578\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0635 - val_loss: 0.0576\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0618 - val_loss: 0.0581\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0582\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0652 - val_loss: 0.0583\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0662 - val_loss: 0.0585\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0589\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0637 - val_loss: 0.0579\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0575\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0649 - val_loss: 0.0579\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0630 - val_loss: 0.0581\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0582\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0616 - val_loss: 0.0581\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0587\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0629 - val_loss: 0.0579\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0619 - val_loss: 0.0580\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0577\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0616 - val_loss: 0.0574\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0649 - val_loss: 0.0585\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0591\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0627 - val_loss: 0.0588\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0603 - val_loss: 0.0575\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0580\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0585\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0578\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0573\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0672 - val_loss: 0.0580\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0636 - val_loss: 0.0590\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0645 - val_loss: 0.0601\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0585\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0579\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0581\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0587\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0591\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0589\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0626 - val_loss: 0.0576\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0581\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0582\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0636 - val_loss: 0.0592\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0593\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0634 - val_loss: 0.0592\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0588\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0594\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0590\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0608 - val_loss: 0.0580\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0631 - val_loss: 0.0578\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0653 - val_loss: 0.0587\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0597\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0588\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0611 - val_loss: 0.0586\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0575\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0639 - val_loss: 0.0587\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0622 - val_loss: 0.0582\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0587\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0616 - val_loss: 0.0584\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0589\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0577\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:37:36,684]\u001b[0m Trial 45 finished with value: 0.06026569381690881 and parameters: {'learning_rate': 0.0005901183968126773, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 42 with value: 0.05986814472207531.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 154ms/step - loss: 0.1658 - val_loss: 0.0801\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0999 - val_loss: 0.0773\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0863 - val_loss: 0.0647\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0743 - val_loss: 0.0601\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0684 - val_loss: 0.0602\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0666 - val_loss: 0.0584\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0669 - val_loss: 0.0579\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0657 - val_loss: 0.0592\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0660 - val_loss: 0.0595\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0657 - val_loss: 0.0581\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0578\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0581\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0657 - val_loss: 0.0587\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0656 - val_loss: 0.0579\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0656 - val_loss: 0.0577\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0656 - val_loss: 0.0597\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0668 - val_loss: 0.0587\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0666 - val_loss: 0.0582\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0658 - val_loss: 0.0585\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0582\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0584\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0578\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0581\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0580\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0642 - val_loss: 0.0578\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0644 - val_loss: 0.0582\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0651 - val_loss: 0.0579\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0573\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0649 - val_loss: 0.0590\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0662 - val_loss: 0.0577\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0610 - val_loss: 0.0577\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0640 - val_loss: 0.0576\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0633 - val_loss: 0.0576\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0616 - val_loss: 0.0584\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0635 - val_loss: 0.0584\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0659 - val_loss: 0.0584\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0620 - val_loss: 0.0580\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0638 - val_loss: 0.0586\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0636 - val_loss: 0.0579\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0632 - val_loss: 0.0578\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0648 - val_loss: 0.0582\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0627 - val_loss: 0.0583\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0613 - val_loss: 0.0580\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0614 - val_loss: 0.0578\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0630 - val_loss: 0.0577\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0620 - val_loss: 0.0581\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0638 - val_loss: 0.0577\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0612 - val_loss: 0.0573\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0649 - val_loss: 0.0591\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0600\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0593\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0637 - val_loss: 0.0578\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0597 - val_loss: 0.0575\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0580\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0622 - val_loss: 0.0596\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0629 - val_loss: 0.0582\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0619 - val_loss: 0.0572\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0626 - val_loss: 0.0578\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0667 - val_loss: 0.0591\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0634 - val_loss: 0.0596\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0611\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0590\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0592\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0595\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0617 - val_loss: 0.0604\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0615 - val_loss: 0.0599\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0632 - val_loss: 0.0603\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0621 - val_loss: 0.0588\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0590\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0601\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0635 - val_loss: 0.0609\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0618\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0637 - val_loss: 0.0611\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0634 - val_loss: 0.0613\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0622 - val_loss: 0.0586\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0616 - val_loss: 0.0609\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0618 - val_loss: 0.0601\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0600 - val_loss: 0.0589\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0590\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0647 - val_loss: 0.0610\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0621 - val_loss: 0.0603\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0616 - val_loss: 0.0606\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0605 - val_loss: 0.0605\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0597 - val_loss: 0.0595\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0637 - val_loss: 0.0610\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0605\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0604 - val_loss: 0.0604\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0608 - val_loss: 0.0604\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0608 - val_loss: 0.0608\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0615 - val_loss: 0.0582\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0609 - val_loss: 0.0620\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0632\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0649 - val_loss: 0.0606\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0653 - val_loss: 0.0605\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0637\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0613\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0603\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0622 - val_loss: 0.0594\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0623 - val_loss: 0.0623\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0612 - val_loss: 0.0612\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0591 - val_loss: 0.0621\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0615 - val_loss: 0.0618\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0618 - val_loss: 0.0598\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0608 - val_loss: 0.0592\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0615 - val_loss: 0.0604\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0627 - val_loss: 0.0590\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0596 - val_loss: 0.0599\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0610 - val_loss: 0.0607\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0621 - val_loss: 0.0610\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0614 - val_loss: 0.0588\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0606\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0591 - val_loss: 0.0611\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0607 - val_loss: 0.0616\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0622 - val_loss: 0.0596\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0605 - val_loss: 0.0606\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0600 - val_loss: 0.0619\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0601 - val_loss: 0.0607\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0585 - val_loss: 0.0623\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0611 - val_loss: 0.0608\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0611\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0566\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0603 - val_loss: 0.0616\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0620 - val_loss: 0.0620\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0613\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0614 - val_loss: 0.0593\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0615 - val_loss: 0.0598\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0609 - val_loss: 0.0632\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0579 - val_loss: 0.0605\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0598 - val_loss: 0.0621\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0612 - val_loss: 0.0605\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0601 - val_loss: 0.0612\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0603 - val_loss: 0.0611\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0601 - val_loss: 0.0597\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0603 - val_loss: 0.0632\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0596 - val_loss: 0.0601\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0609 - val_loss: 0.0624\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0608 - val_loss: 0.0613\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:40:07,177]\u001b[0m Trial 46 finished with value: 0.06055149325169046 and parameters: {'learning_rate': 0.0007488368920857778, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 42 with value: 0.05986814472207531.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 151ms/step - loss: 0.1805 - val_loss: 0.0791\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1212 - val_loss: 0.0730\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0968 - val_loss: 0.0780\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0884 - val_loss: 0.0672\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0798 - val_loss: 0.0621\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0722 - val_loss: 0.0608\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0713 - val_loss: 0.0593\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0678 - val_loss: 0.0587\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0673 - val_loss: 0.0589\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0650 - val_loss: 0.0592\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0658 - val_loss: 0.0583\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0658 - val_loss: 0.0581\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0667 - val_loss: 0.0579\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0654 - val_loss: 0.0581\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0656 - val_loss: 0.0581\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0656 - val_loss: 0.0582\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0669 - val_loss: 0.0580\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0659 - val_loss: 0.0597\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0645 - val_loss: 0.0583\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0585\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0653 - val_loss: 0.0588\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0648 - val_loss: 0.0584\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0653 - val_loss: 0.0584\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0579\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0644 - val_loss: 0.0580\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0648 - val_loss: 0.0579\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0646 - val_loss: 0.0581\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0652 - val_loss: 0.0581\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0638 - val_loss: 0.0576\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0653 - val_loss: 0.0581\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0653 - val_loss: 0.0583\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0657 - val_loss: 0.0580\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0618 - val_loss: 0.0581\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0641 - val_loss: 0.0578\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0638 - val_loss: 0.0575\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0622 - val_loss: 0.0582\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0581\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0654 - val_loss: 0.0581\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0664 - val_loss: 0.0585\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0589\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0587\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0581\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0577\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0651 - val_loss: 0.0580\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0582\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0585\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0582\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0623 - val_loss: 0.0582\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0585\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0581\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0579\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0644 - val_loss: 0.0577\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0574\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0650 - val_loss: 0.0581\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0629 - val_loss: 0.0586\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0643 - val_loss: 0.0584\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0608 - val_loss: 0.0577\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0579\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0584\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0636 - val_loss: 0.0583\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0572\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0673 - val_loss: 0.0576\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0579\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0648 - val_loss: 0.0589\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0615 - val_loss: 0.0582\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0580\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0584\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0576\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0627 - val_loss: 0.0574\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0642 - val_loss: 0.0578\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0637 - val_loss: 0.0582\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0641 - val_loss: 0.0585\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0586\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0583\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0584\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0589\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0609 - val_loss: 0.0583\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0632 - val_loss: 0.0578\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0652 - val_loss: 0.0582\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0632 - val_loss: 0.0592\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0589\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0615 - val_loss: 0.0584\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0574\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0639 - val_loss: 0.0584\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0627 - val_loss: 0.0583\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0618 - val_loss: 0.0588\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0584\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0586\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0623 - val_loss: 0.0577\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0632 - val_loss: 0.0589\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0635 - val_loss: 0.0597\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0667 - val_loss: 0.0591\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0663 - val_loss: 0.0597\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0601\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0626 - val_loss: 0.0594\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0591\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0633 - val_loss: 0.0581\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0586\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0585\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0605 - val_loss: 0.0585\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0591\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0620 - val_loss: 0.0593\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0625 - val_loss: 0.0578\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0581\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0630 - val_loss: 0.0580\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0615 - val_loss: 0.0580\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0615 - val_loss: 0.0589\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0591\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0629 - val_loss: 0.0584\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0581\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0614 - val_loss: 0.0592\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0590\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0596\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0610 - val_loss: 0.0590\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0636 - val_loss: 0.0582\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0637 - val_loss: 0.0586\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0622 - val_loss: 0.0573\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0615 - val_loss: 0.0581\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0632 - val_loss: 0.0593\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0593\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0585\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0577\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0600 - val_loss: 0.0591\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0613 - val_loss: 0.0585\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0618 - val_loss: 0.0586\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0615 - val_loss: 0.0588\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0596\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0580\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0583\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0590\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0588\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0597\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:42:34,363]\u001b[0m Trial 47 finished with value: 0.060133759276318144 and parameters: {'learning_rate': 0.00043746896234857333, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 42 with value: 0.05986814472207531.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 143ms/step - loss: 0.1532 - val_loss: 0.0949\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1149 - val_loss: 0.0776\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.1046 - val_loss: 0.0750\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0954 - val_loss: 0.0702\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0888 - val_loss: 0.0681\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0814 - val_loss: 0.0658\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0791 - val_loss: 0.0637\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0743 - val_loss: 0.0612\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0721 - val_loss: 0.0615\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0685 - val_loss: 0.0604\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0695 - val_loss: 0.0609\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0683 - val_loss: 0.0592\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0675 - val_loss: 0.0595\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0672 - val_loss: 0.0592\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0672 - val_loss: 0.0588\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0668 - val_loss: 0.0595\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0662 - val_loss: 0.0588\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0653 - val_loss: 0.0593\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0658 - val_loss: 0.0590\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0649 - val_loss: 0.0595\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0639 - val_loss: 0.0598\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0598\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0592\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0594\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0647 - val_loss: 0.0594\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0594\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0597\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0599\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0612\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0599\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0609 - val_loss: 0.0598\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0635 - val_loss: 0.0604\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0637 - val_loss: 0.0598\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0607\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0636 - val_loss: 0.0600\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0603\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0658 - val_loss: 0.0602\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0619 - val_loss: 0.0611\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0650 - val_loss: 0.0607\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0635 - val_loss: 0.0598\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0597\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0605\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0631 - val_loss: 0.0606\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0629 - val_loss: 0.0607\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0624 - val_loss: 0.0605\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0605\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0639 - val_loss: 0.0612\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0631 - val_loss: 0.0605\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0628 - val_loss: 0.0610\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0629 - val_loss: 0.0613\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0640 - val_loss: 0.0604\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0606\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0611\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0609\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0637 - val_loss: 0.0604\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0608 - val_loss: 0.0600\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0602\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0628 - val_loss: 0.0603\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0634 - val_loss: 0.0605\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0630 - val_loss: 0.0605\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0610\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0668 - val_loss: 0.0613\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0633 - val_loss: 0.0608\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0632 - val_loss: 0.0617\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0623 - val_loss: 0.0603\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0603\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0647 - val_loss: 0.0598\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0625 - val_loss: 0.0601\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0616 - val_loss: 0.0610\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0607\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0604\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0603\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0627 - val_loss: 0.0606\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0645 - val_loss: 0.0601\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0599\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0646 - val_loss: 0.0599\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0616\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0604\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0599\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0637 - val_loss: 0.0593\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0636 - val_loss: 0.0606\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0631 - val_loss: 0.0600\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0625 - val_loss: 0.0598\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0598\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0636 - val_loss: 0.0601\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0602\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0636 - val_loss: 0.0599\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0628 - val_loss: 0.0605\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0626 - val_loss: 0.0603\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0607 - val_loss: 0.0598\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0596\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0620 - val_loss: 0.0604\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0604\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0601\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0597\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0592\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 77). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:44:14,456]\u001b[0m Trial 48 finished with value: 0.062103066371016605 and parameters: {'learning_rate': 0.0006671446599301017, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'LeakyReLU', 'activation2': 'relu', 'layers1': 1, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 42 with value: 0.05986814472207531.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 4s 147ms/step - loss: 0.2908 - val_loss: 0.1365\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.1084 - val_loss: 0.0723\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0968 - val_loss: 0.0727\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0923 - val_loss: 0.0688\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0813 - val_loss: 0.0611\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0793 - val_loss: 0.0655\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0749 - val_loss: 0.0628\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0772 - val_loss: 0.0616\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0751 - val_loss: 0.0645\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0725 - val_loss: 0.0619\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0766 - val_loss: 0.0643\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0743 - val_loss: 0.0741\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0776 - val_loss: 0.0617\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0771 - val_loss: 0.0607\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0754 - val_loss: 0.0634\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0756 - val_loss: 0.0623\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0754 - val_loss: 0.0609\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0702 - val_loss: 0.0627\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0709 - val_loss: 0.0592\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0688 - val_loss: 0.0598\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0672 - val_loss: 0.0603\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0685 - val_loss: 0.0602\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0671 - val_loss: 0.0597\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0675 - val_loss: 0.0604\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0653 - val_loss: 0.0595\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0666 - val_loss: 0.0601\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0686 - val_loss: 0.0605\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0673 - val_loss: 0.0597\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0677 - val_loss: 0.0605\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0687 - val_loss: 0.0593\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0678 - val_loss: 0.0627\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0686 - val_loss: 0.0601\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0695 - val_loss: 0.0611\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0698 - val_loss: 0.0600\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0670 - val_loss: 0.0591\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0676 - val_loss: 0.0599\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0665 - val_loss: 0.0618\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0666 - val_loss: 0.0593\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0654 - val_loss: 0.0589\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0656 - val_loss: 0.0624\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0665 - val_loss: 0.0589\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0695 - val_loss: 0.0593\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0662 - val_loss: 0.0592\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0684 - val_loss: 0.0618\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0699 - val_loss: 0.0593\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0658 - val_loss: 0.0602\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0654 - val_loss: 0.0628\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0698 - val_loss: 0.0591\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0678 - val_loss: 0.0595\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0668 - val_loss: 0.0596\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0681 - val_loss: 0.0616\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0666 - val_loss: 0.0603\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0675 - val_loss: 0.0586\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0693 - val_loss: 0.0599\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0681 - val_loss: 0.0605\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0653 - val_loss: 0.0594\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0671 - val_loss: 0.0600\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0669 - val_loss: 0.0590\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0653 - val_loss: 0.0589\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0667 - val_loss: 0.0592\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0649 - val_loss: 0.0597\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0667 - val_loss: 0.0585\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0647 - val_loss: 0.0593\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0657 - val_loss: 0.0605\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0666 - val_loss: 0.0607\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0672 - val_loss: 0.0581\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0669 - val_loss: 0.0621\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0638 - val_loss: 0.0583\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0649 - val_loss: 0.0582\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0638 - val_loss: 0.0587\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0663 - val_loss: 0.0601\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0670 - val_loss: 0.0589\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0652 - val_loss: 0.0592\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0660 - val_loss: 0.0587\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0648 - val_loss: 0.0595\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0647 - val_loss: 0.0598\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0657 - val_loss: 0.0591\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0672 - val_loss: 0.0593\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0644 - val_loss: 0.0585\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0675 - val_loss: 0.0600\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0648 - val_loss: 0.0581\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0656 - val_loss: 0.0613\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0649 - val_loss: 0.0592\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0651 - val_loss: 0.0578\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0649 - val_loss: 0.0629\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0657 - val_loss: 0.0592\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0660 - val_loss: 0.0594\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0663 - val_loss: 0.0576\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0671 - val_loss: 0.0593\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0638 - val_loss: 0.0587\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0676 - val_loss: 0.0593\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0662 - val_loss: 0.0593\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0654 - val_loss: 0.0591\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0652 - val_loss: 0.0588\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0675 - val_loss: 0.0605\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0648 - val_loss: 0.0598\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0661 - val_loss: 0.0581\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0655 - val_loss: 0.0595\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0632 - val_loss: 0.0583\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0676 - val_loss: 0.0591\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0676 - val_loss: 0.0596\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0653 - val_loss: 0.0599\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0635 - val_loss: 0.0580\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0643 - val_loss: 0.0587\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0685 - val_loss: 0.0576\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0654 - val_loss: 0.0615\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0640 - val_loss: 0.0579\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0669 - val_loss: 0.0587\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0656 - val_loss: 0.0604\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0656 - val_loss: 0.0589\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0652 - val_loss: 0.0577\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0635 - val_loss: 0.0580\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0646 - val_loss: 0.0589\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0638 - val_loss: 0.0576\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0660 - val_loss: 0.0586\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0631 - val_loss: 0.0585\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0654 - val_loss: 0.0584\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0647 - val_loss: 0.0588\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0656 - val_loss: 0.0592\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0662 - val_loss: 0.0593\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0656 - val_loss: 0.0587\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0658 - val_loss: 0.0598\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0643 - val_loss: 0.0578\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0643 - val_loss: 0.0594\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0648 - val_loss: 0.0575\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0677 - val_loss: 0.0601\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0647 - val_loss: 0.0589\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0636 - val_loss: 0.0595\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0635 - val_loss: 0.0576\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0641 - val_loss: 0.0598\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0637 - val_loss: 0.0593\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0652 - val_loss: 0.0575\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0661 - val_loss: 0.0584\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0613 - val_loss: 0.0573\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0649 - val_loss: 0.0589\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0643 - val_loss: 0.0603\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0638 - val_loss: 0.0575\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0653 - val_loss: 0.0583\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0659 - val_loss: 0.0592\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0646 - val_loss: 0.0581\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0662 - val_loss: 0.0594\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0646 - val_loss: 0.0588\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0639 - val_loss: 0.0590\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0638 - val_loss: 0.0629\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0674 - val_loss: 0.0583\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "2/2 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 74). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:46:56,470]\u001b[0m Trial 49 finished with value: 0.060807437286348714 and parameters: {'learning_rate': 0.0008436761331735061, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 42 with value: 0.05986814472207531.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 139ms/step - loss: 0.1717 - val_loss: 0.0826\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.1127 - val_loss: 0.0736\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0930 - val_loss: 0.0742\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0814 - val_loss: 0.0628\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0749 - val_loss: 0.0604\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0689 - val_loss: 0.0595\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0685 - val_loss: 0.0582\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0662 - val_loss: 0.0585\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0664 - val_loss: 0.0590\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0650 - val_loss: 0.0583\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0653 - val_loss: 0.0582\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0664 - val_loss: 0.0578\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0655 - val_loss: 0.0580\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0655 - val_loss: 0.0579\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0652 - val_loss: 0.0582\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0668 - val_loss: 0.0578\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0660 - val_loss: 0.0591\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0647 - val_loss: 0.0582\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0651 - val_loss: 0.0585\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0647 - val_loss: 0.0582\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0580\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0578\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0577\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0578\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0577\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0646 - val_loss: 0.0580\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0651 - val_loss: 0.0578\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0576\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0579\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0650 - val_loss: 0.0581\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0654 - val_loss: 0.0580\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0580\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0639 - val_loss: 0.0576\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0637 - val_loss: 0.0574\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0581\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0581\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0581\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0659 - val_loss: 0.0587\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0616 - val_loss: 0.0589\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0587\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0581\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0579\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0647 - val_loss: 0.0581\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0616 - val_loss: 0.0583\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0620 - val_loss: 0.0583\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0644 - val_loss: 0.0587\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0587\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0627 - val_loss: 0.0583\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0619 - val_loss: 0.0581\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0579\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0575\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0646 - val_loss: 0.0583\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0640 - val_loss: 0.0584\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0603 - val_loss: 0.0577\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0578\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0634 - val_loss: 0.0582\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0593\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0573\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0672 - val_loss: 0.0577\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0582\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0648 - val_loss: 0.0589\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0616 - val_loss: 0.0587\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0613 - val_loss: 0.0578\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0579\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0618 - val_loss: 0.0583\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0585\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0583\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0628 - val_loss: 0.0583\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0624 - val_loss: 0.0579\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0624 - val_loss: 0.0573\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0578\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0580\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0637 - val_loss: 0.0584\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0640 - val_loss: 0.0585\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0633 - val_loss: 0.0586\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0583\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0581\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0608 - val_loss: 0.0581\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0630 - val_loss: 0.0578\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0582\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0624 - val_loss: 0.0589\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0584\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0613 - val_loss: 0.0586\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0576\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0623 - val_loss: 0.0580\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0615 - val_loss: 0.0584\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0615 - val_loss: 0.0583\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0582\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0581\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0583\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0629 - val_loss: 0.0594\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0654 - val_loss: 0.0587\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0646 - val_loss: 0.0597\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0589\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0587\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0614 - val_loss: 0.0593\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0628 - val_loss: 0.0584\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0633 - val_loss: 0.0588\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0602 - val_loss: 0.0584\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0614 - val_loss: 0.0587\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0626 - val_loss: 0.0582\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0630 - val_loss: 0.0579\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0584\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0614 - val_loss: 0.0577\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0587\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0589\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0627 - val_loss: 0.0585\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0584\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0593\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0586\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0590\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0594\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0618 - val_loss: 0.0586\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0610 - val_loss: 0.0587\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0630 - val_loss: 0.0584\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0585\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0572\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0608 - val_loss: 0.0578\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0591\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0622 - val_loss: 0.0591\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0625 - val_loss: 0.0583\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0596 - val_loss: 0.0588\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0609 - val_loss: 0.0585\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0607 - val_loss: 0.0588\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0615 - val_loss: 0.0596\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0610 - val_loss: 0.0585\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0584\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0613 - val_loss: 0.0594\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0586\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:49:22,411]\u001b[0m Trial 50 finished with value: 0.06062389969542785 and parameters: {'learning_rate': 0.0005589171878280936, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 42 with value: 0.05986814472207531.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 146ms/step - loss: 0.1819 - val_loss: 0.0791\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.1218 - val_loss: 0.0733\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0975 - val_loss: 0.0780\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0891 - val_loss: 0.0680\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0804 - val_loss: 0.0624\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0728 - val_loss: 0.0609\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0717 - val_loss: 0.0596\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0680 - val_loss: 0.0587\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0675 - val_loss: 0.0589\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0650 - val_loss: 0.0592\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0659 - val_loss: 0.0583\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0659 - val_loss: 0.0581\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0667 - val_loss: 0.0580\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0654 - val_loss: 0.0581\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0657 - val_loss: 0.0581\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0657 - val_loss: 0.0581\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0669 - val_loss: 0.0580\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0659 - val_loss: 0.0598\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0583\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0645 - val_loss: 0.0584\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0654 - val_loss: 0.0588\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0652 - val_loss: 0.0584\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0648 - val_loss: 0.0579\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0647 - val_loss: 0.0580\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0651 - val_loss: 0.0580\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0638 - val_loss: 0.0577\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0653 - val_loss: 0.0581\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0654 - val_loss: 0.0583\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0656 - val_loss: 0.0580\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0581\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0640 - val_loss: 0.0578\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0638 - val_loss: 0.0575\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0621 - val_loss: 0.0583\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0643 - val_loss: 0.0581\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0663 - val_loss: 0.0585\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0619 - val_loss: 0.0589\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0649 - val_loss: 0.0587\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0580\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0636 - val_loss: 0.0577\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0650 - val_loss: 0.0579\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0634 - val_loss: 0.0581\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0585\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0582\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0624 - val_loss: 0.0583\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0587\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0648 - val_loss: 0.0585\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0630 - val_loss: 0.0582\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0580\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0644 - val_loss: 0.0577\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0574\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0651 - val_loss: 0.0581\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0642 - val_loss: 0.0587\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0586\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0585\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0609 - val_loss: 0.0577\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0579\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0629 - val_loss: 0.0584\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0581\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0587\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0629 - val_loss: 0.0573\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0673 - val_loss: 0.0576\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0635 - val_loss: 0.0578\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0649 - val_loss: 0.0587\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0615 - val_loss: 0.0580\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0640 - val_loss: 0.0579\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0583\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0586\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0584\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0584\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0624 - val_loss: 0.0576\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0629 - val_loss: 0.0574\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0577\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0637 - val_loss: 0.0581\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0585\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0587\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0587\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0634 - val_loss: 0.0583\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0640 - val_loss: 0.0582\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0610 - val_loss: 0.0585\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0579\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0651 - val_loss: 0.0582\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0591\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0587\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0614 - val_loss: 0.0583\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0619 - val_loss: 0.0573\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0582\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0584\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0585\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0624 - val_loss: 0.0576\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0587\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0595\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0665 - val_loss: 0.0592\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0664 - val_loss: 0.0597\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0650 - val_loss: 0.0601\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0626 - val_loss: 0.0590\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0589\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0634 - val_loss: 0.0581\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0586\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0585\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0607 - val_loss: 0.0586\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0625 - val_loss: 0.0579\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0579\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0630 - val_loss: 0.0578\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0577\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0617 - val_loss: 0.0587\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0581\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0584\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0617 - val_loss: 0.0592\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0587\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0617 - val_loss: 0.0595\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0585\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0614 - val_loss: 0.0590\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0582\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0587\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0573\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0613 - val_loss: 0.0580\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0635 - val_loss: 0.0591\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0578\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0603 - val_loss: 0.0589\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0616 - val_loss: 0.0584\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0619 - val_loss: 0.0584\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0587\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0615 - val_loss: 0.0580\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0582\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0626 - val_loss: 0.0588\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0592\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:51:49,913]\u001b[0m Trial 51 finished with value: 0.061014664124740145 and parameters: {'learning_rate': 0.00042552283505593814, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 42 with value: 0.05986814472207531.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 136ms/step - loss: 0.1749 - val_loss: 0.0810\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1169 - val_loss: 0.0727\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0944 - val_loss: 0.0767\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0842 - val_loss: 0.0639\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0767 - val_loss: 0.0609\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0698 - val_loss: 0.0600\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0693 - val_loss: 0.0584\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0666 - val_loss: 0.0584\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0665 - val_loss: 0.0589\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0649 - val_loss: 0.0591\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0582\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0665 - val_loss: 0.0577\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0655 - val_loss: 0.0579\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0654 - val_loss: 0.0579\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0653 - val_loss: 0.0583\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0667 - val_loss: 0.0578\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0662 - val_loss: 0.0590\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0650 - val_loss: 0.0582\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0644 - val_loss: 0.0583\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0651 - val_loss: 0.0585\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0583\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0653 - val_loss: 0.0579\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0645 - val_loss: 0.0577\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0644 - val_loss: 0.0577\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0642 - val_loss: 0.0577\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0649 - val_loss: 0.0577\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0581\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0654 - val_loss: 0.0579\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0636 - val_loss: 0.0575\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0651 - val_loss: 0.0583\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0655 - val_loss: 0.0581\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0661 - val_loss: 0.0576\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0618 - val_loss: 0.0576\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0642 - val_loss: 0.0576\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0637 - val_loss: 0.0574\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0581\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0642 - val_loss: 0.0580\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0653 - val_loss: 0.0582\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0663 - val_loss: 0.0585\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0587\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0579\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0635 - val_loss: 0.0576\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0650 - val_loss: 0.0578\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0632 - val_loss: 0.0580\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0582\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0582\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0588\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0585\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0582\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0619 - val_loss: 0.0579\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0576\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0618 - val_loss: 0.0574\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0650 - val_loss: 0.0584\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0639 - val_loss: 0.0592\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0605 - val_loss: 0.0574\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0578\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0583\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0583\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0571\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0671 - val_loss: 0.0577\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0635 - val_loss: 0.0583\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0592\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0583\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0613 - val_loss: 0.0580\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0579\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0619 - val_loss: 0.0584\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0584\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0619 - val_loss: 0.0585\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0632 - val_loss: 0.0584\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0576\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0575\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0644 - val_loss: 0.0577\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0589\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0589\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0634 - val_loss: 0.0586\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0585\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0584\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0592\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0609 - val_loss: 0.0581\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0576\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0650 - val_loss: 0.0582\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0630 - val_loss: 0.0596\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0589\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0612 - val_loss: 0.0583\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0615 - val_loss: 0.0571\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0582\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0590\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0616 - val_loss: 0.0585\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0614 - val_loss: 0.0588\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0621 - val_loss: 0.0573\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0597\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0599\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0666 - val_loss: 0.0586\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0667 - val_loss: 0.0592\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0650 - val_loss: 0.0605\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0599\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0583\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0628 - val_loss: 0.0590\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0591\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0637 - val_loss: 0.0584\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0602 - val_loss: 0.0589\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0617 - val_loss: 0.0597\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0577\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0583\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0631 - val_loss: 0.0581\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0610 - val_loss: 0.0583\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0611 - val_loss: 0.0593\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0627 - val_loss: 0.0597\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0625 - val_loss: 0.0584\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0623 - val_loss: 0.0584\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0639 - val_loss: 0.0591\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0611 - val_loss: 0.0602\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0596\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0634 - val_loss: 0.0593\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0614 - val_loss: 0.0602\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0613 - val_loss: 0.0592\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0604 - val_loss: 0.0598\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0587\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0631 - val_loss: 0.0592\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0573\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0590\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0606\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0605\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0582\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0623 - val_loss: 0.0599\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0594 - val_loss: 0.0598\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0595\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0608 - val_loss: 0.0595\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0593\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0610 - val_loss: 0.0597\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0619 - val_loss: 0.0608\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0610 - val_loss: 0.0586\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0622 - val_loss: 0.0593\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0611 - val_loss: 0.0601\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0596\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0615 - val_loss: 0.0603\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:54:16,113]\u001b[0m Trial 52 finished with value: 0.05977768964957389 and parameters: {'learning_rate': 0.0005023904425644004, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 140ms/step - loss: 0.1743 - val_loss: 0.0814\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.1161 - val_loss: 0.0728\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0941 - val_loss: 0.0762\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0836 - val_loss: 0.0636\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0763 - val_loss: 0.0607\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0696 - val_loss: 0.0599\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0691 - val_loss: 0.0583\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0666 - val_loss: 0.0585\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0666 - val_loss: 0.0589\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0649 - val_loss: 0.0591\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0652 - val_loss: 0.0582\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0665 - val_loss: 0.0578\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0655 - val_loss: 0.0579\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0655 - val_loss: 0.0579\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0653 - val_loss: 0.0584\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0667 - val_loss: 0.0578\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0662 - val_loss: 0.0589\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0651 - val_loss: 0.0582\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0583\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0651 - val_loss: 0.0585\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0584\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0653 - val_loss: 0.0580\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0578\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0577\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0578\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0648 - val_loss: 0.0578\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0581\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0654 - val_loss: 0.0580\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0636 - val_loss: 0.0576\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0652 - val_loss: 0.0583\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0652 - val_loss: 0.0584\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0661 - val_loss: 0.0579\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0579\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0577\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0575\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0620 - val_loss: 0.0581\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0581\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0581\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0663 - val_loss: 0.0586\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0619 - val_loss: 0.0588\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0646 - val_loss: 0.0588\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0639 - val_loss: 0.0580\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0635 - val_loss: 0.0576\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0650 - val_loss: 0.0579\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0582\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0581\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0620 - val_loss: 0.0581\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0587\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0645 - val_loss: 0.0585\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0627 - val_loss: 0.0579\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0578\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0576\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0573\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0648 - val_loss: 0.0584\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0639 - val_loss: 0.0592\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0582\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0604 - val_loss: 0.0575\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0578\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0634 - val_loss: 0.0584\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0570\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0674 - val_loss: 0.0575\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0581\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0645 - val_loss: 0.0590\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0621 - val_loss: 0.0581\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0612 - val_loss: 0.0580\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0638 - val_loss: 0.0579\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0583\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0637 - val_loss: 0.0585\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0633 - val_loss: 0.0586\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0578\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0575\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0577\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0581\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0642 - val_loss: 0.0588\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0589\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0634 - val_loss: 0.0590\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0635 - val_loss: 0.0585\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0585\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0622 - val_loss: 0.0586\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0591\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0587\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0609 - val_loss: 0.0582\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0578\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0651 - val_loss: 0.0585\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0632 - val_loss: 0.0594\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0632 - val_loss: 0.0587\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0613 - val_loss: 0.0585\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0616 - val_loss: 0.0573\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0587\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0617 - val_loss: 0.0592\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0585\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0613 - val_loss: 0.0587\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0621 - val_loss: 0.0576\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0631 - val_loss: 0.0592\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0599\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0662 - val_loss: 0.0593\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0661 - val_loss: 0.0592\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0600\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0597\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0631 - val_loss: 0.0587\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0627 - val_loss: 0.0594\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0623 - val_loss: 0.0594\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0585\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0603 - val_loss: 0.0588\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0617 - val_loss: 0.0596\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0578\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0629 - val_loss: 0.0582\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0629 - val_loss: 0.0581\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0579\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0615 - val_loss: 0.0588\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0630 - val_loss: 0.0596\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0624 - val_loss: 0.0584\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0639 - val_loss: 0.0590\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0608 - val_loss: 0.0599\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0596\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0630 - val_loss: 0.0591\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0592\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0603\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0613 - val_loss: 0.0593\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0603 - val_loss: 0.0600\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0588\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0596\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0577\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0614 - val_loss: 0.0596\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0625 - val_loss: 0.0607\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0600\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0621 - val_loss: 0.0585\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0582\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0599\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0592 - val_loss: 0.0601\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0618 - val_loss: 0.0597\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0607 - val_loss: 0.0597\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0613 - val_loss: 0.0602\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0609\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0607 - val_loss: 0.0589\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0599\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0611 - val_loss: 0.0599\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0598\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0615 - val_loss: 0.0610\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:56:41,361]\u001b[0m Trial 53 finished with value: 0.05997878760861784 and parameters: {'learning_rate': 0.000511992578142914, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 160ms/step - loss: 0.1745 - val_loss: 0.0812\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1164 - val_loss: 0.0728\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0942 - val_loss: 0.0763\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0838 - val_loss: 0.0637\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0765 - val_loss: 0.0608\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0696 - val_loss: 0.0600\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0692 - val_loss: 0.0583\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0666 - val_loss: 0.0585\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0667 - val_loss: 0.0589\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0649 - val_loss: 0.0591\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0652 - val_loss: 0.0582\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0665 - val_loss: 0.0578\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0656 - val_loss: 0.0580\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0655 - val_loss: 0.0580\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0652 - val_loss: 0.0584\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0668 - val_loss: 0.0579\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0661 - val_loss: 0.0591\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0650 - val_loss: 0.0583\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0644 - val_loss: 0.0584\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0651 - val_loss: 0.0586\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0584\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0652 - val_loss: 0.0580\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0644 - val_loss: 0.0578\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0577\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0643 - val_loss: 0.0578\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0649 - val_loss: 0.0578\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0581\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0653 - val_loss: 0.0580\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0576\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0652 - val_loss: 0.0582\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0652 - val_loss: 0.0582\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0661 - val_loss: 0.0578\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0579\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0577\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0637 - val_loss: 0.0574\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0581\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0581\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0653 - val_loss: 0.0582\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0664 - val_loss: 0.0586\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0646 - val_loss: 0.0587\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0638 - val_loss: 0.0580\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0635 - val_loss: 0.0577\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0649 - val_loss: 0.0580\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0632 - val_loss: 0.0582\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0616 - val_loss: 0.0582\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0619 - val_loss: 0.0583\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0644 - val_loss: 0.0587\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0619 - val_loss: 0.0580\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0577\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0574\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0650 - val_loss: 0.0586\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0592\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0602 - val_loss: 0.0576\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0621 - val_loss: 0.0580\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0588\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0584\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0624 - val_loss: 0.0582\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0626 - val_loss: 0.0572\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0673 - val_loss: 0.0576\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0633 - val_loss: 0.0586\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0596\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0612 - val_loss: 0.0582\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0580\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0583\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0586\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0580\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0625 - val_loss: 0.0578\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0587\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0588\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0585\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0643 - val_loss: 0.0587\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0583\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0626 - val_loss: 0.0588\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0609 - val_loss: 0.0582\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0579\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0650 - val_loss: 0.0585\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0596\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0631 - val_loss: 0.0590\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0614 - val_loss: 0.0590\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0577\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0588\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0615 - val_loss: 0.0593\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0615 - val_loss: 0.0588\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0612 - val_loss: 0.0592\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0622 - val_loss: 0.0576\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0628 - val_loss: 0.0603\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0610\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0663 - val_loss: 0.0594\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0663 - val_loss: 0.0598\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0650 - val_loss: 0.0605\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0619 - val_loss: 0.0603\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0596\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0629 - val_loss: 0.0586\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0626 - val_loss: 0.0592\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0591\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0584\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0602 - val_loss: 0.0591\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0619 - val_loss: 0.0599\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0582\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0627 - val_loss: 0.0588\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0629 - val_loss: 0.0583\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0608 - val_loss: 0.0588\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0612 - val_loss: 0.0599\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0627 - val_loss: 0.0599\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0636 - val_loss: 0.0594\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0609 - val_loss: 0.0603\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0622 - val_loss: 0.0600\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0634 - val_loss: 0.0596\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0614 - val_loss: 0.0607\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0612 - val_loss: 0.0598\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0602 - val_loss: 0.0605\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0591\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0628 - val_loss: 0.0598\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0578\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0612 - val_loss: 0.0598\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0626 - val_loss: 0.0606\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0605\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0622 - val_loss: 0.0604\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0589 - val_loss: 0.0606\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0614 - val_loss: 0.0600\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0606 - val_loss: 0.0598\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0601\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0611 - val_loss: 0.0607\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0615\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0607 - val_loss: 0.0587\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0604\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0604\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0609\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 16:59:09,407]\u001b[0m Trial 54 finished with value: 0.05991068248732612 and parameters: {'learning_rate': 0.0005087234814437888, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 132ms/step - loss: 0.1728 - val_loss: 0.1004\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.1153 - val_loss: 0.0775\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.1076 - val_loss: 0.0750\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0973 - val_loss: 0.0715\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0915 - val_loss: 0.0705\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0835 - val_loss: 0.0673\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0823 - val_loss: 0.0647\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0778 - val_loss: 0.0628\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0759 - val_loss: 0.0623\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0716 - val_loss: 0.0620\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0716 - val_loss: 0.0618\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0712 - val_loss: 0.0608\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0699 - val_loss: 0.0604\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0694 - val_loss: 0.0602\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0687 - val_loss: 0.0597\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0679 - val_loss: 0.0602\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0678 - val_loss: 0.0595\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0662 - val_loss: 0.0601\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0654 - val_loss: 0.0601\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0671 - val_loss: 0.0595\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0657 - val_loss: 0.0601\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0650 - val_loss: 0.0599\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0643 - val_loss: 0.0603\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0601\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0648 - val_loss: 0.0596\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0652 - val_loss: 0.0598\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0651 - val_loss: 0.0595\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0657 - val_loss: 0.0594\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0646 - val_loss: 0.0596\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0594\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0593\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0644 - val_loss: 0.0605\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0599\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0593\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0625 - val_loss: 0.0603\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0594\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0646 - val_loss: 0.0595\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0661 - val_loss: 0.0595\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0607\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0653 - val_loss: 0.0602\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0596\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0595\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0599\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0639 - val_loss: 0.0599\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0637 - val_loss: 0.0602\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0629 - val_loss: 0.0601\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0600\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0607\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0603\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0607\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0609\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0604\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0602\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0650 - val_loss: 0.0607\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0650 - val_loss: 0.0609\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0611\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0608\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0613 - val_loss: 0.0606\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0608\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0608\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0637 - val_loss: 0.0612\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0607\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0612\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0664 - val_loss: 0.0613\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0611\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0617\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0609\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0629 - val_loss: 0.0609\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0608\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0627 - val_loss: 0.0608\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0608\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0612\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0631 - val_loss: 0.0608\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0629 - val_loss: 0.0607\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0609\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0648 - val_loss: 0.0605\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0603\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0646 - val_loss: 0.0607\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0619\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0608\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0641 - val_loss: 0.0610\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0639 - val_loss: 0.0603\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0635 - val_loss: 0.0609\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0605\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0627 - val_loss: 0.0605\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0627 - val_loss: 0.0606\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0607\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0608\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0609\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0630 - val_loss: 0.0621\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0628 - val_loss: 0.0613\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0612 - val_loss: 0.0606\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0643 - val_loss: 0.0604\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0623 - val_loss: 0.0610\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0616 - val_loss: 0.0606\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0622 - val_loss: 0.0609\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0621 - val_loss: 0.0609\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0599\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0599\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0623 - val_loss: 0.0604\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0650 - val_loss: 0.0623\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0608\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0655 - val_loss: 0.0618\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0622\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0613\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0607\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0619\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0621\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0604\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0604\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0611\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0637 - val_loss: 0.0602\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0624 - val_loss: 0.0601\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0631 - val_loss: 0.0606\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0623 - val_loss: 0.0603\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0602\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0604\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0610\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0619 - val_loss: 0.0606\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0628 - val_loss: 0.0608\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0616\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0612\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0627 - val_loss: 0.0609\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0626 - val_loss: 0.0604\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0631 - val_loss: 0.0608\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0613 - val_loss: 0.0607\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0609\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0612\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0608\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0637 - val_loss: 0.0607\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0628 - val_loss: 0.0606\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0616 - val_loss: 0.0610\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0616 - val_loss: 0.0604\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0623 - val_loss: 0.0605\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0620 - val_loss: 0.0604\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0622 - val_loss: 0.0602\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0637 - val_loss: 0.0604\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0601 - val_loss: 0.0600\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0603\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0609 - val_loss: 0.0610\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0613\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0607\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0609\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0605\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0616\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0615 - val_loss: 0.0607\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0628 - val_loss: 0.0607\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0617\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:01:23,685]\u001b[0m Trial 55 finished with value: 0.062092350394078184 and parameters: {'learning_rate': 0.000509074051098885, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 1, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 156ms/step - loss: 0.2817 - val_loss: 0.2067\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.1472 - val_loss: 0.0671\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0991 - val_loss: 0.0666\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0960 - val_loss: 0.0708\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0864 - val_loss: 0.0677\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0810 - val_loss: 0.0627\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0788 - val_loss: 0.0632\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0806 - val_loss: 0.0651\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0785 - val_loss: 0.0618\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0735 - val_loss: 0.0628\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0780 - val_loss: 0.0651\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0760 - val_loss: 0.0722\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0803 - val_loss: 0.0634\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0787 - val_loss: 0.0617\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0779 - val_loss: 0.0642\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0783 - val_loss: 0.0648\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0768 - val_loss: 0.0651\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0726 - val_loss: 0.0625\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0733 - val_loss: 0.0610\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0716 - val_loss: 0.0599\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0688 - val_loss: 0.0611\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0702 - val_loss: 0.0606\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0681 - val_loss: 0.0602\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0687 - val_loss: 0.0605\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0659 - val_loss: 0.0600\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0677 - val_loss: 0.0603\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0702 - val_loss: 0.0612\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0680 - val_loss: 0.0597\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0687 - val_loss: 0.0610\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0690 - val_loss: 0.0594\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0688 - val_loss: 0.0639\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0687 - val_loss: 0.0601\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0707 - val_loss: 0.0628\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0701 - val_loss: 0.0602\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0677 - val_loss: 0.0594\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0686 - val_loss: 0.0608\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0675 - val_loss: 0.0611\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0675 - val_loss: 0.0600\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0665 - val_loss: 0.0595\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0668 - val_loss: 0.0639\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0681 - val_loss: 0.0594\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0712 - val_loss: 0.0593\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0678 - val_loss: 0.0603\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0686 - val_loss: 0.0618\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0703 - val_loss: 0.0595\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0662 - val_loss: 0.0607\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0660 - val_loss: 0.0635\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0707 - val_loss: 0.0593\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0686 - val_loss: 0.0607\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0674 - val_loss: 0.0597\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0659 - val_loss: 0.0591\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0687 - val_loss: 0.0619\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0674 - val_loss: 0.0602\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0683 - val_loss: 0.0591\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0697 - val_loss: 0.0606\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0685 - val_loss: 0.0602\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0663 - val_loss: 0.0605\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0677 - val_loss: 0.0605\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0682 - val_loss: 0.0601\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0663 - val_loss: 0.0595\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0671 - val_loss: 0.0595\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0658 - val_loss: 0.0602\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0676 - val_loss: 0.0592\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0656 - val_loss: 0.0597\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0667 - val_loss: 0.0607\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0674 - val_loss: 0.0620\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0681 - val_loss: 0.0587\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0682 - val_loss: 0.0629\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0647 - val_loss: 0.0588\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0658 - val_loss: 0.0591\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0643 - val_loss: 0.0590\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0666 - val_loss: 0.0605\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0652 - val_loss: 0.0600\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0687 - val_loss: 0.0597\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0661 - val_loss: 0.0602\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0673 - val_loss: 0.0597\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0665 - val_loss: 0.0598\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0653 - val_loss: 0.0591\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0653 - val_loss: 0.0604\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0671 - val_loss: 0.0596\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0679 - val_loss: 0.0599\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0653 - val_loss: 0.0594\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0686 - val_loss: 0.0604\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0660 - val_loss: 0.0589\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0670 - val_loss: 0.0617\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0658 - val_loss: 0.0601\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0656 - val_loss: 0.0584\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0659 - val_loss: 0.0637\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0665 - val_loss: 0.0596\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0673 - val_loss: 0.0599\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0674 - val_loss: 0.0584\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0680 - val_loss: 0.0595\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0646 - val_loss: 0.0593\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0683 - val_loss: 0.0596\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0673 - val_loss: 0.0602\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0667 - val_loss: 0.0597\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0657 - val_loss: 0.0594\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0679 - val_loss: 0.0609\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0661 - val_loss: 0.0603\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0667 - val_loss: 0.0586\n",
            "2/2 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 74). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:03:15,565]\u001b[0m Trial 56 finished with value: 0.06167984400506969 and parameters: {'learning_rate': 0.00047910186422709815, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 138ms/step - loss: 0.1901 - val_loss: 0.0811\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1231 - val_loss: 0.0758\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1020 - val_loss: 0.0766\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0923 - val_loss: 0.0726\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0845 - val_loss: 0.0645\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0766 - val_loss: 0.0620\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0748 - val_loss: 0.0616\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0704 - val_loss: 0.0594\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0692 - val_loss: 0.0591\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0656 - val_loss: 0.0594\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0666 - val_loss: 0.0585\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0665 - val_loss: 0.0582\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0667 - val_loss: 0.0584\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0655 - val_loss: 0.0581\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0662 - val_loss: 0.0580\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0663 - val_loss: 0.0583\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0667 - val_loss: 0.0585\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0656 - val_loss: 0.0597\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0641 - val_loss: 0.0583\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0651 - val_loss: 0.0583\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0655 - val_loss: 0.0591\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0583\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0649 - val_loss: 0.0585\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0646 - val_loss: 0.0579\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0581\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0578\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0579\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0580\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0577\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0653 - val_loss: 0.0579\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0587\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0583\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0621 - val_loss: 0.0581\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0643 - val_loss: 0.0578\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0575\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0584\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0579\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0579\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0657 - val_loss: 0.0583\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0617 - val_loss: 0.0586\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0581\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0638 - val_loss: 0.0579\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0648 - val_loss: 0.0579\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0635 - val_loss: 0.0579\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0582\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0621 - val_loss: 0.0580\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0627 - val_loss: 0.0581\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0583\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0647 - val_loss: 0.0584\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0581\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0622 - val_loss: 0.0580\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0643 - val_loss: 0.0578\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0574\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0578\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0583\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0581\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0582\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0615 - val_loss: 0.0576\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0576\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0629 - val_loss: 0.0583\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0638 - val_loss: 0.0579\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0633 - val_loss: 0.0575\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0671 - val_loss: 0.0573\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0578\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0651 - val_loss: 0.0579\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0580\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0575\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0638 - val_loss: 0.0575\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0577\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0648 - val_loss: 0.0580\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0630 - val_loss: 0.0579\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0633 - val_loss: 0.0579\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0577\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0572\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0642 - val_loss: 0.0574\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0575\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0577\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0578\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0581\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0634 - val_loss: 0.0576\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0640 - val_loss: 0.0578\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0624 - val_loss: 0.0576\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0578\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0618 - val_loss: 0.0579\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0636 - val_loss: 0.0577\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0654 - val_loss: 0.0579\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0583\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0580\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0580\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0624 - val_loss: 0.0574\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0577\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0631 - val_loss: 0.0575\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0624 - val_loss: 0.0577\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0624 - val_loss: 0.0579\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0576\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0578\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0578\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0583\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0654 - val_loss: 0.0583\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0590\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0645 - val_loss: 0.0581\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0581\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0581\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0579\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0631 - val_loss: 0.0579\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0639 - val_loss: 0.0584\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0614 - val_loss: 0.0578\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0580\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0588\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0579\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0576\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0622 - val_loss: 0.0580\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0623 - val_loss: 0.0574\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0578\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0580\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0578\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0629 - val_loss: 0.0582\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0579\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0580\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0584\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0578\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0631 - val_loss: 0.0581\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0579\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0636 - val_loss: 0.0578\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0583\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0573\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0574\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0651 - val_loss: 0.0584\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0581\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0578\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0631 - val_loss: 0.0579\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0577\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0609 - val_loss: 0.0581\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0587\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0579\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0626 - val_loss: 0.0577\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0580\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0581\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0580\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0625 - val_loss: 0.0582\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0582\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0577\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:05:31,965]\u001b[0m Trial 57 finished with value: 0.06049335834475459 and parameters: {'learning_rate': 0.0003686239041083253, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 142ms/step - loss: 0.1885 - val_loss: 0.0804\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1232 - val_loss: 0.0753\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.1009 - val_loss: 0.0771\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0917 - val_loss: 0.0716\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0833 - val_loss: 0.0637\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0756 - val_loss: 0.0616\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0738 - val_loss: 0.0611\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0695 - val_loss: 0.0591\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0685 - val_loss: 0.0590\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0653 - val_loss: 0.0593\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0662 - val_loss: 0.0584\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0662 - val_loss: 0.0582\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0668 - val_loss: 0.0582\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0655 - val_loss: 0.0582\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0659 - val_loss: 0.0581\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0660 - val_loss: 0.0582\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0669 - val_loss: 0.0583\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0658 - val_loss: 0.0601\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0583\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0584\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0656 - val_loss: 0.0590\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0649 - val_loss: 0.0583\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0651 - val_loss: 0.0586\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0646 - val_loss: 0.0580\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0647 - val_loss: 0.0578\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0648 - val_loss: 0.0580\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0651 - val_loss: 0.0580\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0576\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0654 - val_loss: 0.0579\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0655 - val_loss: 0.0584\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0582\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0577\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0574\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0584\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0581\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0655 - val_loss: 0.0581\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0662 - val_loss: 0.0585\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0619 - val_loss: 0.0589\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0651 - val_loss: 0.0584\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0579\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0636 - val_loss: 0.0577\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0650 - val_loss: 0.0579\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0581\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0584\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0581\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0581\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0585\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0649 - val_loss: 0.0585\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0580\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0645 - val_loss: 0.0577\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0574\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0653 - val_loss: 0.0580\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0644 - val_loss: 0.0585\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0584\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0584\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0614 - val_loss: 0.0577\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0578\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0580\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0580\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0577\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0673 - val_loss: 0.0576\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0577\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0653 - val_loss: 0.0583\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0581\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0579\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0578\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0624 - val_loss: 0.0581\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0646 - val_loss: 0.0584\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0583\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0633 - val_loss: 0.0582\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0626 - val_loss: 0.0576\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0630 - val_loss: 0.0575\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0641 - val_loss: 0.0576\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0638 - val_loss: 0.0577\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0645 - val_loss: 0.0581\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0635 - val_loss: 0.0580\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0584\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0612 - val_loss: 0.0584\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0633 - val_loss: 0.0579\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0587\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0615 - val_loss: 0.0586\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0620 - val_loss: 0.0575\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0629 - val_loss: 0.0579\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0621 - val_loss: 0.0580\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0617 - val_loss: 0.0582\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0625 - val_loss: 0.0576\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0583\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0666 - val_loss: 0.0588\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0661 - val_loss: 0.0596\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0649 - val_loss: 0.0595\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0627 - val_loss: 0.0588\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0580\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0584\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0627 - val_loss: 0.0584\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0642 - val_loss: 0.0582\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0610 - val_loss: 0.0582\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0618 - val_loss: 0.0588\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0591\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0579\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0631 - val_loss: 0.0577\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0578\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0576\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0615 - val_loss: 0.0585\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0589\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0581\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0579\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0582\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0618 - val_loss: 0.0590\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0586\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0627 - val_loss: 0.0584\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0593\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0625 - val_loss: 0.0584\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0587\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0638 - val_loss: 0.0582\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0640 - val_loss: 0.0583\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0622 - val_loss: 0.0573\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0579\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0588\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0626 - val_loss: 0.0577\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0581\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0603 - val_loss: 0.0588\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0625 - val_loss: 0.0589\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0616 - val_loss: 0.0586\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0621 - val_loss: 0.0582\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0613 - val_loss: 0.0584\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0591\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0615 - val_loss: 0.0580\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0584\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0632 - val_loss: 0.0581\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:07:56,720]\u001b[0m Trial 58 finished with value: 0.06112352323358207 and parameters: {'learning_rate': 0.0003777925040459018, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 129ms/step - loss: 0.1510 - val_loss: 0.1099\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.1224 - val_loss: 0.0846\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.1139 - val_loss: 0.0788\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1063 - val_loss: 0.0768\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1026 - val_loss: 0.0759\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0932 - val_loss: 0.0729\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0916 - val_loss: 0.0706\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0871 - val_loss: 0.0667\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0839 - val_loss: 0.0654\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0775 - val_loss: 0.0637\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0765 - val_loss: 0.0613\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0745 - val_loss: 0.0604\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0715 - val_loss: 0.0595\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0713 - val_loss: 0.0586\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0697 - val_loss: 0.0584\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0685 - val_loss: 0.0581\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0689 - val_loss: 0.0579\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0669 - val_loss: 0.0578\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0659 - val_loss: 0.0578\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0665 - val_loss: 0.0578\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0660 - val_loss: 0.0579\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0579\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0652 - val_loss: 0.0579\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0580\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0579\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0648 - val_loss: 0.0579\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0579\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0656 - val_loss: 0.0579\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0579\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0648 - val_loss: 0.0578\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0651 - val_loss: 0.0578\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0643 - val_loss: 0.0581\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0650 - val_loss: 0.0580\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0621 - val_loss: 0.0579\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0641 - val_loss: 0.0581\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0579\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0582\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0651 - val_loss: 0.0580\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0579\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0660 - val_loss: 0.0579\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0579\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0655 - val_loss: 0.0582\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0644 - val_loss: 0.0582\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0641 - val_loss: 0.0579\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0647 - val_loss: 0.0579\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0639 - val_loss: 0.0579\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0581\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0580\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0636 - val_loss: 0.0580\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0650 - val_loss: 0.0581\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0646 - val_loss: 0.0582\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0581\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0628 - val_loss: 0.0583\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0650 - val_loss: 0.0581\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0578\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0655 - val_loss: 0.0581\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0649 - val_loss: 0.0583\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0648 - val_loss: 0.0583\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0581\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0580\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0581\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0580\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0582\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0580\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0668 - val_loss: 0.0580\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0643 - val_loss: 0.0582\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0585\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0644 - val_loss: 0.0581\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0631 - val_loss: 0.0580\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0644 - val_loss: 0.0582\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0635 - val_loss: 0.0580\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0582\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0634 - val_loss: 0.0580\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0639 - val_loss: 0.0577\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0576\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0642 - val_loss: 0.0576\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0650 - val_loss: 0.0577\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0579\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0579\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0640 - val_loss: 0.0580\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0632 - val_loss: 0.0579\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0637 - val_loss: 0.0579\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0580\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0579\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0641 - val_loss: 0.0577\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0655 - val_loss: 0.0578\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0580\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0622 - val_loss: 0.0578\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0631 - val_loss: 0.0577\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0577\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0578\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0577\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0629 - val_loss: 0.0579\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0578\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0576\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0577\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0631 - val_loss: 0.0581\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0580\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0634 - val_loss: 0.0577\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0651 - val_loss: 0.0579\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0579\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0632 - val_loss: 0.0581\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0581\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0581\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0638 - val_loss: 0.0580\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0638 - val_loss: 0.0576\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0617 - val_loss: 0.0578\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0577\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0631 - val_loss: 0.0579\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0580\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0632 - val_loss: 0.0575\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0631 - val_loss: 0.0575\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0626 - val_loss: 0.0573\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0575\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0577\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0631 - val_loss: 0.0577\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0579\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0579\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0628 - val_loss: 0.0580\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0622 - val_loss: 0.0580\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0582\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0578\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0578\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0631 - val_loss: 0.0581\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0579\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0638 - val_loss: 0.0575\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0578\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0628 - val_loss: 0.0574\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0617 - val_loss: 0.0574\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0642 - val_loss: 0.0576\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0579\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0576\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0575\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0637 - val_loss: 0.0574\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0613 - val_loss: 0.0576\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0582\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0581\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0581\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0622 - val_loss: 0.0579\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0628 - val_loss: 0.0583\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0622 - val_loss: 0.0584\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0629 - val_loss: 0.0579\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0577\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0638 - val_loss: 0.0581\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0626 - val_loss: 0.0579\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:10:12,764]\u001b[0m Trial 59 finished with value: 0.06148252455636771 and parameters: {'learning_rate': 0.00027448822891256743, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'relu', 'layers1': 3, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 144ms/step - loss: 0.1000 - val_loss: 0.0716\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0831 - val_loss: 0.0666\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0815 - val_loss: 0.0616\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0806 - val_loss: 0.0621\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0761 - val_loss: 0.0625\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0745 - val_loss: 0.0625\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0724 - val_loss: 0.0607\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0745 - val_loss: 0.0602\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0720 - val_loss: 0.0621\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0693 - val_loss: 0.0590\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0725 - val_loss: 0.0600\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0725 - val_loss: 0.0658\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0740 - val_loss: 0.0596\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0700 - val_loss: 0.0607\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0713 - val_loss: 0.0601\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0719 - val_loss: 0.0597\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0715 - val_loss: 0.0597\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0690 - val_loss: 0.0645\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0699 - val_loss: 0.0589\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0678 - val_loss: 0.0609\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0663 - val_loss: 0.0590\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0692 - val_loss: 0.0600\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0670 - val_loss: 0.0590\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0670 - val_loss: 0.0591\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0656 - val_loss: 0.0593\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0675 - val_loss: 0.0592\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0674 - val_loss: 0.0588\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0668 - val_loss: 0.0593\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0665 - val_loss: 0.0594\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0683 - val_loss: 0.0587\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0680 - val_loss: 0.0617\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0684 - val_loss: 0.0591\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0690 - val_loss: 0.0591\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0709 - val_loss: 0.0600\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0658 - val_loss: 0.0574\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0660 - val_loss: 0.0597\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0660 - val_loss: 0.0601\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0658 - val_loss: 0.0576\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0656 - val_loss: 0.0578\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0659 - val_loss: 0.0589\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0681 - val_loss: 0.0575\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0657 - val_loss: 0.0579\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0673 - val_loss: 0.0604\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0702 - val_loss: 0.0575\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0645 - val_loss: 0.0586\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0631 - val_loss: 0.0615\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0693 - val_loss: 0.0578\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0678 - val_loss: 0.0584\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0663 - val_loss: 0.0584\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0654 - val_loss: 0.0568\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0666 - val_loss: 0.0606\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0654 - val_loss: 0.0581\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0661 - val_loss: 0.0574\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0678 - val_loss: 0.0585\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0665 - val_loss: 0.0581\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0642 - val_loss: 0.0569\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0662 - val_loss: 0.0585\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0649 - val_loss: 0.0572\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0650 - val_loss: 0.0580\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0659 - val_loss: 0.0568\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0652 - val_loss: 0.0579\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0653 - val_loss: 0.0571\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0622 - val_loss: 0.0566\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0634 - val_loss: 0.0599\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0649 - val_loss: 0.0576\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0650 - val_loss: 0.0567\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0637 - val_loss: 0.0594\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0641 - val_loss: 0.0564\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0649 - val_loss: 0.0562\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0640 - val_loss: 0.0564\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0659 - val_loss: 0.0578\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0638 - val_loss: 0.0571\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0663 - val_loss: 0.0580\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0632 - val_loss: 0.0567\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0644 - val_loss: 0.0566\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0636 - val_loss: 0.0574\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0645 - val_loss: 0.0554\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0653 - val_loss: 0.0586\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0649 - val_loss: 0.0558\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0669 - val_loss: 0.0581\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0623 - val_loss: 0.0558\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0664 - val_loss: 0.0581\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0638 - val_loss: 0.0554\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0644 - val_loss: 0.0596\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0651 - val_loss: 0.0563\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0645 - val_loss: 0.0556\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0630 - val_loss: 0.0605\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0644 - val_loss: 0.0559\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0648 - val_loss: 0.0577\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0651 - val_loss: 0.0548\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0662 - val_loss: 0.0571\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0627 - val_loss: 0.0555\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0656 - val_loss: 0.0567\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0639 - val_loss: 0.0570\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0643 - val_loss: 0.0562\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0630 - val_loss: 0.0559\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0661 - val_loss: 0.0565\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0631 - val_loss: 0.0575\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0638 - val_loss: 0.0554\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0647 - val_loss: 0.0569\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0625 - val_loss: 0.0546\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0658 - val_loss: 0.0570\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0663 - val_loss: 0.0559\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0627 - val_loss: 0.0579\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0619 - val_loss: 0.0552\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0635 - val_loss: 0.0563\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0670 - val_loss: 0.0551\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0655 - val_loss: 0.0589\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0628 - val_loss: 0.0556\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0654 - val_loss: 0.0555\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0636 - val_loss: 0.0581\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0631 - val_loss: 0.0555\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0652 - val_loss: 0.0552\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0632 - val_loss: 0.0554\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0622 - val_loss: 0.0560\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0624 - val_loss: 0.0547\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0649 - val_loss: 0.0558\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0604 - val_loss: 0.0555\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0651 - val_loss: 0.0555\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0635 - val_loss: 0.0558\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0641 - val_loss: 0.0565\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0638 - val_loss: 0.0555\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0632 - val_loss: 0.0559\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0645 - val_loss: 0.0562\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0641 - val_loss: 0.0546\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0651 - val_loss: 0.0561\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0634 - val_loss: 0.0542\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0656 - val_loss: 0.0580\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0634 - val_loss: 0.0547\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0627 - val_loss: 0.0563\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0610 - val_loss: 0.0539\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0635 - val_loss: 0.0550\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0632 - val_loss: 0.0570\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0632 - val_loss: 0.0545\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0636 - val_loss: 0.0551\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0604 - val_loss: 0.0541\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0628 - val_loss: 0.0555\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0619 - val_loss: 0.0565\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0616 - val_loss: 0.0535\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0634 - val_loss: 0.0549\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0640 - val_loss: 0.0557\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0638 - val_loss: 0.0536\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0644 - val_loss: 0.0565\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0636 - val_loss: 0.0553\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0620 - val_loss: 0.0545\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0583\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0549\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0608 - val_loss: 0.0545\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0615 - val_loss: 0.0547\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 74). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:12:55,204]\u001b[0m Trial 60 finished with value: 0.06280951194791826 and parameters: {'learning_rate': 0.0005172821061773843, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 1, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 135ms/step - loss: 0.1788 - val_loss: 0.0795\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.1202 - val_loss: 0.0727\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0961 - val_loss: 0.0779\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0873 - val_loss: 0.0662\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0789 - val_loss: 0.0617\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0715 - val_loss: 0.0606\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0707 - val_loss: 0.0589\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0674 - val_loss: 0.0586\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0671 - val_loss: 0.0589\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0649 - val_loss: 0.0592\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0656 - val_loss: 0.0583\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0657 - val_loss: 0.0582\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0667 - val_loss: 0.0579\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0654 - val_loss: 0.0581\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0656 - val_loss: 0.0581\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0655 - val_loss: 0.0582\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0669 - val_loss: 0.0579\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0660 - val_loss: 0.0596\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0646 - val_loss: 0.0584\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0585\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0653 - val_loss: 0.0588\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0585\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0583\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0644 - val_loss: 0.0579\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0579\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0580\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0580\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0647 - val_loss: 0.0582\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0653 - val_loss: 0.0582\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0637 - val_loss: 0.0577\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0654 - val_loss: 0.0583\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0658 - val_loss: 0.0581\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0582\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0578\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0574\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0581\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0581\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0655 - val_loss: 0.0582\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0663 - val_loss: 0.0586\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0589\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0588\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0580\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0577\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0650 - val_loss: 0.0580\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0633 - val_loss: 0.0581\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0627 - val_loss: 0.0584\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0617 - val_loss: 0.0581\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0581\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0645 - val_loss: 0.0584\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0580\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0619 - val_loss: 0.0579\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0576\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0618 - val_loss: 0.0573\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0582\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0585\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0604 - val_loss: 0.0576\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0579\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0635 - val_loss: 0.0582\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0572\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0674 - val_loss: 0.0578\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0633 - val_loss: 0.0582\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0647 - val_loss: 0.0591\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0614 - val_loss: 0.0581\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0639 - val_loss: 0.0581\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0584\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0630 - val_loss: 0.0588\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0626 - val_loss: 0.0579\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0625 - val_loss: 0.0577\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0578\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0586\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0587\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0633 - val_loss: 0.0584\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0586\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0583\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0591\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0588\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0610 - val_loss: 0.0584\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0631 - val_loss: 0.0579\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0652 - val_loss: 0.0583\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0632 - val_loss: 0.0591\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0588\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0614 - val_loss: 0.0587\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0617 - val_loss: 0.0577\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0586\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0589\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0619 - val_loss: 0.0584\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0586\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0579\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0596\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0663 - val_loss: 0.0590\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0662 - val_loss: 0.0597\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0650 - val_loss: 0.0600\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0625 - val_loss: 0.0596\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0623 - val_loss: 0.0594\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0583\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0630 - val_loss: 0.0588\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0624 - val_loss: 0.0588\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0640 - val_loss: 0.0584\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0604 - val_loss: 0.0584\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0593\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0621 - val_loss: 0.0580\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0583\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0580\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0614 - val_loss: 0.0580\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0588\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0593\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0586\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0583\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0587\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0594\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0591\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0636 - val_loss: 0.0593\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0625 - val_loss: 0.0593\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0614 - val_loss: 0.0599\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0586\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0611 - val_loss: 0.0594\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0634 - val_loss: 0.0586\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0636 - val_loss: 0.0590\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0622 - val_loss: 0.0574\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0585\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0593\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0595\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0579\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0589\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0598 - val_loss: 0.0594\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0620 - val_loss: 0.0593\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0610 - val_loss: 0.0589\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0618 - val_loss: 0.0590\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0611 - val_loss: 0.0594\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0601\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0588\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0595\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0597\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0595\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0603\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:15:21,426]\u001b[0m Trial 61 finished with value: 0.06045936963653656 and parameters: {'learning_rate': 0.00045466059368538445, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 141ms/step - loss: 0.1718 - val_loss: 0.0826\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1126 - val_loss: 0.0737\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0930 - val_loss: 0.0741\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0811 - val_loss: 0.0626\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0745 - val_loss: 0.0603\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0687 - val_loss: 0.0593\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0683 - val_loss: 0.0581\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0661 - val_loss: 0.0586\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0663 - val_loss: 0.0591\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0652 - val_loss: 0.0589\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0649 - val_loss: 0.0582\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0652 - val_loss: 0.0581\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0664 - val_loss: 0.0578\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0655 - val_loss: 0.0578\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0655 - val_loss: 0.0578\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0651 - val_loss: 0.0586\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0667 - val_loss: 0.0579\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0662 - val_loss: 0.0584\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0654 - val_loss: 0.0582\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0647 - val_loss: 0.0582\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0645 - val_loss: 0.0582\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0652 - val_loss: 0.0578\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0577\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0577\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0642 - val_loss: 0.0578\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0577\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0581\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0654 - val_loss: 0.0579\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0575\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0582\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0648 - val_loss: 0.0583\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0663 - val_loss: 0.0579\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0578\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0577\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0574\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0619 - val_loss: 0.0580\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0582\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0652 - val_loss: 0.0582\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0660 - val_loss: 0.0586\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0619 - val_loss: 0.0585\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0589\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0637 - val_loss: 0.0580\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0576\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0648 - val_loss: 0.0581\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0583\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0614 - val_loss: 0.0582\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0581\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0590\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0581\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0580\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0578\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0615 - val_loss: 0.0573\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0587\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0638 - val_loss: 0.0594\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0587\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0642 - val_loss: 0.0582\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0601 - val_loss: 0.0576\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0581\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0624 - val_loss: 0.0588\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0588\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0582\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0573\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0673 - val_loss: 0.0575\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0637 - val_loss: 0.0582\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0593\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0619 - val_loss: 0.0582\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0611 - val_loss: 0.0580\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0588\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0637 - val_loss: 0.0585\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0633 - val_loss: 0.0588\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0627 - val_loss: 0.0577\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0577\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0643 - val_loss: 0.0577\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0635 - val_loss: 0.0584\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0589\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0588\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0583\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0610 - val_loss: 0.0582\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0577\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0650 - val_loss: 0.0585\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0591\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0612 - val_loss: 0.0583\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0612 - val_loss: 0.0576\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0638 - val_loss: 0.0587\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0589\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0584\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0588\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0574\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0599\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0630 - val_loss: 0.0604\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0657 - val_loss: 0.0587\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0660 - val_loss: 0.0590\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0647 - val_loss: 0.0601\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0601\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0626 - val_loss: 0.0594\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0581\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0600 - val_loss: 0.0587\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0617 - val_loss: 0.0596\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0596\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0618 - val_loss: 0.0578\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0591\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0627 - val_loss: 0.0583\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0605 - val_loss: 0.0586\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0612 - val_loss: 0.0592\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0621 - val_loss: 0.0595\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0583\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0638 - val_loss: 0.0594\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0607 - val_loss: 0.0602\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0618 - val_loss: 0.0600\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0596\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0594\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0612 - val_loss: 0.0612\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0613 - val_loss: 0.0600\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0602 - val_loss: 0.0608\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0604\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0579\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0606\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0622 - val_loss: 0.0611\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0629 - val_loss: 0.0602\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0588\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0586\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0610\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0587 - val_loss: 0.0606\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0603\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0603 - val_loss: 0.0605\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0606\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0608 - val_loss: 0.0609\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0620 - val_loss: 0.0617\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0606 - val_loss: 0.0589\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0608 - val_loss: 0.0611\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0610\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0609 - val_loss: 0.0614\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:17:40,908]\u001b[0m Trial 62 finished with value: 0.060307031408755804 and parameters: {'learning_rate': 0.0005577849333839947, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'linear', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 146ms/step - loss: 0.2575 - val_loss: 0.1688\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.1425 - val_loss: 0.0862\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.1074 - val_loss: 0.0736\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0971 - val_loss: 0.0710\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0902 - val_loss: 0.0712\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0824 - val_loss: 0.0670\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0800 - val_loss: 0.0647\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0755 - val_loss: 0.0629\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0741 - val_loss: 0.0621\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0702 - val_loss: 0.0617\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0689 - val_loss: 0.0609\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0682 - val_loss: 0.0596\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0668 - val_loss: 0.0596\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0666 - val_loss: 0.0592\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0672 - val_loss: 0.0586\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0662 - val_loss: 0.0599\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0665 - val_loss: 0.0586\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0652 - val_loss: 0.0596\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0650 - val_loss: 0.0596\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0642 - val_loss: 0.0593\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0594\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0648 - val_loss: 0.0590\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0656 - val_loss: 0.0589\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0652 - val_loss: 0.0589\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0600\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0647 - val_loss: 0.0591\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0617 - val_loss: 0.0592\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0591\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0587\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0621 - val_loss: 0.0601\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0646 - val_loss: 0.0588\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0662 - val_loss: 0.0590\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0619 - val_loss: 0.0598\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0653 - val_loss: 0.0593\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0586\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0594\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0627 - val_loss: 0.0588\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0649 - val_loss: 0.0594\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0633 - val_loss: 0.0592\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0580\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0652 - val_loss: 0.0592\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0600\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0630 - val_loss: 0.0593\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0643 - val_loss: 0.0590\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0605 - val_loss: 0.0581\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0582\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0624 - val_loss: 0.0594\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0640 - val_loss: 0.0587\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0628 - val_loss: 0.0594\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0630 - val_loss: 0.0579\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0666 - val_loss: 0.0588\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0592\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0604\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0616 - val_loss: 0.0593\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0585\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0582\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0591\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0619 - val_loss: 0.0590\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0592\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0583\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0639 - val_loss: 0.0588\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0588\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0598\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0638 - val_loss: 0.0598\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0635 - val_loss: 0.0599\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0628 - val_loss: 0.0589\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0638 - val_loss: 0.0586\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0626 - val_loss: 0.0583\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0618 - val_loss: 0.0598\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0603 - val_loss: 0.0579\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0582\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0621 - val_loss: 0.0587\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0611 - val_loss: 0.0594\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0607 - val_loss: 0.0578\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0636 - val_loss: 0.0596\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0591\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0608 - val_loss: 0.0595\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0607 - val_loss: 0.0589\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0607 - val_loss: 0.0595\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0614 - val_loss: 0.0578\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0604\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0624 - val_loss: 0.0605\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0656 - val_loss: 0.0604\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0608\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0610\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0609\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0608\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0625 - val_loss: 0.0605\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0581\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0596 - val_loss: 0.0590\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0596\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0613 - val_loss: 0.0606\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0579\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0595\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0585\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0601 - val_loss: 0.0590\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0608 - val_loss: 0.0597\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0599\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0590\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0602\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0603 - val_loss: 0.0612\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0597\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0594\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0615 - val_loss: 0.0588\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0610 - val_loss: 0.0607\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0608 - val_loss: 0.0592\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0599 - val_loss: 0.0612\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0629 - val_loss: 0.0609\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0579\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0609 - val_loss: 0.0610\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0626 - val_loss: 0.0613\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0628 - val_loss: 0.0606\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0596\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0585\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0600\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0586 - val_loss: 0.0604\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0609 - val_loss: 0.0609\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0606 - val_loss: 0.0601\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0609\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0606 - val_loss: 0.0607\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0605\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0605 - val_loss: 0.0589\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0605\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0603 - val_loss: 0.0612\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0615 - val_loss: 0.0602\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0611 - val_loss: 0.0612\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 81). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:20:01,354]\u001b[0m Trial 63 finished with value: 0.06030905140366405 and parameters: {'learning_rate': 0.0005275997938563806, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'LeakyReLU', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 153ms/step - loss: 0.2619 - val_loss: 0.2044\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1864 - val_loss: 0.1347\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.1196 - val_loss: 0.0761\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.1016 - val_loss: 0.0708\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0924 - val_loss: 0.0717\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0823 - val_loss: 0.0659\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0788 - val_loss: 0.0635\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0731 - val_loss: 0.0613\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0715 - val_loss: 0.0602\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0668 - val_loss: 0.0606\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0668 - val_loss: 0.0599\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0664 - val_loss: 0.0592\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0659 - val_loss: 0.0592\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0658 - val_loss: 0.0586\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0666 - val_loss: 0.0586\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0664 - val_loss: 0.0599\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0667 - val_loss: 0.0592\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0652 - val_loss: 0.0606\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0597\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0590\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0653 - val_loss: 0.0598\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0591\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0590\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0584\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0649 - val_loss: 0.0585\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0588\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0635 - val_loss: 0.0581\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0649 - val_loss: 0.0593\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0647 - val_loss: 0.0597\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0646 - val_loss: 0.0591\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0610 - val_loss: 0.0588\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0641 - val_loss: 0.0582\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0617 - val_loss: 0.0597\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0590\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0645 - val_loss: 0.0591\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0659 - val_loss: 0.0593\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0617 - val_loss: 0.0586\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0591\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0635 - val_loss: 0.0588\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0631 - val_loss: 0.0582\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0617 - val_loss: 0.0590\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0613 - val_loss: 0.0582\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0581\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0638 - val_loss: 0.0593\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0584\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0585\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0615 - val_loss: 0.0576\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0602\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0588\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0591\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0599 - val_loss: 0.0579\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0587\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0599\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0626 - val_loss: 0.0575\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0669 - val_loss: 0.0593\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0595\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0639 - val_loss: 0.0604\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0613 - val_loss: 0.0586\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0610 - val_loss: 0.0586\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0635 - val_loss: 0.0588\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0593\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0636 - val_loss: 0.0590\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0598\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0631 - val_loss: 0.0604\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0579\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0615 - val_loss: 0.0577\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0579\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0633 - val_loss: 0.0594\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0596\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0640 - val_loss: 0.0599\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0599\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0619 - val_loss: 0.0593\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0622 - val_loss: 0.0588\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0614 - val_loss: 0.0601\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0616 - val_loss: 0.0598\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0602 - val_loss: 0.0588\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0623 - val_loss: 0.0589\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0608\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0625 - val_loss: 0.0592\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0605 - val_loss: 0.0592\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0606 - val_loss: 0.0586\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0631 - val_loss: 0.0598\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0611 - val_loss: 0.0595\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0610 - val_loss: 0.0598\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0611 - val_loss: 0.0595\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0606 - val_loss: 0.0597\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0610 - val_loss: 0.0586\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0608\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0607\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0635 - val_loss: 0.0600\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0638 - val_loss: 0.0605\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0613\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0612\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0613 - val_loss: 0.0603\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0597\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0623 - val_loss: 0.0607\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0612 - val_loss: 0.0610\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0589\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0596 - val_loss: 0.0595\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0614 - val_loss: 0.0603\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0612 - val_loss: 0.0613\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0612 - val_loss: 0.0574\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0612 - val_loss: 0.0604\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0575\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0596 - val_loss: 0.0592\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0600 - val_loss: 0.0597\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0603\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0612 - val_loss: 0.0585\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0597\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0603\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0600 - val_loss: 0.0610\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0607 - val_loss: 0.0604\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0614 - val_loss: 0.0593\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0614 - val_loss: 0.0591\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0608 - val_loss: 0.0608\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0608 - val_loss: 0.0590\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0597 - val_loss: 0.0611\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0629 - val_loss: 0.0608\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0595\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0594 - val_loss: 0.0605\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0598\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0608 - val_loss: 0.0594\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0622 - val_loss: 0.0588\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0613 - val_loss: 0.0579\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0610 - val_loss: 0.0600\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0592 - val_loss: 0.0599\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0606 - val_loss: 0.0605\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0602 - val_loss: 0.0596\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0609 - val_loss: 0.0605\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0595 - val_loss: 0.0596\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0599 - val_loss: 0.0586\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0590 - val_loss: 0.0596\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0613 - val_loss: 0.0623\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0603 - val_loss: 0.0613\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0609 - val_loss: 0.0604\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0604\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:22:27,330]\u001b[0m Trial 64 finished with value: 0.06006956279200838 and parameters: {'learning_rate': 0.0006098379859561052, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 149ms/step - loss: 0.2622 - val_loss: 0.2051\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.1875 - val_loss: 0.1366\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.1211 - val_loss: 0.0771\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1017 - val_loss: 0.0711\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0935 - val_loss: 0.0720\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0831 - val_loss: 0.0667\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0795 - val_loss: 0.0632\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0740 - val_loss: 0.0615\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0722 - val_loss: 0.0606\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0673 - val_loss: 0.0600\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0672 - val_loss: 0.0596\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0667 - val_loss: 0.0585\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0656 - val_loss: 0.0591\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0659 - val_loss: 0.0586\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0667 - val_loss: 0.0585\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0666 - val_loss: 0.0600\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0666 - val_loss: 0.0588\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0652 - val_loss: 0.0603\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0596\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0646 - val_loss: 0.0588\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0652 - val_loss: 0.0595\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0591\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0589\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0639 - val_loss: 0.0586\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0647 - val_loss: 0.0586\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0646 - val_loss: 0.0587\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0649 - val_loss: 0.0586\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0612 - val_loss: 0.0587\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0639 - val_loss: 0.0586\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0637 - val_loss: 0.0585\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0617 - val_loss: 0.0596\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0655 - val_loss: 0.0590\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0615 - val_loss: 0.0589\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0651 - val_loss: 0.0592\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0636 - val_loss: 0.0592\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0634 - val_loss: 0.0584\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0629 - val_loss: 0.0590\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0620 - val_loss: 0.0593\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0616 - val_loss: 0.0585\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0642 - val_loss: 0.0593\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0631 - val_loss: 0.0588\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0623 - val_loss: 0.0588\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0640 - val_loss: 0.0588\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0619 - val_loss: 0.0578\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0647 - val_loss: 0.0592\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0639 - val_loss: 0.0599\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0627 - val_loss: 0.0591\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0639 - val_loss: 0.0589\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0602 - val_loss: 0.0587\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0619 - val_loss: 0.0584\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0601\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0636 - val_loss: 0.0585\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0627 - val_loss: 0.0589\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0583\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0666 - val_loss: 0.0584\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0634 - val_loss: 0.0595\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0638 - val_loss: 0.0601\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0618 - val_loss: 0.0590\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0613 - val_loss: 0.0592\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0634 - val_loss: 0.0581\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0619 - val_loss: 0.0588\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0623 - val_loss: 0.0593\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0627 - val_loss: 0.0592\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0619 - val_loss: 0.0578\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0631 - val_loss: 0.0580\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0588\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0635 - val_loss: 0.0593\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0639 - val_loss: 0.0595\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0632 - val_loss: 0.0591\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0594\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0619 - val_loss: 0.0582\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0618 - val_loss: 0.0590\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0593\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0604 - val_loss: 0.0583\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0626 - val_loss: 0.0579\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0596\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0609 - val_loss: 0.0589\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0610 - val_loss: 0.0586\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0617 - val_loss: 0.0590\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0612 - val_loss: 0.0588\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0613 - val_loss: 0.0592\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0607 - val_loss: 0.0587\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0610 - val_loss: 0.0584\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0618 - val_loss: 0.0594\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0639 - val_loss: 0.0595\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0633 - val_loss: 0.0601\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0641 - val_loss: 0.0598\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0623 - val_loss: 0.0599\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0609 - val_loss: 0.0600\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0592\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0627 - val_loss: 0.0589\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0595\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0624 - val_loss: 0.0590\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0598 - val_loss: 0.0588\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0613 - val_loss: 0.0593\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0600\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0588\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0624 - val_loss: 0.0583\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0592\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0607 - val_loss: 0.0580\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0607 - val_loss: 0.0592\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0599\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0623 - val_loss: 0.0589\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0630 - val_loss: 0.0593\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0607 - val_loss: 0.0599\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0606 - val_loss: 0.0596\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0618 - val_loss: 0.0590\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0617 - val_loss: 0.0591\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0609 - val_loss: 0.0603\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0610 - val_loss: 0.0590\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0609 - val_loss: 0.0595\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0627 - val_loss: 0.0593\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0632 - val_loss: 0.0598\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0617 - val_loss: 0.0578\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0601 - val_loss: 0.0590\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0628 - val_loss: 0.0603\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0615 - val_loss: 0.0605\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0623 - val_loss: 0.0598\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0617 - val_loss: 0.0590\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0591\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0594 - val_loss: 0.0599\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0611 - val_loss: 0.0603\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0612 - val_loss: 0.0594\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0613 - val_loss: 0.0596\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0600 - val_loss: 0.0599\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0609 - val_loss: 0.0603\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0603 - val_loss: 0.0586\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0605 - val_loss: 0.0609\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0618 - val_loss: 0.0600\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0622 - val_loss: 0.0601\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:25:02,067]\u001b[0m Trial 65 finished with value: 0.06144067515128643 and parameters: {'learning_rate': 0.0006063384530939923, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'relu', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.3, 'epochs': 150}. Best is trial 52 with value: 0.05977768964957389.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 152ms/step - loss: 0.2341 - val_loss: 0.1594\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.1384 - val_loss: 0.0845\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.1094 - val_loss: 0.0750\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0997 - val_loss: 0.0748\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0928 - val_loss: 0.0708\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0842 - val_loss: 0.0666\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0812 - val_loss: 0.0631\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0744 - val_loss: 0.0612\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0718 - val_loss: 0.0599\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0666 - val_loss: 0.0606\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0681 - val_loss: 0.0604\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0657 - val_loss: 0.0603\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0660 - val_loss: 0.0593\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0661 - val_loss: 0.0591\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0663 - val_loss: 0.0594\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0652 - val_loss: 0.0596\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0663 - val_loss: 0.0601\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0650 - val_loss: 0.0602\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0597\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0646 - val_loss: 0.0603\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0658 - val_loss: 0.0602\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0589\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0591\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0593\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0602\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0647 - val_loss: 0.0595\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0652 - val_loss: 0.0593\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0639 - val_loss: 0.0587\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0651 - val_loss: 0.0597\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0647 - val_loss: 0.0607\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0647 - val_loss: 0.0594\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0613 - val_loss: 0.0593\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0635 - val_loss: 0.0587\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0646 - val_loss: 0.0596\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0658 - val_loss: 0.0622\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0658 - val_loss: 0.0590\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0638 - val_loss: 0.0597\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0630 - val_loss: 0.0586\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0642 - val_loss: 0.0588\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0628 - val_loss: 0.0595\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0619 - val_loss: 0.0591\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0612 - val_loss: 0.0586\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0612 - val_loss: 0.0590\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0646 - val_loss: 0.0607\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0645 - val_loss: 0.0593\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0634 - val_loss: 0.0586\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0619 - val_loss: 0.0593\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0647 - val_loss: 0.0590\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0642 - val_loss: 0.0597\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0635 - val_loss: 0.0606\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0639 - val_loss: 0.0588\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0601 - val_loss: 0.0585\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0615 - val_loss: 0.0592\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0613 - val_loss: 0.0595\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0628 - val_loss: 0.0589\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0591\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0626 - val_loss: 0.0580\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0658 - val_loss: 0.0598\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0636 - val_loss: 0.0600\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0645 - val_loss: 0.0609\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0609 - val_loss: 0.0579\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0616 - val_loss: 0.0595\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0633 - val_loss: 0.0582\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0620 - val_loss: 0.0593\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0637 - val_loss: 0.0591\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0622 - val_loss: 0.0598\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0635 - val_loss: 0.0600\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0586\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0586\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0599\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0634 - val_loss: 0.0579\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0626 - val_loss: 0.0600\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0620 - val_loss: 0.0590\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0614 - val_loss: 0.0599\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0602 - val_loss: 0.0589\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0631 - val_loss: 0.0584\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0636 - val_loss: 0.0601\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0629 - val_loss: 0.0591\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0624 - val_loss: 0.0590\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0605 - val_loss: 0.0586\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0606 - val_loss: 0.0585\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0627 - val_loss: 0.0601\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0623 - val_loss: 0.0599\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0614 - val_loss: 0.0584\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0612 - val_loss: 0.0582\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0608 - val_loss: 0.0586\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0610 - val_loss: 0.0577\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:26:46,918]\u001b[0m Trial 66 finished with value: 0.05880281624670264 and parameters: {'learning_rate': 0.00040344880360689266, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 66 with value: 0.05880281624670264.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 150ms/step - loss: 0.2471 - val_loss: 0.1824\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.1638 - val_loss: 0.1127\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.1142 - val_loss: 0.0779\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.1072 - val_loss: 0.0738\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.1001 - val_loss: 0.0757\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0913 - val_loss: 0.0713\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0887 - val_loss: 0.0675\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0837 - val_loss: 0.0658\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0801 - val_loss: 0.0632\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0728 - val_loss: 0.0613\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0722 - val_loss: 0.0613\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0698 - val_loss: 0.0599\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0677 - val_loss: 0.0597\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0685 - val_loss: 0.0597\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0674 - val_loss: 0.0589\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0661 - val_loss: 0.0594\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0672 - val_loss: 0.0590\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0650 - val_loss: 0.0594\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0643 - val_loss: 0.0592\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0652 - val_loss: 0.0595\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0656 - val_loss: 0.0595\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0649 - val_loss: 0.0590\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0651 - val_loss: 0.0588\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0647 - val_loss: 0.0589\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0647 - val_loss: 0.0590\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0653 - val_loss: 0.0588\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0650 - val_loss: 0.0588\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0643 - val_loss: 0.0585\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0648 - val_loss: 0.0590\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0642 - val_loss: 0.0596\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0648 - val_loss: 0.0591\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0615 - val_loss: 0.0592\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0642 - val_loss: 0.0584\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0647 - val_loss: 0.0595\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0649 - val_loss: 0.0595\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0662 - val_loss: 0.0612\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0627 - val_loss: 0.0593\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0663 - val_loss: 0.0594\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0595\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0585\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0645 - val_loss: 0.0589\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0596\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0626 - val_loss: 0.0593\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0618 - val_loss: 0.0587\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0645 - val_loss: 0.0600\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0646 - val_loss: 0.0591\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0638 - val_loss: 0.0584\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0624 - val_loss: 0.0588\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0649 - val_loss: 0.0586\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0634 - val_loss: 0.0588\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0649 - val_loss: 0.0584\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0610 - val_loss: 0.0586\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0631 - val_loss: 0.0584\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0629 - val_loss: 0.0593\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0633 - val_loss: 0.0579\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0667 - val_loss: 0.0585\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0638 - val_loss: 0.0590\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0645 - val_loss: 0.0601\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0621 - val_loss: 0.0582\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0593\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0591\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0647 - val_loss: 0.0594\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0635 - val_loss: 0.0597\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0625 - val_loss: 0.0579\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0624 - val_loss: 0.0578\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0638 - val_loss: 0.0581\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0636 - val_loss: 0.0593\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0643 - val_loss: 0.0584\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0640 - val_loss: 0.0588\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0635 - val_loss: 0.0594\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0633 - val_loss: 0.0588\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0632 - val_loss: 0.0581\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0628 - val_loss: 0.0580\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0623 - val_loss: 0.0593\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0629 - val_loss: 0.0586\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0613 - val_loss: 0.0587\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0636 - val_loss: 0.0578\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0645 - val_loss: 0.0592\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0633 - val_loss: 0.0598\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0630 - val_loss: 0.0594\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0615 - val_loss: 0.0593\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0614 - val_loss: 0.0585\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0593\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0585\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0584\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0617 - val_loss: 0.0586\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0586\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0581\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:28:33,111]\u001b[0m Trial 67 finished with value: 0.06015701429944101 and parameters: {'learning_rate': 0.0003041135656900576, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 66 with value: 0.05880281624670264.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 4s 142ms/step - loss: 0.2239 - val_loss: 0.1398\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.1250 - val_loss: 0.0775\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.1060 - val_loss: 0.0726\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0944 - val_loss: 0.0725\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0878 - val_loss: 0.0662\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0790 - val_loss: 0.0639\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0757 - val_loss: 0.0606\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0696 - val_loss: 0.0596\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0680 - val_loss: 0.0602\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0652 - val_loss: 0.0623\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0669 - val_loss: 0.0597\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0651 - val_loss: 0.0591\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0653 - val_loss: 0.0590\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0659 - val_loss: 0.0588\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0662 - val_loss: 0.0592\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0652 - val_loss: 0.0600\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0663 - val_loss: 0.0594\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0649 - val_loss: 0.0603\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0639 - val_loss: 0.0595\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0597\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0659 - val_loss: 0.0606\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0589\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0646 - val_loss: 0.0589\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0599\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0638 - val_loss: 0.0601\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0597\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0597\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0588\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0597\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0650 - val_loss: 0.0601\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0654 - val_loss: 0.0592\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0618 - val_loss: 0.0596\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0600\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0637 - val_loss: 0.0587\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0616 - val_loss: 0.0600\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0636 - val_loss: 0.0593\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0664 - val_loss: 0.0617\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0657 - val_loss: 0.0592\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0634 - val_loss: 0.0602\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0637 - val_loss: 0.0593\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0605\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0609 - val_loss: 0.0588\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0611 - val_loss: 0.0589\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0608\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0642 - val_loss: 0.0590\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0581\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0586\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0647 - val_loss: 0.0595\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0635 - val_loss: 0.0610\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0586\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0585\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0599 - val_loss: 0.0579\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0613 - val_loss: 0.0589\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0611 - val_loss: 0.0598\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0579\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0593\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0630 - val_loss: 0.0573\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0653 - val_loss: 0.0592\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0606\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0614\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0611 - val_loss: 0.0581\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0612 - val_loss: 0.0596\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0631 - val_loss: 0.0579\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0594\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0597\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0632 - val_loss: 0.0609\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0620 - val_loss: 0.0586\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0590\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0583\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0633 - val_loss: 0.0603\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0604\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0596\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0618 - val_loss: 0.0590\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0616 - val_loss: 0.0597\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0593\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0618 - val_loss: 0.0581\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0593 - val_loss: 0.0580\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0602\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0582\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0604 - val_loss: 0.0576\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0606 - val_loss: 0.0583\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0602\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0594\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0608 - val_loss: 0.0579\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0609 - val_loss: 0.0579\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0607 - val_loss: 0.0596\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0606 - val_loss: 0.0570\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:30:08,651]\u001b[0m Trial 68 finished with value: 0.05924656805288328 and parameters: {'learning_rate': 0.0004891255246817184, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 66 with value: 0.05880281624670264.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 144ms/step - loss: 0.1584 - val_loss: 0.1041\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.1226 - val_loss: 0.0811\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.1133 - val_loss: 0.0778\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.1045 - val_loss: 0.0758\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0991 - val_loss: 0.0737\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0905 - val_loss: 0.0708\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0882 - val_loss: 0.0689\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0835 - val_loss: 0.0661\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0806 - val_loss: 0.0655\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0764 - val_loss: 0.0639\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0758 - val_loss: 0.0635\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0745 - val_loss: 0.0622\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0724 - val_loss: 0.0613\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0721 - val_loss: 0.0612\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0709 - val_loss: 0.0603\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0701 - val_loss: 0.0603\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0698 - val_loss: 0.0598\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0672 - val_loss: 0.0603\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0673 - val_loss: 0.0603\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0678 - val_loss: 0.0598\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0667 - val_loss: 0.0601\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0661 - val_loss: 0.0599\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0656 - val_loss: 0.0603\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0650 - val_loss: 0.0600\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0653 - val_loss: 0.0596\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0657 - val_loss: 0.0600\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0655 - val_loss: 0.0598\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0666 - val_loss: 0.0596\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0653 - val_loss: 0.0596\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0652 - val_loss: 0.0593\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0652 - val_loss: 0.0594\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0604\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0652 - val_loss: 0.0598\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0597\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0599\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0627 - val_loss: 0.0604\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0599\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0645 - val_loss: 0.0597\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0670 - val_loss: 0.0596\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0629 - val_loss: 0.0603\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0656 - val_loss: 0.0608\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0642 - val_loss: 0.0601\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0596\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0642 - val_loss: 0.0601\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0637 - val_loss: 0.0605\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0607\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0603\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0604\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0611\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0638 - val_loss: 0.0606\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0636 - val_loss: 0.0608\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0612\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0605\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0627 - val_loss: 0.0600\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0651 - val_loss: 0.0605\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0652 - val_loss: 0.0608\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0608\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0644 - val_loss: 0.0603\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0617 - val_loss: 0.0600\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0627 - val_loss: 0.0602\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0602\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0604\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0640 - val_loss: 0.0604\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0639 - val_loss: 0.0612\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0671 - val_loss: 0.0614\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0642 - val_loss: 0.0611\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0631 - val_loss: 0.0618\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0608\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0630 - val_loss: 0.0604\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0654 - val_loss: 0.0602\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0601\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0605\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0603\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0602\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0603\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0633 - val_loss: 0.0604\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0648 - val_loss: 0.0603\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0630 - val_loss: 0.0598\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0654 - val_loss: 0.0599\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0612\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0603\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0599\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0608\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0639 - val_loss: 0.0606\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0632 - val_loss: 0.0600\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0632 - val_loss: 0.0596\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0600\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0651 - val_loss: 0.0606\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0641 - val_loss: 0.0598\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0635 - val_loss: 0.0602\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0633 - val_loss: 0.0605\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0615 - val_loss: 0.0603\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0652 - val_loss: 0.0600\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0604\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0622 - val_loss: 0.0604\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0626 - val_loss: 0.0604\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0601\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0596\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:31:48,138]\u001b[0m Trial 69 finished with value: 0.06239950916608885 and parameters: {'learning_rate': 0.000410898733685206, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 1, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 66 with value: 0.05880281624670264.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 139ms/step - loss: 0.2230 - val_loss: 0.1380\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.1242 - val_loss: 0.0773\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1052 - val_loss: 0.0726\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0942 - val_loss: 0.0721\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0872 - val_loss: 0.0661\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0788 - val_loss: 0.0638\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0753 - val_loss: 0.0607\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0693 - val_loss: 0.0596\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0679 - val_loss: 0.0600\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0652 - val_loss: 0.0624\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0676 - val_loss: 0.0598\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0653 - val_loss: 0.0595\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0656 - val_loss: 0.0593\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0657 - val_loss: 0.0591\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0663 - val_loss: 0.0596\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0656 - val_loss: 0.0607\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0664 - val_loss: 0.0597\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0649 - val_loss: 0.0605\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0600\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0598\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0657 - val_loss: 0.0604\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0594\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0591\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0594\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0639 - val_loss: 0.0601\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0595\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0653 - val_loss: 0.0593\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0649 - val_loss: 0.0596\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0602\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0646 - val_loss: 0.0591\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0616 - val_loss: 0.0593\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0592\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0637 - val_loss: 0.0582\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0592\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0662 - val_loss: 0.0626\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0593\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0654 - val_loss: 0.0595\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0603\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0628 - val_loss: 0.0586\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0590\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0626 - val_loss: 0.0601\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0596\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0606 - val_loss: 0.0590\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0608 - val_loss: 0.0594\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0608\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0599\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0635 - val_loss: 0.0592\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0618 - val_loss: 0.0604\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0585\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0614 - val_loss: 0.0594\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0648 - val_loss: 0.0600\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0612\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0633 - val_loss: 0.0585\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0598 - val_loss: 0.0579\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0610 - val_loss: 0.0587\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0609 - val_loss: 0.0600\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0591\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0583\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0652 - val_loss: 0.0602\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0638 - val_loss: 0.0603\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0612\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0610 - val_loss: 0.0577\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0611 - val_loss: 0.0590\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0630 - val_loss: 0.0584\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0595\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0599\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0621 - val_loss: 0.0601\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0608\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0618 - val_loss: 0.0586\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0611 - val_loss: 0.0589\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0622 - val_loss: 0.0588\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0604\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0585\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0648 - val_loss: 0.0599\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0596\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0621 - val_loss: 0.0594\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0591\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0610 - val_loss: 0.0594\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0594 - val_loss: 0.0581\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0624 - val_loss: 0.0593\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0601\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0627 - val_loss: 0.0599\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0587\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0603 - val_loss: 0.0580\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0607 - val_loss: 0.0580\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0625 - val_loss: 0.0603\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0597\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0610 - val_loss: 0.0585\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0609 - val_loss: 0.0589\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0605 - val_loss: 0.0593\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0608 - val_loss: 0.0573\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:33:23,332]\u001b[0m Trial 70 finished with value: 0.05790674968668603 and parameters: {'learning_rate': 0.0004974254807276534, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 143ms/step - loss: 0.2268 - val_loss: 0.1453\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.1280 - val_loss: 0.0784\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1074 - val_loss: 0.0728\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0954 - val_loss: 0.0734\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0892 - val_loss: 0.0673\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0809 - val_loss: 0.0652\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0776 - val_loss: 0.0613\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0714 - val_loss: 0.0607\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0695 - val_loss: 0.0601\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0612\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0674 - val_loss: 0.0600\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0654 - val_loss: 0.0592\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0658 - val_loss: 0.0588\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0663 - val_loss: 0.0590\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0651 - val_loss: 0.0595\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0661 - val_loss: 0.0595\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0648 - val_loss: 0.0605\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0599\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0660 - val_loss: 0.0609\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0599\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0646 - val_loss: 0.0592\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0589\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0594\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0595\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0605\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0593\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0588\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0650 - val_loss: 0.0601\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0648 - val_loss: 0.0610\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0612 - val_loss: 0.0598\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0642 - val_loss: 0.0596\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0638 - val_loss: 0.0584\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0593\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0594\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0660 - val_loss: 0.0619\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0593\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0656 - val_loss: 0.0593\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0600\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0592\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0627 - val_loss: 0.0602\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0610 - val_loss: 0.0588\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0592\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0609\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0638 - val_loss: 0.0593\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0593\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0618 - val_loss: 0.0598\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0587\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0616 - val_loss: 0.0587\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0607\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0634 - val_loss: 0.0592\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0588\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0601 - val_loss: 0.0575\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0613 - val_loss: 0.0580\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0590\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0626 - val_loss: 0.0589\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0592\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0628 - val_loss: 0.0574\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0659 - val_loss: 0.0595\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0635 - val_loss: 0.0593\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0606\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0611 - val_loss: 0.0586\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0586\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0635 - val_loss: 0.0580\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0622 - val_loss: 0.0591\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0638 - val_loss: 0.0600\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0596\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0612\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0618 - val_loss: 0.0583\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0585\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0626 - val_loss: 0.0583\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0602\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0600\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0628 - val_loss: 0.0596\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0590\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0588\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0613 - val_loss: 0.0597\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0589\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0600 - val_loss: 0.0583\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0624 - val_loss: 0.0591\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0634 - val_loss: 0.0608\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0589\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0606 - val_loss: 0.0576\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0609 - val_loss: 0.0583\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0626 - val_loss: 0.0600\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0600\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0611 - val_loss: 0.0585\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0608 - val_loss: 0.0586\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0603 - val_loss: 0.0595\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0609 - val_loss: 0.0577\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:34:57,431]\u001b[0m Trial 71 finished with value: 0.05881450304305483 and parameters: {'learning_rate': 0.00046248958991211515, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 157ms/step - loss: 0.2723 - val_loss: 0.2246\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.2173 - val_loss: 0.1829\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.1781 - val_loss: 0.1462\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1464 - val_loss: 0.1129\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.1214 - val_loss: 0.0893\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.1065 - val_loss: 0.0792\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.1054 - val_loss: 0.0770\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.1031 - val_loss: 0.0762\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0999 - val_loss: 0.0758\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0946 - val_loss: 0.0743\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0913 - val_loss: 0.0718\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0894 - val_loss: 0.0697\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0864 - val_loss: 0.0688\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0862 - val_loss: 0.0677\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0827 - val_loss: 0.0662\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0819 - val_loss: 0.0655\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0814 - val_loss: 0.0644\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0758 - val_loss: 0.0631\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0757 - val_loss: 0.0626\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0746 - val_loss: 0.0615\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0724 - val_loss: 0.0610\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0701 - val_loss: 0.0603\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0700 - val_loss: 0.0600\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0681 - val_loss: 0.0598\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0675 - val_loss: 0.0593\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0673 - val_loss: 0.0592\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0665 - val_loss: 0.0591\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0672 - val_loss: 0.0589\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0663 - val_loss: 0.0587\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0662 - val_loss: 0.0586\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0661 - val_loss: 0.0585\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0627 - val_loss: 0.0588\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0644 - val_loss: 0.0587\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0629 - val_loss: 0.0593\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0652 - val_loss: 0.0592\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0657 - val_loss: 0.0588\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0665 - val_loss: 0.0588\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0630 - val_loss: 0.0588\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0659 - val_loss: 0.0593\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0642 - val_loss: 0.0586\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0643 - val_loss: 0.0590\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0633 - val_loss: 0.0592\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0634 - val_loss: 0.0590\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0651 - val_loss: 0.0592\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0592\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0650 - val_loss: 0.0592\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0594\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0586\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0658 - val_loss: 0.0589\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0647 - val_loss: 0.0593\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0591\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0590\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0675 - val_loss: 0.0587\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0594\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0591\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0590\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0595\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0632 - val_loss: 0.0586\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0635 - val_loss: 0.0586\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0643 - val_loss: 0.0585\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0650 - val_loss: 0.0586\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0587\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0586\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0637 - val_loss: 0.0588\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0640 - val_loss: 0.0586\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0590\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0637 - val_loss: 0.0588\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0624 - val_loss: 0.0585\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0584\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0656 - val_loss: 0.0590\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0636 - val_loss: 0.0590\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0588\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0586\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0636 - val_loss: 0.0587\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0590\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0587\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:36:41,029]\u001b[0m Trial 72 finished with value: 0.061277967766665775 and parameters: {'learning_rate': 0.00014648349534095086, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 157ms/step - loss: 0.2272 - val_loss: 0.1462\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.1285 - val_loss: 0.0786\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.1075 - val_loss: 0.0729\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0955 - val_loss: 0.0734\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0894 - val_loss: 0.0675\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0810 - val_loss: 0.0652\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0778 - val_loss: 0.0614\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0715 - val_loss: 0.0605\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0695 - val_loss: 0.0601\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0653 - val_loss: 0.0611\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0674 - val_loss: 0.0599\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0595\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0652 - val_loss: 0.0592\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0659 - val_loss: 0.0589\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0664 - val_loss: 0.0590\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0653 - val_loss: 0.0599\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0663 - val_loss: 0.0599\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0649 - val_loss: 0.0605\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0641 - val_loss: 0.0599\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0646 - val_loss: 0.0603\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0655 - val_loss: 0.0607\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0643 - val_loss: 0.0597\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0590\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0642 - val_loss: 0.0596\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0640 - val_loss: 0.0602\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0596\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0649 - val_loss: 0.0597\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0651 - val_loss: 0.0600\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0650 - val_loss: 0.0616\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0650 - val_loss: 0.0594\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0615 - val_loss: 0.0598\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0645 - val_loss: 0.0598\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0635 - val_loss: 0.0588\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0618 - val_loss: 0.0603\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0637 - val_loss: 0.0594\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0660 - val_loss: 0.0624\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0620 - val_loss: 0.0597\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0659 - val_loss: 0.0599\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0633 - val_loss: 0.0606\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0630 - val_loss: 0.0584\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0639 - val_loss: 0.0586\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0628 - val_loss: 0.0601\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0618 - val_loss: 0.0597\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0607 - val_loss: 0.0594\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0614 - val_loss: 0.0593\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0646 - val_loss: 0.0616\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0642 - val_loss: 0.0599\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0617 - val_loss: 0.0597\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0643 - val_loss: 0.0591\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0619 - val_loss: 0.0592\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0647 - val_loss: 0.0598\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0633 - val_loss: 0.0608\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0633 - val_loss: 0.0591\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0602 - val_loss: 0.0582\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0612 - val_loss: 0.0588\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0626 - val_loss: 0.0578\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0660 - val_loss: 0.0595\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0637 - val_loss: 0.0603\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0645 - val_loss: 0.0607\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0613 - val_loss: 0.0586\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0611 - val_loss: 0.0591\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0635 - val_loss: 0.0578\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0637 - val_loss: 0.0596\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0595\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0636 - val_loss: 0.0615\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0582\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0615 - val_loss: 0.0583\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0580\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0631 - val_loss: 0.0595\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0633 - val_loss: 0.0593\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0641 - val_loss: 0.0600\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0630 - val_loss: 0.0599\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0619 - val_loss: 0.0591\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0616 - val_loss: 0.0597\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0625 - val_loss: 0.0581\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0599 - val_loss: 0.0589\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0624 - val_loss: 0.0591\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0603\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0624 - val_loss: 0.0588\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0622 - val_loss: 0.0584\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0608 - val_loss: 0.0577\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0608 - val_loss: 0.0580\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0625 - val_loss: 0.0596\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0599\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0612 - val_loss: 0.0583\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0610 - val_loss: 0.0585\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0606 - val_loss: 0.0598\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0609 - val_loss: 0.0573\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:38:25,661]\u001b[0m Trial 73 finished with value: 0.058830504010486326 and parameters: {'learning_rate': 0.000458889329992282, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 155ms/step - loss: 0.2345 - val_loss: 0.1601\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1390 - val_loss: 0.0851\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.1094 - val_loss: 0.0751\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0999 - val_loss: 0.0749\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0929 - val_loss: 0.0704\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0844 - val_loss: 0.0665\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0819 - val_loss: 0.0633\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0751 - val_loss: 0.0615\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0726 - val_loss: 0.0601\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0668 - val_loss: 0.0601\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0679 - val_loss: 0.0598\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0663 - val_loss: 0.0593\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0659 - val_loss: 0.0592\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0662 - val_loss: 0.0595\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0663 - val_loss: 0.0601\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0654 - val_loss: 0.0600\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0666 - val_loss: 0.0601\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0649 - val_loss: 0.0595\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0591\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0644 - val_loss: 0.0598\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0657 - val_loss: 0.0598\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0642 - val_loss: 0.0594\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0648 - val_loss: 0.0591\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0641 - val_loss: 0.0590\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0638 - val_loss: 0.0587\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0599\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0594\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0649 - val_loss: 0.0600\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0648 - val_loss: 0.0604\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0651 - val_loss: 0.0595\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0612 - val_loss: 0.0589\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0642 - val_loss: 0.0585\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0587\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0594\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0597\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0660 - val_loss: 0.0616\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0591\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0656 - val_loss: 0.0595\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0639 - val_loss: 0.0600\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0633 - val_loss: 0.0582\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0596\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0612 - val_loss: 0.0588\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0588\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0643 - val_loss: 0.0602\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0586\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0618 - val_loss: 0.0596\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0648 - val_loss: 0.0591\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0588\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0595\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0635 - val_loss: 0.0605\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0589\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0606 - val_loss: 0.0583\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0618 - val_loss: 0.0586\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0585\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0624 - val_loss: 0.0592\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0578\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0659 - val_loss: 0.0590\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0597\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0605\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0612 - val_loss: 0.0580\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0589\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0575\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0622 - val_loss: 0.0584\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0623 - val_loss: 0.0593\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0597\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0621 - val_loss: 0.0578\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0580\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0631 - val_loss: 0.0585\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0592\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0633 - val_loss: 0.0583\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0595\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0588\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0617 - val_loss: 0.0589\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0615 - val_loss: 0.0595\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0587\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0606 - val_loss: 0.0583\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0577\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0637 - val_loss: 0.0598\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0579\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0608 - val_loss: 0.0583\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0608 - val_loss: 0.0582\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0588\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 0.0584\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0583\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0607 - val_loss: 0.0586\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0611 - val_loss: 0.0577\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:40:03,379]\u001b[0m Trial 74 finished with value: 0.05978448409304834 and parameters: {'learning_rate': 0.0004004511619924016, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 4s 146ms/step - loss: 0.2394 - val_loss: 0.1690\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.1479 - val_loss: 0.0936\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.1099 - val_loss: 0.0764\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1037 - val_loss: 0.0740\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0955 - val_loss: 0.0736\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0872 - val_loss: 0.0680\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0849 - val_loss: 0.0661\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0788 - val_loss: 0.0623\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0754 - val_loss: 0.0613\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0685 - val_loss: 0.0608\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0697 - val_loss: 0.0610\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0671 - val_loss: 0.0600\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0660 - val_loss: 0.0592\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0668 - val_loss: 0.0592\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0667 - val_loss: 0.0602\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0656 - val_loss: 0.0603\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0666 - val_loss: 0.0600\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0594\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0599\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0655 - val_loss: 0.0600\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0598\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0648 - val_loss: 0.0589\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0639 - val_loss: 0.0592\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0639 - val_loss: 0.0602\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0597\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0654 - val_loss: 0.0592\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0649 - val_loss: 0.0602\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0649 - val_loss: 0.0603\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0593\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0610 - val_loss: 0.0595\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0597\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0584\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0603\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0595\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0595\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0662 - val_loss: 0.0615\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0660 - val_loss: 0.0593\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0639 - val_loss: 0.0598\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0585\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0593\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0632 - val_loss: 0.0600\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0621 - val_loss: 0.0596\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0614 - val_loss: 0.0591\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0590\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0605\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0595\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0633 - val_loss: 0.0591\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0592\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0598\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0637 - val_loss: 0.0608\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0631 - val_loss: 0.0588\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0587\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0602 - val_loss: 0.0586\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0601\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0594\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0582\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0661 - val_loss: 0.0594\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0636 - val_loss: 0.0599\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0606\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0613 - val_loss: 0.0584\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0595\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0635 - val_loss: 0.0578\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0646 - val_loss: 0.0594\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0593\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0635 - val_loss: 0.0604\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0585\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0582\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0597\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0586\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0592\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0592\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0585\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0585\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0587\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0600\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0583\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0604 - val_loss: 0.0586\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0582\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0599\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0626 - val_loss: 0.0590\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0624 - val_loss: 0.0577\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0607 - val_loss: 0.0584\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0609 - val_loss: 0.0579\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0591\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0624 - val_loss: 0.0590\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0616 - val_loss: 0.0585\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0579\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0610 - val_loss: 0.0589\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0612 - val_loss: 0.0580\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:41:39,971]\u001b[0m Trial 75 finished with value: 0.05977310886387063 and parameters: {'learning_rate': 0.00036102269108353763, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 170ms/step - loss: 0.1176 - val_loss: 0.0657\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0873 - val_loss: 0.0689\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0841 - val_loss: 0.0662\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0859 - val_loss: 0.0633\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0817 - val_loss: 0.0654\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0777 - val_loss: 0.0617\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0758 - val_loss: 0.0620\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0773 - val_loss: 0.0613\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0748 - val_loss: 0.0599\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0729 - val_loss: 0.0603\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0757 - val_loss: 0.0652\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0744 - val_loss: 0.0623\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0758 - val_loss: 0.0640\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0715 - val_loss: 0.0593\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0739 - val_loss: 0.0598\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0756 - val_loss: 0.0621\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0716 - val_loss: 0.0592\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0700 - val_loss: 0.0620\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0698 - val_loss: 0.0596\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0682 - val_loss: 0.0587\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0669 - val_loss: 0.0600\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0703 - val_loss: 0.0601\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0674 - val_loss: 0.0591\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0674 - val_loss: 0.0594\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0667 - val_loss: 0.0589\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0677 - val_loss: 0.0599\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0674 - val_loss: 0.0596\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0669 - val_loss: 0.0594\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0670 - val_loss: 0.0592\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0677 - val_loss: 0.0586\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0686 - val_loss: 0.0620\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0668 - val_loss: 0.0600\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.0673 - val_loss: 0.0591\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0700 - val_loss: 0.0610\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0662 - val_loss: 0.0579\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.0659 - val_loss: 0.0603\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0670 - val_loss: 0.0624\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0655 - val_loss: 0.0580\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0632 - val_loss: 0.0582\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0649 - val_loss: 0.0614\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0673 - val_loss: 0.0581\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0691 - val_loss: 0.0594\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0656 - val_loss: 0.0594\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0656 - val_loss: 0.0583\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0695 - val_loss: 0.0587\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0627 - val_loss: 0.0578\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0618 - val_loss: 0.0605\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0682 - val_loss: 0.0593\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0676 - val_loss: 0.0586\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0659 - val_loss: 0.0592\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0642 - val_loss: 0.0572\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0647 - val_loss: 0.0598\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0645 - val_loss: 0.0597\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0664 - val_loss: 0.0563\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0668 - val_loss: 0.0582\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0648 - val_loss: 0.0586\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0641 - val_loss: 0.0575\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0650 - val_loss: 0.0573\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0632 - val_loss: 0.0578\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0638 - val_loss: 0.0572\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0643 - val_loss: 0.0573\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0648 - val_loss: 0.0567\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0637 - val_loss: 0.0567\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0605 - val_loss: 0.0569\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0626 - val_loss: 0.0570\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0625 - val_loss: 0.0592\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0639 - val_loss: 0.0554\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0623 - val_loss: 0.0600\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0632 - val_loss: 0.0565\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0640 - val_loss: 0.0569\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0636 - val_loss: 0.0573\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0643 - val_loss: 0.0577\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0638 - val_loss: 0.0577\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0645 - val_loss: 0.0577\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0631 - val_loss: 0.0566\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0625 - val_loss: 0.0564\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0628 - val_loss: 0.0574\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0630 - val_loss: 0.0552\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0633 - val_loss: 0.0572\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0636 - val_loss: 0.0552\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.0658 - val_loss: 0.0566\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0622 - val_loss: 0.0556\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0657 - val_loss: 0.0561\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0629 - val_loss: 0.0551\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0626 - val_loss: 0.0573\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0642 - val_loss: 0.0568\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0626 - val_loss: 0.0551\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0618 - val_loss: 0.0579\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0632 - val_loss: 0.0566\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0640 - val_loss: 0.0575\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0631 - val_loss: 0.0551\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0648 - val_loss: 0.0560\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0624 - val_loss: 0.0550\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0642 - val_loss: 0.0561\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0628 - val_loss: 0.0572\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0645 - val_loss: 0.0556\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0623 - val_loss: 0.0561\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0647 - val_loss: 0.0568\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0615 - val_loss: 0.0565\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0605 - val_loss: 0.0563\n",
            "2/2 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 74). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:43:41,551]\u001b[0m Trial 76 finished with value: 0.06535704179150743 and parameters: {'learning_rate': 0.0003895383482072927, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 143ms/step - loss: 0.2471 - val_loss: 0.1827\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1643 - val_loss: 0.1137\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.1146 - val_loss: 0.0783\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.1071 - val_loss: 0.0740\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.1007 - val_loss: 0.0756\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0918 - val_loss: 0.0719\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0894 - val_loss: 0.0680\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0847 - val_loss: 0.0661\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0810 - val_loss: 0.0642\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0737 - val_loss: 0.0617\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0731 - val_loss: 0.0618\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0707 - val_loss: 0.0601\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0684 - val_loss: 0.0599\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0690 - val_loss: 0.0599\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0677 - val_loss: 0.0589\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0665 - val_loss: 0.0592\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0673 - val_loss: 0.0588\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0593\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0653 - val_loss: 0.0593\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0656 - val_loss: 0.0593\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0591\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0651 - val_loss: 0.0588\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0649 - val_loss: 0.0589\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0646 - val_loss: 0.0587\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0589\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0590\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0655 - val_loss: 0.0588\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0650 - val_loss: 0.0588\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0583\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0649 - val_loss: 0.0591\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0649 - val_loss: 0.0595\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0615 - val_loss: 0.0592\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0595\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0647 - val_loss: 0.0591\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0648 - val_loss: 0.0589\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0662 - val_loss: 0.0600\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0590\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0658 - val_loss: 0.0594\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0591\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0638 - val_loss: 0.0587\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0643 - val_loss: 0.0589\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0592\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0592\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0646 - val_loss: 0.0594\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0625 - val_loss: 0.0592\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0588\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0651 - val_loss: 0.0588\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0642 - val_loss: 0.0596\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0587\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0590\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0593\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0633 - val_loss: 0.0588\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0631 - val_loss: 0.0592\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0635 - val_loss: 0.0585\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0667 - val_loss: 0.0586\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0597\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0625 - val_loss: 0.0588\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0587\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0625 - val_loss: 0.0590\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0647 - val_loss: 0.0595\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0586\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0634 - val_loss: 0.0592\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0585\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0628 - val_loss: 0.0585\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0639 - val_loss: 0.0583\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0591\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0647 - val_loss: 0.0583\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0637 - val_loss: 0.0584\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0633 - val_loss: 0.0589\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0636 - val_loss: 0.0586\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0590\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0631 - val_loss: 0.0589\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0617 - val_loss: 0.0584\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0581\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0651 - val_loss: 0.0589\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0593\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0631 - val_loss: 0.0584\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0614 - val_loss: 0.0583\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0622 - val_loss: 0.0583\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0586\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0581\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0584\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0583\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0617 - val_loss: 0.0582\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:45:13,935]\u001b[0m Trial 77 finished with value: 0.060623982051587554 and parameters: {'learning_rate': 0.0003042516357321677, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 138ms/step - loss: 0.2407 - val_loss: 0.1712\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1505 - val_loss: 0.0966\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.1101 - val_loss: 0.0764\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.1043 - val_loss: 0.0735\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0961 - val_loss: 0.0743\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0876 - val_loss: 0.0676\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0852 - val_loss: 0.0663\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0793 - val_loss: 0.0626\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0756 - val_loss: 0.0617\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0690 - val_loss: 0.0609\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0703 - val_loss: 0.0611\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0676 - val_loss: 0.0602\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0664 - val_loss: 0.0592\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0673 - val_loss: 0.0593\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0667 - val_loss: 0.0597\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0657 - val_loss: 0.0600\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0666 - val_loss: 0.0598\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0650 - val_loss: 0.0594\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0600\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0661 - val_loss: 0.0600\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0644 - val_loss: 0.0596\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0646 - val_loss: 0.0592\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0648 - val_loss: 0.0591\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0642 - val_loss: 0.0593\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0641 - val_loss: 0.0602\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0651 - val_loss: 0.0595\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0656 - val_loss: 0.0596\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0641 - val_loss: 0.0587\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0649 - val_loss: 0.0600\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0602\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0649 - val_loss: 0.0597\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0611 - val_loss: 0.0593\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0592\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0587\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0649 - val_loss: 0.0596\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0661 - val_loss: 0.0618\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0626 - val_loss: 0.0594\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0662 - val_loss: 0.0591\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0595\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0585\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0633 - val_loss: 0.0597\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0596\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0615 - val_loss: 0.0587\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0586\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0645 - val_loss: 0.0599\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0642 - val_loss: 0.0594\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0590\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0647 - val_loss: 0.0594\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0605\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0643 - val_loss: 0.0588\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0604 - val_loss: 0.0585\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0604\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0622 - val_loss: 0.0598\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0630 - val_loss: 0.0581\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0662 - val_loss: 0.0591\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0634 - val_loss: 0.0595\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0602\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0614 - val_loss: 0.0588\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0616 - val_loss: 0.0597\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0636 - val_loss: 0.0579\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0626 - val_loss: 0.0590\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0633 - val_loss: 0.0603\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0622 - val_loss: 0.0583\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0619 - val_loss: 0.0583\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0584\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0634 - val_loss: 0.0599\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0637 - val_loss: 0.0588\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0631 - val_loss: 0.0595\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0581\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0622 - val_loss: 0.0581\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0595\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0603 - val_loss: 0.0584\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0630 - val_loss: 0.0579\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0626 - val_loss: 0.0582\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0581\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0608 - val_loss: 0.0580\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0610 - val_loss: 0.0576\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0633 - val_loss: 0.0594\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0615 - val_loss: 0.0584\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0578\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0586\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0613 - val_loss: 0.0579\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:46:44,930]\u001b[0m Trial 78 finished with value: 0.060363538038311376 and parameters: {'learning_rate': 0.0003505965372401773, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 133ms/step - loss: 0.2275 - val_loss: 0.1469\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.1289 - val_loss: 0.0788\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.1076 - val_loss: 0.0730\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0958 - val_loss: 0.0736\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0900 - val_loss: 0.0679\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0811 - val_loss: 0.0653\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0778 - val_loss: 0.0615\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0716 - val_loss: 0.0608\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0696 - val_loss: 0.0596\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0653 - val_loss: 0.0614\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0675 - val_loss: 0.0603\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0653 - val_loss: 0.0598\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0653 - val_loss: 0.0591\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0658 - val_loss: 0.0587\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0661 - val_loss: 0.0591\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0651 - val_loss: 0.0597\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0662 - val_loss: 0.0597\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0648 - val_loss: 0.0603\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0638 - val_loss: 0.0596\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0641 - val_loss: 0.0599\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0661 - val_loss: 0.0610\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0645 - val_loss: 0.0594\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0586\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0638 - val_loss: 0.0594\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0641 - val_loss: 0.0599\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0645 - val_loss: 0.0588\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0648 - val_loss: 0.0600\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0614\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0649 - val_loss: 0.0595\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0612 - val_loss: 0.0596\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0643 - val_loss: 0.0591\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0584\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0617 - val_loss: 0.0603\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0639 - val_loss: 0.0595\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0644 - val_loss: 0.0595\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0659 - val_loss: 0.0621\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0656 - val_loss: 0.0594\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0601\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0629 - val_loss: 0.0585\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0638 - val_loss: 0.0591\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0629 - val_loss: 0.0598\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0594\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0610 - val_loss: 0.0588\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0613 - val_loss: 0.0595\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0644 - val_loss: 0.0613\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0636 - val_loss: 0.0594\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0587\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0616 - val_loss: 0.0599\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0590\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0630 - val_loss: 0.0604\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0631 - val_loss: 0.0591\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0600 - val_loss: 0.0577\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0613 - val_loss: 0.0583\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0613 - val_loss: 0.0600\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0583\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0599\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0574\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0656 - val_loss: 0.0596\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0596\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0606\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0611 - val_loss: 0.0582\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0609 - val_loss: 0.0586\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0633 - val_loss: 0.0580\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0618 - val_loss: 0.0589\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0595\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0624 - val_loss: 0.0598\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0636 - val_loss: 0.0612\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0582\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0583\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0627 - val_loss: 0.0585\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0598\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0631 - val_loss: 0.0589\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0641 - val_loss: 0.0596\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0627 - val_loss: 0.0600\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0588\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0614 - val_loss: 0.0603\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0600 - val_loss: 0.0591\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0626 - val_loss: 0.0588\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0606\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0623 - val_loss: 0.0590\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0622 - val_loss: 0.0589\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0607 - val_loss: 0.0577\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0608 - val_loss: 0.0583\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0623 - val_loss: 0.0595\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0620 - val_loss: 0.0596\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0611 - val_loss: 0.0584\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0608 - val_loss: 0.0584\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0605 - val_loss: 0.0593\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0609 - val_loss: 0.0575\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:48:15,453]\u001b[0m Trial 79 finished with value: 0.05952289685309839 and parameters: {'learning_rate': 0.00045542421527859287, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 139ms/step - loss: 0.2278 - val_loss: 0.1473\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.1292 - val_loss: 0.0789\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1077 - val_loss: 0.0730\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0959 - val_loss: 0.0737\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0901 - val_loss: 0.0679\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0812 - val_loss: 0.0655\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0780 - val_loss: 0.0615\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0719 - val_loss: 0.0608\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0698 - val_loss: 0.0596\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0654 - val_loss: 0.0605\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0672 - val_loss: 0.0593\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0655 - val_loss: 0.0602\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0659 - val_loss: 0.0593\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0663 - val_loss: 0.0588\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0665 - val_loss: 0.0590\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0654 - val_loss: 0.0594\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0665 - val_loss: 0.0596\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0649 - val_loss: 0.0599\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0596\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0658 - val_loss: 0.0603\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0594\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0644 - val_loss: 0.0588\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0585\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0639 - val_loss: 0.0589\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0598\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0589\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0650 - val_loss: 0.0590\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0637 - val_loss: 0.0582\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0651 - val_loss: 0.0596\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0648 - val_loss: 0.0609\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0649 - val_loss: 0.0589\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0612 - val_loss: 0.0592\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0642 - val_loss: 0.0591\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0583\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0594\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0588\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0591\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0659 - val_loss: 0.0619\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0591\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0656 - val_loss: 0.0588\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0597\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0583\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0586\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0595\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0609 - val_loss: 0.0584\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0614 - val_loss: 0.0586\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0645 - val_loss: 0.0613\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0634 - val_loss: 0.0588\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0592\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0582\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0583\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0647 - val_loss: 0.0591\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0606\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0589\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0583\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0601 - val_loss: 0.0577\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0611 - val_loss: 0.0581\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0613 - val_loss: 0.0587\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0628 - val_loss: 0.0580\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0618 - val_loss: 0.0587\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0571\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0659 - val_loss: 0.0590\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0591\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0608\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0610 - val_loss: 0.0582\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0610 - val_loss: 0.0589\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0633 - val_loss: 0.0579\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0633 - val_loss: 0.0590\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0590\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0635 - val_loss: 0.0607\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0621 - val_loss: 0.0578\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0617 - val_loss: 0.0584\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0626 - val_loss: 0.0586\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0631 - val_loss: 0.0594\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0584\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0595\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0588\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0624 - val_loss: 0.0583\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0582\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0613 - val_loss: 0.0597\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0600 - val_loss: 0.0586\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0635 - val_loss: 0.0599\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0583\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0607 - val_loss: 0.0577\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0608 - val_loss: 0.0582\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0624 - val_loss: 0.0593\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0594\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0609 - val_loss: 0.0580\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0609 - val_loss: 0.0577\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0607 - val_loss: 0.0593\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0608 - val_loss: 0.0575\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:49:52,359]\u001b[0m Trial 80 finished with value: 0.05919703306359705 and parameters: {'learning_rate': 0.00045359446486987256, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 136ms/step - loss: 0.2261 - val_loss: 0.1441\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.1272 - val_loss: 0.0781\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1071 - val_loss: 0.0727\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0952 - val_loss: 0.0735\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0888 - val_loss: 0.0666\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0803 - val_loss: 0.0651\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0774 - val_loss: 0.0611\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0712 - val_loss: 0.0604\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0691 - val_loss: 0.0600\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0652 - val_loss: 0.0615\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0675 - val_loss: 0.0601\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0653 - val_loss: 0.0599\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0656 - val_loss: 0.0590\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0660 - val_loss: 0.0585\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0666 - val_loss: 0.0589\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0653 - val_loss: 0.0596\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0663 - val_loss: 0.0593\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0649 - val_loss: 0.0596\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0638 - val_loss: 0.0591\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.0645 - val_loss: 0.0598\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0658 - val_loss: 0.0608\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0646 - val_loss: 0.0597\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0647 - val_loss: 0.0595\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0588\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0640 - val_loss: 0.0590\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0639 - val_loss: 0.0590\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0642 - val_loss: 0.0600\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0591\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0649 - val_loss: 0.0588\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0635 - val_loss: 0.0586\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0648 - val_loss: 0.0600\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0647 - val_loss: 0.0612\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0649 - val_loss: 0.0594\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0613 - val_loss: 0.0596\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0643 - val_loss: 0.0594\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0618 - val_loss: 0.0600\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0637 - val_loss: 0.0595\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0660 - val_loss: 0.0618\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0619 - val_loss: 0.0593\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0656 - val_loss: 0.0597\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0636 - val_loss: 0.0603\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0629 - val_loss: 0.0584\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0638 - val_loss: 0.0589\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0628 - val_loss: 0.0602\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0618 - val_loss: 0.0597\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0610 - val_loss: 0.0590\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0613 - val_loss: 0.0593\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0644 - val_loss: 0.0610\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0633 - val_loss: 0.0592\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0618 - val_loss: 0.0601\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0641 - val_loss: 0.0589\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0617 - val_loss: 0.0587\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0648 - val_loss: 0.0596\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0612\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0634 - val_loss: 0.0595\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0588\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0601 - val_loss: 0.0577\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0614 - val_loss: 0.0584\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0614 - val_loss: 0.0597\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0626 - val_loss: 0.0583\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0628 - val_loss: 0.0577\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0655 - val_loss: 0.0599\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0634 - val_loss: 0.0598\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0610\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0611 - val_loss: 0.0583\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0613 - val_loss: 0.0591\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0634 - val_loss: 0.0579\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0623 - val_loss: 0.0590\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0638 - val_loss: 0.0593\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0598\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0609\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0578\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0615 - val_loss: 0.0586\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0626 - val_loss: 0.0583\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0596\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0587\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0642 - val_loss: 0.0598\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0596\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0622 - val_loss: 0.0591\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0618 - val_loss: 0.0603\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0592\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0601 - val_loss: 0.0591\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0634 - val_loss: 0.0602\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0621 - val_loss: 0.0583\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0605 - val_loss: 0.0578\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0607 - val_loss: 0.0582\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0605\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0611 - val_loss: 0.0587\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0610 - val_loss: 0.0585\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0607 - val_loss: 0.0596\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0609 - val_loss: 0.0580\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:51:22,456]\u001b[0m Trial 81 finished with value: 0.05888971474753407 and parameters: {'learning_rate': 0.0004684214919322501, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 137ms/step - loss: 0.2269 - val_loss: 0.1455\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1281 - val_loss: 0.0784\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.1074 - val_loss: 0.0729\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0955 - val_loss: 0.0735\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0893 - val_loss: 0.0673\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0809 - val_loss: 0.0652\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0777 - val_loss: 0.0613\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0715 - val_loss: 0.0606\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0695 - val_loss: 0.0603\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0653 - val_loss: 0.0612\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0675 - val_loss: 0.0601\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0652 - val_loss: 0.0589\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0657 - val_loss: 0.0589\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0661 - val_loss: 0.0592\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0662 - val_loss: 0.0594\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0649 - val_loss: 0.0604\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0595\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0600\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0658 - val_loss: 0.0607\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0644 - val_loss: 0.0599\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0592\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0644 - val_loss: 0.0589\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0640 - val_loss: 0.0603\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0595\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0648 - val_loss: 0.0602\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0610\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0649 - val_loss: 0.0592\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0612 - val_loss: 0.0594\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0635 - val_loss: 0.0586\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0617 - val_loss: 0.0600\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0592\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0659 - val_loss: 0.0627\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0659 - val_loss: 0.0591\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0634 - val_loss: 0.0598\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0630 - val_loss: 0.0582\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0588\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0628 - val_loss: 0.0599\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0616 - val_loss: 0.0595\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0608 - val_loss: 0.0590\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0611 - val_loss: 0.0594\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0644 - val_loss: 0.0616\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0637 - val_loss: 0.0591\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0636 - val_loss: 0.0586\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0615 - val_loss: 0.0603\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0642 - val_loss: 0.0590\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0617 - val_loss: 0.0586\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0648 - val_loss: 0.0599\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0632 - val_loss: 0.0610\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0634 - val_loss: 0.0588\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0636 - val_loss: 0.0593\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0601 - val_loss: 0.0579\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0610 - val_loss: 0.0587\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0612 - val_loss: 0.0596\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0584\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0618 - val_loss: 0.0594\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0571\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0656 - val_loss: 0.0598\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0633 - val_loss: 0.0601\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0644 - val_loss: 0.0609\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0611 - val_loss: 0.0580\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0611 - val_loss: 0.0590\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0633 - val_loss: 0.0582\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0592\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0595\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0633 - val_loss: 0.0613\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0619 - val_loss: 0.0580\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0613 - val_loss: 0.0594\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0630 - val_loss: 0.0581\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0633 - val_loss: 0.0602\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0631 - val_loss: 0.0586\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0602\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0591\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0622 - val_loss: 0.0588\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0590\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0618 - val_loss: 0.0602\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0582\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0600 - val_loss: 0.0587\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0594\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0608\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0621 - val_loss: 0.0585\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0606 - val_loss: 0.0578\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0607 - val_loss: 0.0585\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0623 - val_loss: 0.0596\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0622 - val_loss: 0.0603\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0612 - val_loss: 0.0579\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0612 - val_loss: 0.0581\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0603 - val_loss: 0.0595\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0610 - val_loss: 0.0578\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:52:52,791]\u001b[0m Trial 82 finished with value: 0.059205727590760655 and parameters: {'learning_rate': 0.00046159738345185323, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 135ms/step - loss: 0.2270 - val_loss: 0.1458\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.1283 - val_loss: 0.0785\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.1074 - val_loss: 0.0729\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0954 - val_loss: 0.0732\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0892 - val_loss: 0.0675\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.0810 - val_loss: 0.0651\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0777 - val_loss: 0.0614\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0714 - val_loss: 0.0605\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0694 - val_loss: 0.0601\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0653 - val_loss: 0.0614\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0675 - val_loss: 0.0599\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0653 - val_loss: 0.0596\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0654 - val_loss: 0.0592\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0658 - val_loss: 0.0588\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0661 - val_loss: 0.0591\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0651 - val_loss: 0.0599\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0662 - val_loss: 0.0594\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0648 - val_loss: 0.0602\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0638 - val_loss: 0.0594\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0641 - val_loss: 0.0597\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0658 - val_loss: 0.0610\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0600\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0592\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0644 - val_loss: 0.0589\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0591\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0642 - val_loss: 0.0605\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0646 - val_loss: 0.0591\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0650 - val_loss: 0.0595\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0590\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0648 - val_loss: 0.0600\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0646 - val_loss: 0.0610\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0591\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0611 - val_loss: 0.0596\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0643 - val_loss: 0.0591\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0636 - val_loss: 0.0585\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0637 - val_loss: 0.0594\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0661 - val_loss: 0.0620\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0658 - val_loss: 0.0594\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0636 - val_loss: 0.0599\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0631 - val_loss: 0.0580\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0598\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0617 - val_loss: 0.0592\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0610 - val_loss: 0.0587\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0613 - val_loss: 0.0591\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0608\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0640 - val_loss: 0.0595\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0616 - val_loss: 0.0604\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0643 - val_loss: 0.0589\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0618 - val_loss: 0.0586\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0648 - val_loss: 0.0595\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0632 - val_loss: 0.0604\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0634 - val_loss: 0.0591\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0602 - val_loss: 0.0578\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0613 - val_loss: 0.0585\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0613 - val_loss: 0.0595\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0626 - val_loss: 0.0591\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0619 - val_loss: 0.0594\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0574\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0658 - val_loss: 0.0596\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0642 - val_loss: 0.0605\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0612 - val_loss: 0.0583\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0611 - val_loss: 0.0583\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0580\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0624 - val_loss: 0.0593\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0640 - val_loss: 0.0603\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0627 - val_loss: 0.0598\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0637 - val_loss: 0.0612\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0620 - val_loss: 0.0578\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0614 - val_loss: 0.0583\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0632 - val_loss: 0.0596\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0590\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0638 - val_loss: 0.0602\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0629 - val_loss: 0.0599\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0623 - val_loss: 0.0588\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0627 - val_loss: 0.0590\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0614 - val_loss: 0.0605\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0590\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0602 - val_loss: 0.0589\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0591\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.0635 - val_loss: 0.0609\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0624 - val_loss: 0.0595\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0622 - val_loss: 0.0589\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0607 - val_loss: 0.0579\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0608 - val_loss: 0.0583\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0603\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0598\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0586\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0610 - val_loss: 0.0587\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0604 - val_loss: 0.0597\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0579\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:54:22,563]\u001b[0m Trial 83 finished with value: 0.058516639379729944 and parameters: {'learning_rate': 0.00046040525018399233, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 146ms/step - loss: 0.2279 - val_loss: 0.1476\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.1293 - val_loss: 0.0790\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1077 - val_loss: 0.0730\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0959 - val_loss: 0.0737\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0901 - val_loss: 0.0679\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0811 - val_loss: 0.0655\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0779 - val_loss: 0.0615\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0717 - val_loss: 0.0607\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0695 - val_loss: 0.0601\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0654 - val_loss: 0.0614\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0672 - val_loss: 0.0601\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0653 - val_loss: 0.0600\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0656 - val_loss: 0.0595\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0659 - val_loss: 0.0589\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0662 - val_loss: 0.0591\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0652 - val_loss: 0.0600\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0662 - val_loss: 0.0596\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0648 - val_loss: 0.0601\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0596\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0601\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0659 - val_loss: 0.0612\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0595\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0645 - val_loss: 0.0590\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0589\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0592\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0603\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0648 - val_loss: 0.0594\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0636 - val_loss: 0.0588\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0650 - val_loss: 0.0597\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0649 - val_loss: 0.0608\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0648 - val_loss: 0.0592\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0611 - val_loss: 0.0596\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0586\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0617 - val_loss: 0.0600\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0638 - val_loss: 0.0592\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0660 - val_loss: 0.0619\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0619 - val_loss: 0.0593\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0655 - val_loss: 0.0592\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0598\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0586\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0637 - val_loss: 0.0589\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0599\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0618 - val_loss: 0.0592\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0611 - val_loss: 0.0586\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0613 - val_loss: 0.0592\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0608\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0586\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0594\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0619 - val_loss: 0.0585\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0648 - val_loss: 0.0596\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0607\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0591\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0635 - val_loss: 0.0587\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0601 - val_loss: 0.0579\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0613 - val_loss: 0.0583\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0615 - val_loss: 0.0596\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0587\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0619 - val_loss: 0.0594\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0575\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0655 - val_loss: 0.0594\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0637 - val_loss: 0.0592\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0608\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0608 - val_loss: 0.0581\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0611 - val_loss: 0.0589\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0582\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0624 - val_loss: 0.0590\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0639 - val_loss: 0.0595\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0627 - val_loss: 0.0597\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0638 - val_loss: 0.0610\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0582\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0614 - val_loss: 0.0587\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0627 - val_loss: 0.0584\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0634 - val_loss: 0.0608\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0633 - val_loss: 0.0589\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0598\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0594\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0622 - val_loss: 0.0591\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0627 - val_loss: 0.0590\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0616 - val_loss: 0.0603\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0604 - val_loss: 0.0591\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0627 - val_loss: 0.0588\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0633 - val_loss: 0.0604\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0588\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0622 - val_loss: 0.0586\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0607 - val_loss: 0.0579\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0607 - val_loss: 0.0578\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0594\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0609 - val_loss: 0.0585\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0608 - val_loss: 0.0585\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0605 - val_loss: 0.0597\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0608 - val_loss: 0.0576\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:55:59,037]\u001b[0m Trial 84 finished with value: 0.0593304979228369 and parameters: {'learning_rate': 0.0004526432768317466, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 131ms/step - loss: 0.2273 - val_loss: 0.1465\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.1287 - val_loss: 0.0787\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.1075 - val_loss: 0.0729\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0956 - val_loss: 0.0736\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0900 - val_loss: 0.0679\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0809 - val_loss: 0.0651\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0777 - val_loss: 0.0613\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0716 - val_loss: 0.0607\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0693 - val_loss: 0.0599\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0653 - val_loss: 0.0611\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0671 - val_loss: 0.0602\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0651 - val_loss: 0.0599\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0655 - val_loss: 0.0592\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0661 - val_loss: 0.0589\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0665 - val_loss: 0.0593\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0597\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0663 - val_loss: 0.0596\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0650 - val_loss: 0.0602\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0639 - val_loss: 0.0596\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0660 - val_loss: 0.0606\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0646 - val_loss: 0.0598\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0646 - val_loss: 0.0591\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0638 - val_loss: 0.0602\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0646 - val_loss: 0.0592\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0634 - val_loss: 0.0588\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0648 - val_loss: 0.0596\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0649 - val_loss: 0.0602\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0645 - val_loss: 0.0591\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0612 - val_loss: 0.0593\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0635 - val_loss: 0.0584\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0618 - val_loss: 0.0595\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0592\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0646 - val_loss: 0.0596\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0661 - val_loss: 0.0626\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0622 - val_loss: 0.0592\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0657 - val_loss: 0.0592\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0634 - val_loss: 0.0605\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0587\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0594\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0629 - val_loss: 0.0602\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0594\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0608 - val_loss: 0.0589\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0613 - val_loss: 0.0590\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0644 - val_loss: 0.0608\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0638 - val_loss: 0.0593\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0618 - val_loss: 0.0598\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0645 - val_loss: 0.0582\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0649 - val_loss: 0.0600\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0633 - val_loss: 0.0609\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0630 - val_loss: 0.0591\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0636 - val_loss: 0.0590\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0600 - val_loss: 0.0577\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0613 - val_loss: 0.0580\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0616 - val_loss: 0.0599\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0583\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0620 - val_loss: 0.0599\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0628 - val_loss: 0.0572\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0655 - val_loss: 0.0594\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0636 - val_loss: 0.0599\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0643 - val_loss: 0.0609\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0612 - val_loss: 0.0585\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0613 - val_loss: 0.0592\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0633 - val_loss: 0.0578\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0640 - val_loss: 0.0590\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0623 - val_loss: 0.0588\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0606\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0620 - val_loss: 0.0576\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0614 - val_loss: 0.0589\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0632 - val_loss: 0.0601\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0593\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0604\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0629 - val_loss: 0.0600\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0592\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0614 - val_loss: 0.0597\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0624 - val_loss: 0.0585\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0599 - val_loss: 0.0586\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0594\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0635 - val_loss: 0.0603\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0624 - val_loss: 0.0595\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0623 - val_loss: 0.0583\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0605 - val_loss: 0.0575\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0605 - val_loss: 0.0579\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0628 - val_loss: 0.0606\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0623 - val_loss: 0.0593\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0610 - val_loss: 0.0586\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0610 - val_loss: 0.0585\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0608 - val_loss: 0.0596\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0609 - val_loss: 0.0579\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:57:28,741]\u001b[0m Trial 85 finished with value: 0.05885807485001718 and parameters: {'learning_rate': 0.00045726259560207347, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 140ms/step - loss: 0.2326 - val_loss: 0.1567\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.1360 - val_loss: 0.0827\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1093 - val_loss: 0.0746\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0988 - val_loss: 0.0750\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0920 - val_loss: 0.0700\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0832 - val_loss: 0.0654\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0801 - val_loss: 0.0626\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0732 - val_loss: 0.0609\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0710 - val_loss: 0.0597\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0662 - val_loss: 0.0605\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0680 - val_loss: 0.0600\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0661 - val_loss: 0.0595\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0661 - val_loss: 0.0589\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0664 - val_loss: 0.0591\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0670 - val_loss: 0.0597\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0659 - val_loss: 0.0601\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0668 - val_loss: 0.0596\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0652 - val_loss: 0.0596\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0592\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0645 - val_loss: 0.0595\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0652 - val_loss: 0.0597\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0641 - val_loss: 0.0591\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0646 - val_loss: 0.0586\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0642 - val_loss: 0.0594\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0641 - val_loss: 0.0595\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0657 - val_loss: 0.0595\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0651 - val_loss: 0.0600\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0603\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0656 - val_loss: 0.0590\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0615 - val_loss: 0.0594\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0639 - val_loss: 0.0587\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0603\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0642 - val_loss: 0.0598\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0650 - val_loss: 0.0598\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0660 - val_loss: 0.0621\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0622 - val_loss: 0.0592\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0658 - val_loss: 0.0593\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0637 - val_loss: 0.0596\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0630 - val_loss: 0.0583\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0642 - val_loss: 0.0587\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0630 - val_loss: 0.0600\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0613 - val_loss: 0.0588\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0592\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0645 - val_loss: 0.0607\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0647 - val_loss: 0.0597\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0620 - val_loss: 0.0593\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0647 - val_loss: 0.0585\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0594\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0607\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0629 - val_loss: 0.0590\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0637 - val_loss: 0.0587\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0602 - val_loss: 0.0579\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0617 - val_loss: 0.0585\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0617 - val_loss: 0.0598\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0630 - val_loss: 0.0587\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0622 - val_loss: 0.0593\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0629 - val_loss: 0.0576\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0659 - val_loss: 0.0594\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0595\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0644 - val_loss: 0.0606\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0612 - val_loss: 0.0586\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0616 - val_loss: 0.0590\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0635 - val_loss: 0.0576\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0619 - val_loss: 0.0587\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0591\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0636 - val_loss: 0.0605\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0618 - val_loss: 0.0578\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0615 - val_loss: 0.0584\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0602\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0634 - val_loss: 0.0582\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0638 - val_loss: 0.0592\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0628 - val_loss: 0.0596\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0621 - val_loss: 0.0589\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0587\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0620 - val_loss: 0.0590\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0617 - val_loss: 0.0598\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0601 - val_loss: 0.0584\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0626 - val_loss: 0.0584\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0601\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0593\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0623 - val_loss: 0.0584\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0607 - val_loss: 0.0578\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0606 - val_loss: 0.0580\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0627 - val_loss: 0.0591\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0621 - val_loss: 0.0597\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0615 - val_loss: 0.0581\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0610 - val_loss: 0.0581\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0606 - val_loss: 0.0589\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0610 - val_loss: 0.0577\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 17:58:58,480]\u001b[0m Trial 86 finished with value: 0.059250486311838116 and parameters: {'learning_rate': 0.000414798528695268, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 135ms/step - loss: 0.2280 - val_loss: 0.1478\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.1295 - val_loss: 0.0791\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.1077 - val_loss: 0.0731\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0959 - val_loss: 0.0737\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0902 - val_loss: 0.0679\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0813 - val_loss: 0.0656\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0781 - val_loss: 0.0616\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0718 - val_loss: 0.0609\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0698 - val_loss: 0.0596\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0654 - val_loss: 0.0615\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0675 - val_loss: 0.0604\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0654 - val_loss: 0.0601\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0654 - val_loss: 0.0593\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0658 - val_loss: 0.0588\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0660 - val_loss: 0.0589\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0593\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0661 - val_loss: 0.0594\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0648 - val_loss: 0.0602\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0638 - val_loss: 0.0594\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0640 - val_loss: 0.0599\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0660 - val_loss: 0.0609\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0598\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0645 - val_loss: 0.0591\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0590\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0642 - val_loss: 0.0602\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0645 - val_loss: 0.0590\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0649 - val_loss: 0.0593\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0635 - val_loss: 0.0587\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0650 - val_loss: 0.0598\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0649 - val_loss: 0.0607\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0649 - val_loss: 0.0591\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0611 - val_loss: 0.0593\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0643 - val_loss: 0.0594\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0632 - val_loss: 0.0587\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0617 - val_loss: 0.0600\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0636 - val_loss: 0.0592\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0662 - val_loss: 0.0623\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0620 - val_loss: 0.0594\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0655 - val_loss: 0.0593\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0635 - val_loss: 0.0601\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0629 - val_loss: 0.0582\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0587\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0628 - val_loss: 0.0600\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0618 - val_loss: 0.0592\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0608 - val_loss: 0.0589\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0612 - val_loss: 0.0594\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0643 - val_loss: 0.0610\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0594\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0615 - val_loss: 0.0598\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0586\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0615 - val_loss: 0.0588\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0597\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0632 - val_loss: 0.0609\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0585\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0600 - val_loss: 0.0575\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0613 - val_loss: 0.0583\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0614 - val_loss: 0.0596\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0618 - val_loss: 0.0589\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0570\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0657 - val_loss: 0.0594\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0637 - val_loss: 0.0595\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0608\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0610 - val_loss: 0.0585\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0611 - val_loss: 0.0589\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0636 - val_loss: 0.0581\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0622 - val_loss: 0.0592\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0637 - val_loss: 0.0594\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0599\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0637 - val_loss: 0.0609\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0621 - val_loss: 0.0580\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0614 - val_loss: 0.0587\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0633 - val_loss: 0.0600\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0583\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0629 - val_loss: 0.0602\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0623 - val_loss: 0.0592\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0625 - val_loss: 0.0586\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0586\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0603\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0601 - val_loss: 0.0590\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0627 - val_loss: 0.0590\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0634 - val_loss: 0.0605\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0622 - val_loss: 0.0590\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0607 - val_loss: 0.0577\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0608 - val_loss: 0.0582\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0604\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0601\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0612 - val_loss: 0.0585\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0610 - val_loss: 0.0585\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0605 - val_loss: 0.0596\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0610 - val_loss: 0.0581\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:00:33,577]\u001b[0m Trial 87 finished with value: 0.05953363230516299 and parameters: {'learning_rate': 0.00045112066870257693, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 150ms/step - loss: 0.2255 - val_loss: 0.1430\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1265 - val_loss: 0.0778\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.1068 - val_loss: 0.0728\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0950 - val_loss: 0.0724\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0885 - val_loss: 0.0670\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0799 - val_loss: 0.0645\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0765 - val_loss: 0.0613\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0703 - val_loss: 0.0598\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0686 - val_loss: 0.0602\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0651 - val_loss: 0.0622\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0672 - val_loss: 0.0600\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0651 - val_loss: 0.0594\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0654 - val_loss: 0.0589\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0660 - val_loss: 0.0590\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0662 - val_loss: 0.0596\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0653 - val_loss: 0.0603\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0663 - val_loss: 0.0596\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0650 - val_loss: 0.0603\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0640 - val_loss: 0.0597\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0599\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0658 - val_loss: 0.0607\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0646 - val_loss: 0.0585\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0639 - val_loss: 0.0592\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0597\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0600\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0644 - val_loss: 0.0589\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0635 - val_loss: 0.0586\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0648 - val_loss: 0.0601\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0649 - val_loss: 0.0611\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0648 - val_loss: 0.0594\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0612 - val_loss: 0.0595\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0645 - val_loss: 0.0592\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0636 - val_loss: 0.0586\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0603\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0638 - val_loss: 0.0595\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0659 - val_loss: 0.0622\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0617 - val_loss: 0.0594\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0658 - val_loss: 0.0595\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0634 - val_loss: 0.0603\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0583\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0638 - val_loss: 0.0592\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0627 - val_loss: 0.0602\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0617 - val_loss: 0.0596\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0610 - val_loss: 0.0587\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0612 - val_loss: 0.0588\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0607\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0589\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0615 - val_loss: 0.0600\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0616 - val_loss: 0.0589\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0596\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0606\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0633 - val_loss: 0.0591\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0638 - val_loss: 0.0590\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0602 - val_loss: 0.0579\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0613 - val_loss: 0.0585\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0614 - val_loss: 0.0591\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0628 - val_loss: 0.0582\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0618 - val_loss: 0.0594\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0624 - val_loss: 0.0575\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0657 - val_loss: 0.0596\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0635 - val_loss: 0.0599\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0611\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0611 - val_loss: 0.0583\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0608 - val_loss: 0.0587\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0579\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0636 - val_loss: 0.0599\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0628 - val_loss: 0.0597\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0638 - val_loss: 0.0606\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0579\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0613 - val_loss: 0.0589\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0587\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0599\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0630 - val_loss: 0.0587\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0641 - val_loss: 0.0598\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0627 - val_loss: 0.0602\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0619 - val_loss: 0.0591\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0623 - val_loss: 0.0587\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0617 - val_loss: 0.0589\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0610 - val_loss: 0.0597\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0621 - val_loss: 0.0594\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0595 - val_loss: 0.0585\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0602\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0620 - val_loss: 0.0602\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0622 - val_loss: 0.0586\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0604 - val_loss: 0.0576\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0607 - val_loss: 0.0581\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0607\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0602\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0611 - val_loss: 0.0587\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0608 - val_loss: 0.0593\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0604 - val_loss: 0.0598\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0608 - val_loss: 0.0579\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:02:13,070]\u001b[0m Trial 88 finished with value: 0.05847552295609458 and parameters: {'learning_rate': 0.00047457287647348486, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 132ms/step - loss: 0.1595 - val_loss: 0.1064\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.1234 - val_loss: 0.0820\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.1139 - val_loss: 0.0782\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.1055 - val_loss: 0.0763\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.1004 - val_loss: 0.0743\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0916 - val_loss: 0.0718\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0895 - val_loss: 0.0694\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0847 - val_loss: 0.0667\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0817 - val_loss: 0.0662\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0775 - val_loss: 0.0644\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0767 - val_loss: 0.0639\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0754 - val_loss: 0.0627\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0732 - val_loss: 0.0617\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0729 - val_loss: 0.0615\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0716 - val_loss: 0.0607\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0709 - val_loss: 0.0606\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0704 - val_loss: 0.0601\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0677 - val_loss: 0.0603\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0678 - val_loss: 0.0603\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0681 - val_loss: 0.0598\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0670 - val_loss: 0.0600\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0664 - val_loss: 0.0597\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0660 - val_loss: 0.0601\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0599\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0655 - val_loss: 0.0595\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0660 - val_loss: 0.0599\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0655 - val_loss: 0.0598\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0668 - val_loss: 0.0597\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0655 - val_loss: 0.0596\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0654 - val_loss: 0.0595\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0654 - val_loss: 0.0595\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0650 - val_loss: 0.0606\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0653 - val_loss: 0.0599\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0597\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0599\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0600\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0628 - val_loss: 0.0606\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0646 - val_loss: 0.0601\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0598\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0671 - val_loss: 0.0596\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0630 - val_loss: 0.0603\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0657 - val_loss: 0.0606\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0643 - val_loss: 0.0600\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0599\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0638 - val_loss: 0.0607\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0637 - val_loss: 0.0609\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0630 - val_loss: 0.0603\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0644 - val_loss: 0.0604\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.0646 - val_loss: 0.0610\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0638 - val_loss: 0.0605\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0637 - val_loss: 0.0607\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0636 - val_loss: 0.0610\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0652 - val_loss: 0.0604\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0628 - val_loss: 0.0599\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0651 - val_loss: 0.0605\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0652 - val_loss: 0.0608\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0633 - val_loss: 0.0608\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0603\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0618 - val_loss: 0.0601\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0628 - val_loss: 0.0604\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0603\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0604\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0603\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0639 - val_loss: 0.0612\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0670 - val_loss: 0.0614\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0642 - val_loss: 0.0611\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0631 - val_loss: 0.0617\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0608\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0604\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0654 - val_loss: 0.0604\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0627 - val_loss: 0.0605\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0624 - val_loss: 0.0606\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0603\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0634 - val_loss: 0.0602\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0633 - val_loss: 0.0604\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0605\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0648 - val_loss: 0.0604\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0631 - val_loss: 0.0600\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0654 - val_loss: 0.0599\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0627 - val_loss: 0.0611\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0603\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0644 - val_loss: 0.0600\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0596\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0639 - val_loss: 0.0609\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0607\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0633 - val_loss: 0.0601\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0632 - val_loss: 0.0597\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0643 - val_loss: 0.0601\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0651 - val_loss: 0.0607\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0642 - val_loss: 0.0598\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0635 - val_loss: 0.0603\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0633 - val_loss: 0.0605\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0604\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0653 - val_loss: 0.0600\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0630 - val_loss: 0.0603\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0623 - val_loss: 0.0604\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0628 - val_loss: 0.0605\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0625 - val_loss: 0.0602\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0626 - val_loss: 0.0597\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:03:47,122]\u001b[0m Trial 89 finished with value: 0.06245081933217629 and parameters: {'learning_rate': 0.0003920060535650844, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 1, 'layers2': 1, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 136ms/step - loss: 0.2452 - val_loss: 0.1793\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1598 - val_loss: 0.1076\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.1122 - val_loss: 0.0770\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.1065 - val_loss: 0.0733\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0986 - val_loss: 0.0758\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0900 - val_loss: 0.0698\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0877 - val_loss: 0.0674\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0821 - val_loss: 0.0646\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0783 - val_loss: 0.0622\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0712 - val_loss: 0.0616\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0712 - val_loss: 0.0616\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0687 - val_loss: 0.0601\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0667 - val_loss: 0.0594\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0676 - val_loss: 0.0593\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0668 - val_loss: 0.0592\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0656 - val_loss: 0.0598\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0671 - val_loss: 0.0595\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0649 - val_loss: 0.0594\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0592\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0645 - val_loss: 0.0596\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0656 - val_loss: 0.0598\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0642 - val_loss: 0.0596\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0645 - val_loss: 0.0590\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0650 - val_loss: 0.0592\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0642 - val_loss: 0.0600\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0647 - val_loss: 0.0593\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0653 - val_loss: 0.0591\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0587\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0601\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0603\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0651 - val_loss: 0.0596\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0616 - val_loss: 0.0596\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0597\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0583\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0601\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0646 - val_loss: 0.0595\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0649 - val_loss: 0.0596\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0663 - val_loss: 0.0615\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0625 - val_loss: 0.0593\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0662 - val_loss: 0.0595\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0638 - val_loss: 0.0599\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0635 - val_loss: 0.0587\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0593\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0596\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0626 - val_loss: 0.0596\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0617 - val_loss: 0.0586\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0598\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0594\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0585\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0591\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0647 - val_loss: 0.0589\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0586\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0604\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0587\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0587\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0606 - val_loss: 0.0583\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0622 - val_loss: 0.0595\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0631 - val_loss: 0.0589\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0629 - val_loss: 0.0593\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0582\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0664 - val_loss: 0.0588\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0594\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0606\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0617 - val_loss: 0.0585\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0622 - val_loss: 0.0596\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0587\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0627 - val_loss: 0.0592\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0601\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0621 - val_loss: 0.0587\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0633 - val_loss: 0.0583\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0639 - val_loss: 0.0582\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0635 - val_loss: 0.0597\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0631 - val_loss: 0.0579\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0626 - val_loss: 0.0579\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0623 - val_loss: 0.0592\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0587\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0606 - val_loss: 0.0582\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0632 - val_loss: 0.0583\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0595\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0630 - val_loss: 0.0585\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0580\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0609 - val_loss: 0.0580\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0609 - val_loss: 0.0581\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0633 - val_loss: 0.0588\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0613 - val_loss: 0.0582\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0615 - val_loss: 0.0582\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0609 - val_loss: 0.0584\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0613 - val_loss: 0.0580\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:05:22,366]\u001b[0m Trial 90 finished with value: 0.06041269618652567 and parameters: {'learning_rate': 0.0003177107018860946, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 201ms/step - loss: 0.2257 - val_loss: 0.1433\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.1267 - val_loss: 0.0779\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.1069 - val_loss: 0.0728\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0949 - val_loss: 0.0725\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0888 - val_loss: 0.0671\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0801 - val_loss: 0.0645\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0766 - val_loss: 0.0611\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0706 - val_loss: 0.0600\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0688 - val_loss: 0.0597\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0651 - val_loss: 0.0616\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0673 - val_loss: 0.0600\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0652 - val_loss: 0.0596\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0655 - val_loss: 0.0589\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0660 - val_loss: 0.0589\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0663 - val_loss: 0.0596\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0654 - val_loss: 0.0606\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0664 - val_loss: 0.0596\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0650 - val_loss: 0.0604\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0639 - val_loss: 0.0597\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0598\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0659 - val_loss: 0.0607\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0592\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0640 - val_loss: 0.0592\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0637 - val_loss: 0.0592\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0641 - val_loss: 0.0604\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0645 - val_loss: 0.0592\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0649 - val_loss: 0.0593\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0635 - val_loss: 0.0589\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0651 - val_loss: 0.0602\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0648 - val_loss: 0.0606\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0649 - val_loss: 0.0588\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0613 - val_loss: 0.0592\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0644 - val_loss: 0.0592\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0634 - val_loss: 0.0587\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0618 - val_loss: 0.0597\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0636 - val_loss: 0.0590\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0644 - val_loss: 0.0593\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0660 - val_loss: 0.0625\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0622 - val_loss: 0.0594\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0659 - val_loss: 0.0592\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0633 - val_loss: 0.0600\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0584\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0598\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0617 - val_loss: 0.0595\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0609 - val_loss: 0.0589\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0613 - val_loss: 0.0590\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0643 - val_loss: 0.0606\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0634 - val_loss: 0.0590\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0616 - val_loss: 0.0597\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0641 - val_loss: 0.0583\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0616 - val_loss: 0.0588\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0648 - val_loss: 0.0593\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0608\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0635 - val_loss: 0.0594\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0636 - val_loss: 0.0589\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0600 - val_loss: 0.0578\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0612 - val_loss: 0.0584\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0614 - val_loss: 0.0595\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0627 - val_loss: 0.0582\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0619 - val_loss: 0.0595\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0628 - val_loss: 0.0575\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0655 - val_loss: 0.0599\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0633 - val_loss: 0.0595\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0640 - val_loss: 0.0606\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0610 - val_loss: 0.0583\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0610 - val_loss: 0.0588\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.0635 - val_loss: 0.0580\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0635 - val_loss: 0.0594\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0625 - val_loss: 0.0592\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0634 - val_loss: 0.0606\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0616 - val_loss: 0.0581\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0613 - val_loss: 0.0586\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0636 - val_loss: 0.0602\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0630 - val_loss: 0.0583\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0637 - val_loss: 0.0594\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0625 - val_loss: 0.0593\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0618 - val_loss: 0.0590\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0625 - val_loss: 0.0580\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0616 - val_loss: 0.0593\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0614 - val_loss: 0.0601\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0589\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0601 - val_loss: 0.0582\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0625 - val_loss: 0.0591\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0633 - val_loss: 0.0602\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0627 - val_loss: 0.0589\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0603 - val_loss: 0.0576\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0605 - val_loss: 0.0579\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0625 - val_loss: 0.0603\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0623 - val_loss: 0.0606\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0611 - val_loss: 0.0591\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0609 - val_loss: 0.0590\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0604 - val_loss: 0.0598\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0607 - val_loss: 0.0575\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:06:53,046]\u001b[0m Trial 91 finished with value: 0.05822629664845558 and parameters: {'learning_rate': 0.0004727473879087996, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 134ms/step - loss: 0.2248 - val_loss: 0.1416\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1258 - val_loss: 0.0776\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.1064 - val_loss: 0.0727\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0947 - val_loss: 0.0726\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0884 - val_loss: 0.0667\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0796 - val_loss: 0.0644\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0762 - val_loss: 0.0608\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0703 - val_loss: 0.0601\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0684 - val_loss: 0.0601\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0621\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0672 - val_loss: 0.0599\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0651 - val_loss: 0.0593\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0655 - val_loss: 0.0589\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0660 - val_loss: 0.0590\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0664 - val_loss: 0.0596\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0652 - val_loss: 0.0603\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0663 - val_loss: 0.0597\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0649 - val_loss: 0.0603\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0637 - val_loss: 0.0594\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0641 - val_loss: 0.0597\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0662 - val_loss: 0.0610\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0644 - val_loss: 0.0596\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0645 - val_loss: 0.0588\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0646 - val_loss: 0.0589\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0638 - val_loss: 0.0593\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0641 - val_loss: 0.0601\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0644 - val_loss: 0.0594\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0646 - val_loss: 0.0592\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0635 - val_loss: 0.0587\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0651 - val_loss: 0.0600\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0650 - val_loss: 0.0606\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0589\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0613 - val_loss: 0.0593\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0639 - val_loss: 0.0584\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0617 - val_loss: 0.0601\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0636 - val_loss: 0.0592\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0642 - val_loss: 0.0592\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0661 - val_loss: 0.0623\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0619 - val_loss: 0.0596\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0659 - val_loss: 0.0594\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0633 - val_loss: 0.0601\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0583\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0637 - val_loss: 0.0592\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0598\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0621 - val_loss: 0.0599\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0611 - val_loss: 0.0591\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0618 - val_loss: 0.0586\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0646 - val_loss: 0.0611\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0643 - val_loss: 0.0596\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0588\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0598\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0644 - val_loss: 0.0586\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0616 - val_loss: 0.0589\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0649 - val_loss: 0.0593\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0605\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0629 - val_loss: 0.0592\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0631 - val_loss: 0.0593\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0599 - val_loss: 0.0576\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0611 - val_loss: 0.0586\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0611 - val_loss: 0.0591\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0624 - val_loss: 0.0578\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0617 - val_loss: 0.0594\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0574\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0656 - val_loss: 0.0601\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0599\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0643 - val_loss: 0.0611\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0613 - val_loss: 0.0579\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0612 - val_loss: 0.0593\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0634 - val_loss: 0.0579\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0585\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0633 - val_loss: 0.0594\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0588\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0633 - val_loss: 0.0603\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0574\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0616 - val_loss: 0.0584\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0625 - val_loss: 0.0582\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0630 - val_loss: 0.0600\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0631 - val_loss: 0.0580\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0598\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0600\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0583\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0593\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0611 - val_loss: 0.0597\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0596 - val_loss: 0.0581\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0623 - val_loss: 0.0586\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0630 - val_loss: 0.0599\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0599\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0624 - val_loss: 0.0590\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0608 - val_loss: 0.0577\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0608 - val_loss: 0.0584\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0619 - val_loss: 0.0588\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0603\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0612 - val_loss: 0.0584\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0609 - val_loss: 0.0585\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0605 - val_loss: 0.0599\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0610 - val_loss: 0.0573\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:08:29,005]\u001b[0m Trial 92 finished with value: 0.058385310393095136 and parameters: {'learning_rate': 0.00048085601563701934, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 135ms/step - loss: 0.2244 - val_loss: 0.1407\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.1254 - val_loss: 0.0775\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.1062 - val_loss: 0.0727\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0946 - val_loss: 0.0724\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0882 - val_loss: 0.0667\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0794 - val_loss: 0.0642\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0759 - val_loss: 0.0607\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0698 - val_loss: 0.0600\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0682 - val_loss: 0.0601\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0652 - val_loss: 0.0616\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0671 - val_loss: 0.0598\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0651 - val_loss: 0.0593\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0655 - val_loss: 0.0588\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0660 - val_loss: 0.0589\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0661 - val_loss: 0.0595\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0652 - val_loss: 0.0603\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0661 - val_loss: 0.0591\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0649 - val_loss: 0.0599\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0638 - val_loss: 0.0596\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0642 - val_loss: 0.0600\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0662 - val_loss: 0.0610\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0598\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0645 - val_loss: 0.0591\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0646 - val_loss: 0.0590\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0639 - val_loss: 0.0594\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0640 - val_loss: 0.0596\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0638 - val_loss: 0.0600\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0644 - val_loss: 0.0596\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0650 - val_loss: 0.0594\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0587\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0651 - val_loss: 0.0599\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0649 - val_loss: 0.0600\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0657 - val_loss: 0.0592\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0614 - val_loss: 0.0594\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0643 - val_loss: 0.0598\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0638 - val_loss: 0.0585\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0618 - val_loss: 0.0598\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0636 - val_loss: 0.0594\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0659 - val_loss: 0.0617\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0653 - val_loss: 0.0596\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0634 - val_loss: 0.0603\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0629 - val_loss: 0.0586\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0639 - val_loss: 0.0593\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0627 - val_loss: 0.0604\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0617 - val_loss: 0.0597\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0609 - val_loss: 0.0589\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0611 - val_loss: 0.0592\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0644 - val_loss: 0.0608\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0638 - val_loss: 0.0595\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0634 - val_loss: 0.0588\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0615 - val_loss: 0.0597\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0613 - val_loss: 0.0590\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0646 - val_loss: 0.0597\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0633 - val_loss: 0.0607\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0589\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0633 - val_loss: 0.0587\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0599 - val_loss: 0.0579\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0611 - val_loss: 0.0586\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0612 - val_loss: 0.0598\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0625 - val_loss: 0.0582\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0618 - val_loss: 0.0596\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0573\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0652 - val_loss: 0.0588\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0635 - val_loss: 0.0599\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0645 - val_loss: 0.0609\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0611 - val_loss: 0.0586\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0611 - val_loss: 0.0589\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0632 - val_loss: 0.0578\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0619 - val_loss: 0.0591\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0598\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0623 - val_loss: 0.0595\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0637 - val_loss: 0.0604\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0620 - val_loss: 0.0574\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0615 - val_loss: 0.0584\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0627 - val_loss: 0.0582\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0632 - val_loss: 0.0605\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0632 - val_loss: 0.0587\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0644 - val_loss: 0.0601\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0628 - val_loss: 0.0595\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0619 - val_loss: 0.0590\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0581\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.0617 - val_loss: 0.0593\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0616 - val_loss: 0.0596\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0624 - val_loss: 0.0580\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0599 - val_loss: 0.0578\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0625 - val_loss: 0.0590\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0602\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0629 - val_loss: 0.0589\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0621 - val_loss: 0.0580\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0602 - val_loss: 0.0577\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0608 - val_loss: 0.0576\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0623 - val_loss: 0.0595\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0624 - val_loss: 0.0593\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0609 - val_loss: 0.0584\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0608 - val_loss: 0.0584\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0606 - val_loss: 0.0597\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0606 - val_loss: 0.0576\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:10:02,723]\u001b[0m Trial 93 finished with value: 0.05853873374095454 and parameters: {'learning_rate': 0.0004853611312982456, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 134ms/step - loss: 0.2178 - val_loss: 0.1282\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.1208 - val_loss: 0.0770\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.1027 - val_loss: 0.0736\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0925 - val_loss: 0.0693\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0852 - val_loss: 0.0650\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0766 - val_loss: 0.0618\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0735 - val_loss: 0.0597\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0679 - val_loss: 0.0603\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0673 - val_loss: 0.0611\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0656 - val_loss: 0.0617\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0672 - val_loss: 0.0599\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0652 - val_loss: 0.0590\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0654 - val_loss: 0.0590\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0656 - val_loss: 0.0593\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0658 - val_loss: 0.0593\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0655 - val_loss: 0.0599\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0665 - val_loss: 0.0596\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0648 - val_loss: 0.0602\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0643 - val_loss: 0.0601\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0665 - val_loss: 0.0613\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0590\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0646 - val_loss: 0.0587\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0640 - val_loss: 0.0592\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0642 - val_loss: 0.0596\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0641 - val_loss: 0.0601\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0643 - val_loss: 0.0598\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0650 - val_loss: 0.0594\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0636 - val_loss: 0.0587\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0649 - val_loss: 0.0598\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0645 - val_loss: 0.0606\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0647 - val_loss: 0.0589\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0616 - val_loss: 0.0594\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0643 - val_loss: 0.0587\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0637 - val_loss: 0.0583\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0597\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0636 - val_loss: 0.0595\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0597\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0659 - val_loss: 0.0626\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0657 - val_loss: 0.0589\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0634 - val_loss: 0.0600\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0640 - val_loss: 0.0588\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0627 - val_loss: 0.0601\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0621 - val_loss: 0.0586\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0605 - val_loss: 0.0589\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0607 - val_loss: 0.0593\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0641 - val_loss: 0.0607\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0631 - val_loss: 0.0588\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0616 - val_loss: 0.0607\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0638 - val_loss: 0.0590\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0610 - val_loss: 0.0589\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0644 - val_loss: 0.0599\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0630 - val_loss: 0.0605\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0625 - val_loss: 0.0585\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0593\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0596 - val_loss: 0.0584\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0609 - val_loss: 0.0596\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0606 - val_loss: 0.0595\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0623 - val_loss: 0.0590\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0612 - val_loss: 0.0593\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0624 - val_loss: 0.0573\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0655 - val_loss: 0.0589\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0600\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0643 - val_loss: 0.0602\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0610 - val_loss: 0.0581\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0608 - val_loss: 0.0596\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0631 - val_loss: 0.0588\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0615 - val_loss: 0.0596\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0623 - val_loss: 0.0589\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0619 - val_loss: 0.0596\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0631 - val_loss: 0.0608\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0620 - val_loss: 0.0574\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0614 - val_loss: 0.0584\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0624 - val_loss: 0.0587\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0628 - val_loss: 0.0600\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0626 - val_loss: 0.0585\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0642 - val_loss: 0.0597\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0622 - val_loss: 0.0596\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0619 - val_loss: 0.0595\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0622 - val_loss: 0.0586\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0618 - val_loss: 0.0588\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0610 - val_loss: 0.0602\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0618 - val_loss: 0.0590\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0597 - val_loss: 0.0590\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0628 - val_loss: 0.0589\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0632 - val_loss: 0.0613\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0622 - val_loss: 0.0577\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0624 - val_loss: 0.0574\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0605 - val_loss: 0.0561\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0610 - val_loss: 0.0575\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.0621 - val_loss: 0.0594\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0603\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0607 - val_loss: 0.0591\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0604 - val_loss: 0.0584\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0604 - val_loss: 0.0589\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0600 - val_loss: 0.0573\n",
            "2/2 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:11:35,159]\u001b[0m Trial 94 finished with value: 0.05925158610237004 and parameters: {'learning_rate': 0.0005462175621406749, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 145ms/step - loss: 0.2242 - val_loss: 0.1404\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.1253 - val_loss: 0.0775\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.1062 - val_loss: 0.0727\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0945 - val_loss: 0.0724\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0883 - val_loss: 0.0667\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0794 - val_loss: 0.0639\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0759 - val_loss: 0.0607\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0698 - val_loss: 0.0599\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0681 - val_loss: 0.0602\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0653 - val_loss: 0.0619\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0673 - val_loss: 0.0600\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0652 - val_loss: 0.0593\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0655 - val_loss: 0.0588\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0657 - val_loss: 0.0590\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0660 - val_loss: 0.0596\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0653 - val_loss: 0.0606\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0664 - val_loss: 0.0594\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0648 - val_loss: 0.0597\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0637 - val_loss: 0.0598\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0643 - val_loss: 0.0603\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0661 - val_loss: 0.0614\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0643 - val_loss: 0.0600\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0644 - val_loss: 0.0595\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0641 - val_loss: 0.0597\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0640 - val_loss: 0.0595\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0600\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0645 - val_loss: 0.0596\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0650 - val_loss: 0.0592\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0638 - val_loss: 0.0588\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0649 - val_loss: 0.0598\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0602\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0647 - val_loss: 0.0595\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0619 - val_loss: 0.0597\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0600\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0638 - val_loss: 0.0586\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0600\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0634 - val_loss: 0.0597\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0641 - val_loss: 0.0595\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0658 - val_loss: 0.0618\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0618 - val_loss: 0.0591\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0654 - val_loss: 0.0594\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0632 - val_loss: 0.0607\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0636 - val_loss: 0.0593\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0606\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0620 - val_loss: 0.0595\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0607 - val_loss: 0.0589\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0609 - val_loss: 0.0598\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0642 - val_loss: 0.0613\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0630 - val_loss: 0.0598\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0630 - val_loss: 0.0595\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0617 - val_loss: 0.0603\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0643 - val_loss: 0.0589\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0613 - val_loss: 0.0594\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0647 - val_loss: 0.0606\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0629 - val_loss: 0.0613\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0628 - val_loss: 0.0592\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0629 - val_loss: 0.0586\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0596 - val_loss: 0.0579\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0608 - val_loss: 0.0594\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0605 - val_loss: 0.0597\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0624 - val_loss: 0.0585\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0615 - val_loss: 0.0598\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0625 - val_loss: 0.0577\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0653 - val_loss: 0.0595\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0632 - val_loss: 0.0601\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0613\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0610 - val_loss: 0.0589\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0605 - val_loss: 0.0590\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0631 - val_loss: 0.0581\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0616 - val_loss: 0.0592\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0629 - val_loss: 0.0601\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0620 - val_loss: 0.0600\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0635 - val_loss: 0.0605\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0620 - val_loss: 0.0579\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0612 - val_loss: 0.0588\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0625 - val_loss: 0.0583\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0628 - val_loss: 0.0603\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0630 - val_loss: 0.0593\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0639 - val_loss: 0.0603\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0625 - val_loss: 0.0598\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0619 - val_loss: 0.0599\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0620 - val_loss: 0.0587\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0616 - val_loss: 0.0594\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0606 - val_loss: 0.0602\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0619 - val_loss: 0.0594\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0593 - val_loss: 0.0584\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0624 - val_loss: 0.0589\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0629 - val_loss: 0.0597\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0629 - val_loss: 0.0592\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0602 - val_loss: 0.0572\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0608 - val_loss: 0.0584\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0620 - val_loss: 0.0605\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0623 - val_loss: 0.0598\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.0609 - val_loss: 0.0587\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0606 - val_loss: 0.0592\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.0603 - val_loss: 0.0595\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0605 - val_loss: 0.0574\n",
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:13:17,380]\u001b[0m Trial 95 finished with value: 0.05828501957967283 and parameters: {'learning_rate': 0.00048664933516662625, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 153ms/step - loss: 0.1150 - val_loss: 0.0665\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0854 - val_loss: 0.0724\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0828 - val_loss: 0.0629\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0853 - val_loss: 0.0644\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0807 - val_loss: 0.0643\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0771 - val_loss: 0.0609\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0752 - val_loss: 0.0622\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0764 - val_loss: 0.0610\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0739 - val_loss: 0.0607\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0720 - val_loss: 0.0605\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0753 - val_loss: 0.0659\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0737 - val_loss: 0.0625\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0751 - val_loss: 0.0632\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0708 - val_loss: 0.0595\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0731 - val_loss: 0.0602\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0743 - val_loss: 0.0620\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0720 - val_loss: 0.0592\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0687 - val_loss: 0.0639\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 0.0697 - val_loss: 0.0596\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 0.0680 - val_loss: 0.0591\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0665 - val_loss: 0.0599\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0698 - val_loss: 0.0598\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0668 - val_loss: 0.0594\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0667 - val_loss: 0.0595\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0663 - val_loss: 0.0588\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0665 - val_loss: 0.0600\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0665 - val_loss: 0.0599\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0664 - val_loss: 0.0592\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0663 - val_loss: 0.0599\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0674 - val_loss: 0.0586\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0679 - val_loss: 0.0616\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0665 - val_loss: 0.0608\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0666 - val_loss: 0.0596\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0690 - val_loss: 0.0596\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0666 - val_loss: 0.0581\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0650 - val_loss: 0.0597\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0660 - val_loss: 0.0611\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0650 - val_loss: 0.0576\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0622 - val_loss: 0.0581\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0638 - val_loss: 0.0606\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0667 - val_loss: 0.0579\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0684 - val_loss: 0.0582\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0650 - val_loss: 0.0578\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0647 - val_loss: 0.0576\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0691 - val_loss: 0.0562\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0622 - val_loss: 0.0570\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0610 - val_loss: 0.0594\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0683 - val_loss: 0.0574\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.0675 - val_loss: 0.0579\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.0656 - val_loss: 0.0569\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0631 - val_loss: 0.0557\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0642 - val_loss: 0.0582\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.0633 - val_loss: 0.0578\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0660 - val_loss: 0.0560\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0654 - val_loss: 0.0576\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0644 - val_loss: 0.0573\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0636 - val_loss: 0.0563\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0641 - val_loss: 0.0566\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0630 - val_loss: 0.0568\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0633 - val_loss: 0.0560\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0636 - val_loss: 0.0549\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0649 - val_loss: 0.0550\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0635 - val_loss: 0.0555\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0598 - val_loss: 0.0542\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0625 - val_loss: 0.0573\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0618 - val_loss: 0.0561\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0629 - val_loss: 0.0536\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0618 - val_loss: 0.0578\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0623 - val_loss: 0.0546\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0645 - val_loss: 0.0552\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0635 - val_loss: 0.0561\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0643 - val_loss: 0.0559\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0631 - val_loss: 0.0560\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0641 - val_loss: 0.0570\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0622 - val_loss: 0.0558\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0623 - val_loss: 0.0563\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0627 - val_loss: 0.0558\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 0.0631 - val_loss: 0.0542\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0629 - val_loss: 0.0555\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0626 - val_loss: 0.0546\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0654 - val_loss: 0.0565\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0616 - val_loss: 0.0550\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0659 - val_loss: 0.0558\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0628 - val_loss: 0.0543\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0621 - val_loss: 0.0569\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0635 - val_loss: 0.0564\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0625 - val_loss: 0.0547\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.0611 - val_loss: 0.0562\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0627 - val_loss: 0.0551\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0635 - val_loss: 0.0566\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0627 - val_loss: 0.0536\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.0647 - val_loss: 0.0555\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0622 - val_loss: 0.0539\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0644 - val_loss: 0.0557\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0626 - val_loss: 0.0568\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.0647 - val_loss: 0.0549\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0554\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.0642 - val_loss: 0.0567\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0610 - val_loss: 0.0554\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0604 - val_loss: 0.0558\n",
            "2/2 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 74). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:15:14,624]\u001b[0m Trial 96 finished with value: 0.06688195407499875 and parameters: {'learning_rate': 0.0004853078770800494, 'nb_filter': 3, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 142ms/step - loss: 0.2306 - val_loss: 0.1531\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1332 - val_loss: 0.0810\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1090 - val_loss: 0.0740\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0976 - val_loss: 0.0749\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0910 - val_loss: 0.0685\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0825 - val_loss: 0.0651\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0796 - val_loss: 0.0623\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0729 - val_loss: 0.0610\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0710 - val_loss: 0.0597\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0664 - val_loss: 0.0603\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0677 - val_loss: 0.0600\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0661 - val_loss: 0.0595\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0663 - val_loss: 0.0584\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0663 - val_loss: 0.0585\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0668 - val_loss: 0.0589\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0655 - val_loss: 0.0595\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0667 - val_loss: 0.0592\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0648 - val_loss: 0.0594\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0641 - val_loss: 0.0590\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0647 - val_loss: 0.0596\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0652 - val_loss: 0.0595\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0640 - val_loss: 0.0588\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0647 - val_loss: 0.0587\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0586\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0644 - val_loss: 0.0589\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0645 - val_loss: 0.0589\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0641 - val_loss: 0.0588\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0653 - val_loss: 0.0587\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0654 - val_loss: 0.0588\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0582\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0647 - val_loss: 0.0590\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0644 - val_loss: 0.0598\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0650 - val_loss: 0.0591\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0612 - val_loss: 0.0589\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0640 - val_loss: 0.0586\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0618 - val_loss: 0.0596\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0646 - val_loss: 0.0593\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0648 - val_loss: 0.0592\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0659 - val_loss: 0.0606\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0589\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0660 - val_loss: 0.0590\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0639 - val_loss: 0.0591\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0637 - val_loss: 0.0585\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0643 - val_loss: 0.0589\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0633 - val_loss: 0.0594\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0625 - val_loss: 0.0592\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0616 - val_loss: 0.0586\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0645 - val_loss: 0.0599\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0644 - val_loss: 0.0590\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0636 - val_loss: 0.0587\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0590\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0649 - val_loss: 0.0588\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0630 - val_loss: 0.0584\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0648 - val_loss: 0.0587\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0640 - val_loss: 0.0599\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0630 - val_loss: 0.0589\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0605 - val_loss: 0.0586\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0624 - val_loss: 0.0586\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0628 - val_loss: 0.0587\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0625 - val_loss: 0.0591\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0632 - val_loss: 0.0581\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0667 - val_loss: 0.0587\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0635 - val_loss: 0.0592\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0641 - val_loss: 0.0602\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0617 - val_loss: 0.0586\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0620 - val_loss: 0.0593\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0642 - val_loss: 0.0586\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0588\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0595\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0632 - val_loss: 0.0592\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0625 - val_loss: 0.0587\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0638 - val_loss: 0.0583\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0639 - val_loss: 0.0592\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0638 - val_loss: 0.0584\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0636 - val_loss: 0.0587\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0632 - val_loss: 0.0591\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0629 - val_loss: 0.0588\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0633 - val_loss: 0.0584\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0625 - val_loss: 0.0583\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0622 - val_loss: 0.0590\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0627 - val_loss: 0.0587\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0609 - val_loss: 0.0582\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0633 - val_loss: 0.0579\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0643 - val_loss: 0.0593\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0630 - val_loss: 0.0590\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0624 - val_loss: 0.0582\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0612 - val_loss: 0.0580\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0615 - val_loss: 0.0579\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0636 - val_loss: 0.0586\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0624 - val_loss: 0.0584\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0614 - val_loss: 0.0581\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0616 - val_loss: 0.0585\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0612 - val_loss: 0.0583\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0615 - val_loss: 0.0582\n",
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:16:53,462]\u001b[0m Trial 97 finished with value: 0.06109077798411491 and parameters: {'learning_rate': 0.00043205480151367094, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 0.001, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 70 with value: 0.05790674968668603.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 142ms/step - loss: 0.2238 - val_loss: 0.1396\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.1248 - val_loss: 0.0774\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.1059 - val_loss: 0.0726\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0943 - val_loss: 0.0725\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0878 - val_loss: 0.0661\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0790 - val_loss: 0.0639\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0757 - val_loss: 0.0605\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0697 - val_loss: 0.0596\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0679 - val_loss: 0.0602\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0651 - val_loss: 0.0623\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0671 - val_loss: 0.0595\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0651 - val_loss: 0.0590\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0654 - val_loss: 0.0591\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0658 - val_loss: 0.0588\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0663 - val_loss: 0.0593\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0653 - val_loss: 0.0607\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0663 - val_loss: 0.0590\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0648 - val_loss: 0.0597\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0639 - val_loss: 0.0596\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0642 - val_loss: 0.0600\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0661 - val_loss: 0.0609\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0645 - val_loss: 0.0595\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0647 - val_loss: 0.0590\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0641 - val_loss: 0.0592\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0639 - val_loss: 0.0601\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0642 - val_loss: 0.0595\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0648 - val_loss: 0.0594\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0636 - val_loss: 0.0585\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0649 - val_loss: 0.0594\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0646 - val_loss: 0.0601\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0647 - val_loss: 0.0590\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0612 - val_loss: 0.0596\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0641 - val_loss: 0.0597\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0635 - val_loss: 0.0588\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0618 - val_loss: 0.0603\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0635 - val_loss: 0.0592\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0640 - val_loss: 0.0589\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0660 - val_loss: 0.0617\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0620 - val_loss: 0.0589\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0656 - val_loss: 0.0591\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0632 - val_loss: 0.0599\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0627 - val_loss: 0.0577\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0639 - val_loss: 0.0584\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0626 - val_loss: 0.0599\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0615 - val_loss: 0.0596\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0607 - val_loss: 0.0589\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0609 - val_loss: 0.0592\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0643 - val_loss: 0.0607\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0637 - val_loss: 0.0591\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0631 - val_loss: 0.0591\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0600\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0640 - val_loss: 0.0586\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0615 - val_loss: 0.0584\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0644 - val_loss: 0.0596\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0631 - val_loss: 0.0602\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.0632 - val_loss: 0.0591\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0635 - val_loss: 0.0583\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0600 - val_loss: 0.0574\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0609 - val_loss: 0.0587\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0610 - val_loss: 0.0594\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0624 - val_loss: 0.0582\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0617 - val_loss: 0.0593\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0625 - val_loss: 0.0575\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0656 - val_loss: 0.0598\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0634 - val_loss: 0.0603\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0642 - val_loss: 0.0606\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0611 - val_loss: 0.0584\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0607 - val_loss: 0.0590\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0632 - val_loss: 0.0579\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0621 - val_loss: 0.0592\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0631 - val_loss: 0.0602\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0623 - val_loss: 0.0605\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0637 - val_loss: 0.0610\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0621 - val_loss: 0.0585\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0611 - val_loss: 0.0584\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0622 - val_loss: 0.0585\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0632 - val_loss: 0.0602\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0628 - val_loss: 0.0590\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0643 - val_loss: 0.0607\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0627 - val_loss: 0.0598\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0619 - val_loss: 0.0597\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0621 - val_loss: 0.0584\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0617 - val_loss: 0.0592\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0611 - val_loss: 0.0601\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0623 - val_loss: 0.0591\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0595 - val_loss: 0.0586\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0622 - val_loss: 0.0590\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0633 - val_loss: 0.0601\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0627 - val_loss: 0.0600\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0623 - val_loss: 0.0589\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0605 - val_loss: 0.0573\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0608 - val_loss: 0.0573\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0622 - val_loss: 0.0594\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0628 - val_loss: 0.0600\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0610 - val_loss: 0.0587\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.0608 - val_loss: 0.0589\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0604 - val_loss: 0.0592\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.0608 - val_loss: 0.0570\n",
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:18:33,440]\u001b[0m Trial 98 finished with value: 0.05762980538051311 and parameters: {'learning_rate': 0.0004902206362619683, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 98 with value: 0.05762980538051311.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [2, 3] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 2].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [1, 2] and step=3, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:686: UserWarning: The distribution is specified by [50, 100] and step=150, but the range is not divisible by `step`. It will be replaced by [50, 50].\n",
            "  low=low, old_high=old_high, high=high, step=step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 3s 151ms/step - loss: 0.2194 - val_loss: 0.1312\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1216 - val_loss: 0.0771\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.1035 - val_loss: 0.0733\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0931 - val_loss: 0.0703\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0860 - val_loss: 0.0653\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.0772 - val_loss: 0.0622\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0741 - val_loss: 0.0601\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0681 - val_loss: 0.0601\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0675 - val_loss: 0.0611\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.0656 - val_loss: 0.0629\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0672 - val_loss: 0.0597\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0651 - val_loss: 0.0592\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0654 - val_loss: 0.0592\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0657 - val_loss: 0.0592\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0661 - val_loss: 0.0595\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0652 - val_loss: 0.0600\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.0664 - val_loss: 0.0597\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0649 - val_loss: 0.0603\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0639 - val_loss: 0.0591\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0638 - val_loss: 0.0594\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0662 - val_loss: 0.0603\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0644 - val_loss: 0.0591\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0645 - val_loss: 0.0587\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0645 - val_loss: 0.0586\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0639 - val_loss: 0.0588\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0639 - val_loss: 0.0600\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0642 - val_loss: 0.0597\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0645 - val_loss: 0.0590\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0634 - val_loss: 0.0583\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0646 - val_loss: 0.0597\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0643 - val_loss: 0.0606\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0643 - val_loss: 0.0590\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0609 - val_loss: 0.0592\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0639 - val_loss: 0.0589\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0633 - val_loss: 0.0587\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0617 - val_loss: 0.0606\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.0637 - val_loss: 0.0593\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0640 - val_loss: 0.0593\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0656 - val_loss: 0.0613\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0618 - val_loss: 0.0593\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0652 - val_loss: 0.0593\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.0632 - val_loss: 0.0594\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0625 - val_loss: 0.0580\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0636 - val_loss: 0.0587\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.0626 - val_loss: 0.0602\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.0615 - val_loss: 0.0592\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0605 - val_loss: 0.0587\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0608 - val_loss: 0.0593\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0644 - val_loss: 0.0617\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 1s 126ms/step - loss: 0.0632 - val_loss: 0.0591\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0631 - val_loss: 0.0590\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0617 - val_loss: 0.0606\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0643 - val_loss: 0.0587\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0612 - val_loss: 0.0586\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0646 - val_loss: 0.0595\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0630 - val_loss: 0.0604\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0627 - val_loss: 0.0592\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0629 - val_loss: 0.0584\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0601 - val_loss: 0.0566\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0610 - val_loss: 0.0589\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0610 - val_loss: 0.0591\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0625 - val_loss: 0.0582\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0614 - val_loss: 0.0588\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0622 - val_loss: 0.0573\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.0650 - val_loss: 0.0600\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0632 - val_loss: 0.0596\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.0640 - val_loss: 0.0607\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0608 - val_loss: 0.0583\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.0607 - val_loss: 0.0590\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.0630 - val_loss: 0.0575\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0617 - val_loss: 0.0588\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.0630 - val_loss: 0.0597\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0618 - val_loss: 0.0600\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.0634 - val_loss: 0.0606\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.0624 - val_loss: 0.0588\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0619 - val_loss: 0.0583\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0628 - val_loss: 0.0588\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0637 - val_loss: 0.0613\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.0629 - val_loss: 0.0583\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0648 - val_loss: 0.0601\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.0625 - val_loss: 0.0597\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0621 - val_loss: 0.0593\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0622 - val_loss: 0.0582\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0616 - val_loss: 0.0588\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.0613 - val_loss: 0.0598\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.0623 - val_loss: 0.0585\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0596 - val_loss: 0.0585\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.0622 - val_loss: 0.0587\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.0632 - val_loss: 0.0608\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.0626 - val_loss: 0.0591\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.0624 - val_loss: 0.0577\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0602 - val_loss: 0.0567\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.0606 - val_loss: 0.0578\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.0623 - val_loss: 0.0592\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.0621 - val_loss: 0.0590\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.0607 - val_loss: 0.0580\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.0608 - val_loss: 0.0584\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.0604 - val_loss: 0.0587\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.0610 - val_loss: 0.0575\n",
            "2/2 [==============================] - 1s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_fn, residual_block_0_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n",
            "\u001b[32m[I 2022-11-14 18:20:21,281]\u001b[0m Trial 99 finished with value: 0.058474356741100075 and parameters: {'learning_rate': 0.0005303343069472293, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}. Best is trial 98 with value: 0.05762980538051311.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "reset_random_seeds()\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=21))\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vDhCbdRu8xPh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "60Pzkl858u19",
        "outputId": "ac0d6fd9-c13c-4aa5-aa70-81ba05ec71fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.05762980538051311\n",
            "Best hyperparameters: {'learning_rate': 0.0004902206362619683, 'nb_filter': 2, 'kernel_size': 2, 'nb_stacks': 1, 'decay': 1e-05, 'dense1': 50, 'dense2': 50, 'activation1': 'linear', 'activation2': 'relu', 'layers1': 3, 'layers2': 3, 'dropout_rate': 0.0, 'epochs': 100}\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "0.05762980538051311\n",
            "98\n"
          ]
        }
      ],
      "source": [
        "trial = study.best_trial\n",
        "print('MSE: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))\n",
        "with open(\"/content/drive/MyDrive/TCN_400/{}.pickle\".format(study.best_trial.number), \"rb\") as fin:\n",
        "    best_tcn = pickle.load(fin)\n",
        "model = best_tcn\n",
        "y_pred = model.predict(input_test)\n",
        "mse = mean_squared_error(output_test, y_pred)\n",
        "print(mse)\n",
        "print(study.best_trial.number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1b3OttlJ8y7f",
        "outputId": "13d22257-ab07-495c-e501-e4310820de21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 16ms/step\n",
            "0.9116519314771111\n"
          ]
        }
      ],
      "source": [
        "train_pred = model.predict(input_train)\n",
        "train_nrmse = np.sqrt(np.sum((output_train - train_pred)**2))/np.sqrt(np.sum((output_train - np.average(output_train))**2))\n",
        "print(train_nrmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hR0aIhhd80hh",
        "outputId": "8b3202a3-1d2e-4af9-a5a7-802a16fc47a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"b4e04875-122a-4b9c-ad75-ca7d261a0a28\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b4e04875-122a-4b9c-ad75-ca7d261a0a28\")) {                    Plotly.newPlot(                        \"b4e04875-122a-4b9c-ad75-ca7d261a0a28\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.061310371235159956,0.06367555398126995,0.06285439970394634,0.061734803556181134,0.06351078797144726,0.06270774247215814,0.06112011983093863,0.06217703616460952,0.061993390933001366,0.062351122734517345,0.06342583965605045,0.06203197164850083,0.06312248363439851,0.0630532154945284,0.06201794639372511,0.0617800260366049,0.06280246736142317,0.0624878005827534,0.06302349286653905,0.06192365791049718,0.060385942772235406,0.06028892838355286,0.06026837469723022,0.06000529532369251,0.06050282274723499,0.06018717694693776,0.06037283386720821,0.060633639855959195,0.0605476770794937,0.061067948439516184,0.06009188676303226,0.060343494142338236,0.060489937697731755,0.060287951164876674,0.059985352049217906,0.0604126576961287,0.061032757735291834,0.060504387090303535,0.06099258572776439,0.06009715360281694,0.06087349813757747,0.060578331553446725,0.05986814472207531,0.06044665673239763,0.062095964415632025,0.06026569381690881,0.06055149325169046,0.060133759276318144,0.062103066371016605,0.060807437286348714,0.06062389969542785,0.061014664124740145,0.05977768964957389,0.05997878760861784,0.05991068248732612,0.062092350394078184,0.06167984400506969,0.06049335834475459,0.06112352323358207,0.06148252455636771,0.06280951194791826,0.06045936963653656,0.060307031408755804,0.06030905140366405,0.06006956279200838,0.06144067515128643,0.05880281624670264,0.06015701429944101,0.05924656805288328,0.06239950916608885,0.05790674968668603,0.05881450304305483,0.061277967766665775,0.058830504010486326,0.05978448409304834,0.05977310886387063,0.06535704179150743,0.060623982051587554,0.060363538038311376,0.05952289685309839,0.05919703306359705,0.05888971474753407,0.059205727590760655,0.058516639379729944,0.0593304979228369,0.05885807485001718,0.059250486311838116,0.05953363230516299,0.05847552295609458,0.06245081933217629,0.06041269618652567,0.05822629664845558,0.058385310393095136,0.05853873374095454,0.05925158610237004,0.05828501957967283,0.06688195407499875,0.06109077798411491,0.05762980538051311,0.058474356741100075],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.061310371235159956,0.061310371235159956,0.061310371235159956,0.061310371235159956,0.061310371235159956,0.061310371235159956,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.06112011983093863,0.060385942772235406,0.06028892838355286,0.06026837469723022,0.06000529532369251,0.06000529532369251,0.06000529532369251,0.06000529532369251,0.06000529532369251,0.06000529532369251,0.06000529532369251,0.06000529532369251,0.06000529532369251,0.06000529532369251,0.06000529532369251,0.059985352049217906,0.059985352049217906,0.059985352049217906,0.059985352049217906,0.059985352049217906,0.059985352049217906,0.059985352049217906,0.059985352049217906,0.05986814472207531,0.05986814472207531,0.05986814472207531,0.05986814472207531,0.05986814472207531,0.05986814472207531,0.05986814472207531,0.05986814472207531,0.05986814472207531,0.05986814472207531,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05977768964957389,0.05880281624670264,0.05880281624670264,0.05880281624670264,0.05880281624670264,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05790674968668603,0.05762980538051311,0.05762980538051311],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b4e04875-122a-4b9c-ad75-ca7d261a0a28');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZjgjQXR4818e",
        "outputId": "8ef7ccd2-1fea-4948-8d13-6049d25e46dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 15ms/step\n",
            "0.9621566657366498\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(input_validation)\n",
        "nrmse = np.sqrt(np.sum((output_validation - y_pred)**2))/np.sqrt(np.sum((output_validation - np.average(output_validation))**2))\n",
        "print(nrmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WxZT6Ewm85lh",
        "outputId": "7c632ae7-c110-4073-a77b-50ebfebd4066"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fa7127c8e90>"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAb3ElEQVR4nO3df4wc533f8fdHp6N0suUcXV4B80iJlEExpq1UdLa0C6FKnEgmbaMkYaUpFRiVCqOsXLOOLZcICQtVQwU1LSJGU4SFxKpE3QIyZbsCcYZsXFVLqps0VLjsMWJI9+ITrYhcGfBFFGW0OktH6ts/do5aLndvZ+92Z3dnPy+A4M6vve/szH73med5Zh5FBGZmll9XdToAMzNrLyd6M7Occ6I3M8s5J3ozs5xzojczy7mrOx1AtWXLlsWqVas6HYaZWU85duzY30TESK1lXZfoV61aRbFY7HQYZmY9RdJf11vmqhszs5xzojczyzknejOznHOiNzPLOSd6M7Oc67peN2ZmrXR4osS+8UleOT/D8uEhdm5cy9b1o50OK1NO9GaWW4cnSux+8gQzsxcBKJ2fYfeTJwD6Ktm76sbMcmvf+OSlJD9nZvYi+8YnOxRRZzjRm1luvXJ+pqn5eeVEb2a5tXx4qKn5eeVEb2a5tXPjWoYGBy6bNzQ4wM6NazsUUWe4MdbMcmuuwdW9blKQtAn4I2AAeCwi9lYtvxfYB5SSWX8cEY8lyy4CJ5L5L0fE5hbEbWaWytb1o12b2LPq+tkw0UsaAPYDdwJngaOSxiLiVNWqT0TEjhpvMRMRty4+VDOz/Miy62eaOvoNwFREnI6It4BDwJaWRmFm1mey7PqZJtGPAmcqps8m86rdJekFSd+RtLJi/rWSipKOSNpa6w9I2p6sU5yenk4fvZlZj8qy62eret18F1gVEb8CPA18o2LZjRFRAH4H+LeS3l+9cUQciIhCRBRGRmoOkGJmlitZdv1Mk+hLQGUJfQXvNLoCEBGvRsSbyeRjwK9WLCsl/58GngPWLyJeMw5PlLht7zOs3vUUt+19hsMTpcYbmXWZLLt+pkn0R4E1klZLWgJsA8YqV5D0vorJzcCPkvlLJV2TvF4G3AZUN+KapTbXgFU6P0PwTgOWk731mq3rR/nqp29hdHgIAaPDQ3z107d0ptdNRFyQtAMYp9y98mBEnJS0ByhGxBjwBUmbgQvAOeDeZPMPAI9Kepvyj8reGr11zFKbrwGrW7vQmdWTVdfPVP3oI+J7wPeq5v2rite7gd01tvtfwC2LjNHsEj+7xKx5fgSC9RQ/u8SseU701lP87BKz5vlZN9ZT/OwSy6N2PwrBid5q6ubh17r52SWWb+34XmTxKARX3dgV3IXR7Ert+l5k8SgEJ3q7Qr0T74tPHPcNStZ1srqBrl0JOYueZK66sSvMd4J1y+DK3Vy1ZLWlOWbNHtcsnwDZroS8fHiIUo33aGVPMpfo7QqNTrBOD67sqqXeewxEmmO2kOOa5RMg29W1N4ueZE70NfTal6jVap141Tp5g1KWX+5ulMUPXau/A2mO2UKOa5Y30LUrIWfxKARX3VTJ8lKwW1V2Yax1SQmdvUGpU3fHdkt1UbsfA9GO70CaY7aQ45pFtcecdnbtbXdPMif6Kmm+RN3yhW+nuROv+ksP9Usx9T6XVn9eWX6553RTAaDdP3Tt+CFJc8wWclx3blyb+vxshV7t2uuqmyqNvkS1Lpu/+MRxbv39/9aTVTyNLtHTXlbWq0544PCJllcz1LqEHrxKvPHWhbZVt3VTdVE7HwNxeKJU9ypuMT8kaao9FlI1kuUTIHtZ35XoG5UuG5Uqan3hAc7PzPZUFc/hiRK//92TvPbG7KV5pfMzfOmJ43y7+DIvvTpz2Wf0p7t+Y973q5cIv/n8GS5GXDF/vtJho2NUfQl97eBVzMy+fWlf5vbji08cZ3R4iI/98gjP/p/pBV1RzMWSNvlVxj583SAR8PrMbEuv/NpVip37sa5nMT8kaao90qxT79xo53cuD1fwiqovYacVCoUoFoste7/Kg/RLQ4P8v7cuMHvxnX0eGhy4rARQr6pibp3Vu55ivk9sdHioYVLstFr7OJ9an1H1if+lJ47P+7lUE/CTvZ9KFVv1369ev9m/Pd/7NYql2oDEH/7236lbzbWQv5tGO5LPbXufqfuDlib2difEZs+NXv2bCyXpWDKa3xVyU6KvdZIBlx2k8zOzV2xXXbpsVKqoV+Kf0wuPy613VVJP5WdUr656+LrBy64O5gxIV5TooX7psNn64X3jk00l+Ubv1yiWahcjLpWCG63fygbTdpRi5zt30yT5drdhdGIsgryMf5Aq0UvaBPwR5YFHHouIvVXL7wX28c4Qg38cEY8ly+4BHkjm/0FEVI4n2xL1TrJrrr4qVUKrPsHn+xLVumyu1AuPy13Ij1Hp/EzdEt/M7EWuufoqhgYHrij53PWro/zXY6XU1QzNNjQu9Ic1zXZp33vui9/K9+yEeoWY0eGhBf0otjohdqK3VV7GP2jYGCtpANgPfAJYB9wtaV2NVZ+IiFuTf3NJ/r3Ag8BHgA3Ag5KWtiz6RL2TrFYJvpZmkvNc48/S6wavWNbpx+Wm7fu8kB8jwbxXMq/PzNZsFPuDrbc01ViWtqFxbl8XWvGY5jNo5nOau/pr5XtmbTH9xLNIiFmORdDo/Orm41hLmhL9BmAqGdwbSYeALaQb+3Uj8HREnEu2fRrYBHxzYeHWtpiTaSHJubLrYbc00jRz6dzoqqSaoGFCXZ6U+mrtfzPVDGkaGpttY6iW9pjXiqXeZzF3/BvV0Xfzc/MX0088iy6vWXWlTNPW0s3HsZY0iX4UOFMxfZZyCb3aXZJuB/4K+FJEnKmz7RVnjaTtwHaAG264IV3kFeqdZEuvG+QXs29fdsAGrxLvvvZqzr+x+J4Q3dSntplL5+ovdHXvkOpeKvOV5KG1J36aZDNfXXitXjYL7XVTK5aP/fJI3aqoRp9rL/TWWOg5nUUSzmosgkbnVy8cx2qtaoz9LvDNiHhT0j8DvgGk7noSEQeAA1DuddPsH693kj34Dz4I9McgFc1eOjfzhZ6vN0Y7TvxGsc33w9PqHk+1Yinc+N6651Q3/fhnKasknMXnW+87I1p/fmUlTaIvASsrplfwTqMrABHxasXkY8DDFdv+etW2zzUbZCONTrJ++OK189K53g9pp7qY1evJMyBl8vf7NZk3kpfPpRN3XrdbmkR/FFgjaTXlxL0N+J3KFSS9LyJ+mkxuBn6UvB4H/k1FA+zHgd2LjrqGvJxkC9XOS+esSmtp1Ury8803a0bWj1XIQsNEHxEXJO2gnLQHgIMRcVLSHqAYEWPAFyRtBi4A54B7k23PSXqI8o8FwJ65hllrrXYn4276IR2dpxug2WJ1W8GmFXJ/Z6zlTy/drdgtuqmHmLVHX9wZa/0jjyWuduqmJ29aZzjRW0/qpqqkxWp3aTsvt/HbwjnRm3VQFqXtvNzGbwvn59GbdVAWz7nP8tEBWen34T6b5URv1kFZlLazGHw6Sx4cvnlO9GYdlEVpO2+jMHXTaF+9wnX0Zh2U1c05eWq8dptD85zozX2sO8hdRZuXx0cUtJsTfZ9zH+vOy1NpOwt5fERBu7mOvs+5vtN6Td7aHLLgEn2fc32n9SJfBTXHJfo+l8c+1mZ2OZfou1gWjaSu7+wNbjC3xXCi71JZNZK610f3c4O5LZYTfZfK8kFUru/sbn4omS2W6+i7lBtJbY7PBVusVIle0iZJk5KmJO2aZ727JIWkQjK9StKMpOPJv0daFXjeuZHU5vhcsMVqmOglDQD7gU8A64C7Ja2rsd71wO8Cz1ctejEibk3+3deCmPtC3h5EZQvnc8EWK02JfgMwFRGnI+It4BCwpcZ6DwFfA37Rwvj6lm8KsTk+F2yx0jTGjgJnKqbPAh+pXEHSh4GVEfGUpJ1V26+WNAH8HHggIv5n9R+QtB3YDnDDDTc0EX6+uZHU5vhcsMVYdGOspKuArwNfrrH4p8ANEbEeuB94XNJ7qleKiAMRUYiIwsjIyGJDMjOzCmkSfQlYWTG9Ipk353rgQ8Bzkl4CPgqMSSpExJsR8SpARBwDXgRubkXgZmaWTppEfxRYI2m1pCXANmBsbmFEvB4RyyJiVUSsAo4AmyOiKGkkacxF0k3AGuB0y/fCzMzqalhHHxEXJO0AxoEB4GBEnJS0ByhGxNg8m98O7JE0C7wN3BcR51oRuFkr+NEC1g8UEZ2O4TKFQiGKxWKnw7A+UP1oASh3W3SPFutFko5FRKHWMt8Za33Lz+K3fuFEb33LjxawfuFEb33LjxawfuFEb33LjxawfuHHFFvf8rP4rV840TfBXfHyx48WsH7gRJ+SR/kxs17lOvqU3BXPzHqVE31K7opnZr3KiT4ld8Uzs17lRJ+Su+Klc3iixG17n2H1rqe4be8zHJ4oNd7IzNrKjbEpuSteY26wNutOTvRN6NeueGm7lc7XYN2Pn5tZt3Cit3k1U0p3g7VZd3Idvc2rmW6lbrA2606pEr2kTZImJU1J2jXPendJCkmFinm7k+0mJW1sRdCWnWZK6W6wNutODatukqEA9wN3AmeBo5LGIuJU1XrXA78LPF8xbx3loQc/CCwH/rukmyPi8iKida3h6wZ57Y3ZK+bXKqW7wdqsO6Wpo98ATEXEaQBJh4AtwKmq9R4CvgbsrJi3BTgUEW8CP5E0lbzfny02cGu/wxMl/u8vLlwxf3BAdUvp/dpgbdbN0lTdjAJnKqbPJvMukfRhYGVEPNXstsn22yUVJRWnp6dTBW7tt298ktm3rxxq8l1LrnYyN+shi26MlXQV8HXgywt9j4g4EBGFiCiMjIwsNiRrkXr186/PXFmVY2bdK02iLwErK6ZXJPPmXA98CHhO0kvAR4GxpEG20bbWxdyLxiwf0iT6o8AaSaslLaHcuDo2tzAiXo+IZRGxKiJWAUeAzRFRTNbbJukaSauBNcCft3wvrC3ci8YsHxo2xkbEBUk7gHFgADgYEScl7QGKETE2z7YnJX2LcsPtBeDz7nHTO9yLxiwfFHFlY1snFQqFKBaLnQ7DzKynSDoWEYVay/wIBLMMeBhK6yQnerM281M9rdP8rBuzNvMwlNZpLtGbLVDa6hg/1dM6zSV6swWYq44pnZ8heKc6ptaIWr4fwTrNid5sAZqpjvH9CNZprroxW4BmqmN8P4J1mhO92QIsHx6iVCOp16uO8VM9rZNcdWO2AK6OsV7iEr3ZArg6xnqJE73ZArk6xnqFq27MzHLOid7MLOec6M3Mcs6J3sws51IlekmbJE1KmpK0q8by+ySdkHRc0p9IWpfMXyVpJpl/XNIjrd4BMzObX8NeN5IGgP3AncBZ4KiksYg4VbHa4xHxSLL+ZsqDhW9Klr0YEbe2NmwzM0srTYl+AzAVEacj4i3gELClcoWI+HnF5LuA7hq2ysysj6VJ9KPAmYrps8m8y0j6vKQXgYeBL1QsWi1pQtL/kPT3a/0BSdslFSUVp6enmwjfzMwaaVljbETsj4j3A78HPJDM/ilwQ0SsB+4HHpf0nhrbHoiIQkQURkZGWhWSmZmRLtGXgJUV0yuSefUcArYCRMSbEfFq8voY8CJw88JCNTOzhUiT6I8CayStlrQE2AaMVa4gaU3F5KeAHyfzR5LGXCTdBKwBTrcicDMzS6dhr5uIuCBpBzAODAAHI+KkpD1AMSLGgB2S7gBmgdeAe5LNbwf2SJoF3gbui4hz7dgRMzOrTRHd1UGmUChEsVjsdBhmZj1F0rGIKNRa5jtjzcxyzonezCznnOjNzHLOid7MLOec6M3Mcs6J3sws55zozcxyzonezCznnOjNzHLOid7MLOec6M3Mcs6J3sws55zozcxyzonezCznnOjNzHIuVaKXtEnSpKQpSbtqLL9P0glJxyX9iaR1Fct2J9tNStrYyuDNzKyxhok+GQpwP/AJYB1wd2UiTzweEbdExK3Aw8DXk23XUR568IPAJuDfzw0taGZm2UhTot8ATEXE6Yh4i/Lg31sqV4iIn1dMvguYG7ZqC3AoGST8J8BU8n5mZpaRhmPGAqPAmYrps8BHqleS9HngfmAJ8BsV2x6p2nZ0QZGamdmCtKwxNiL2R8T7gd8DHmhmW0nbJRUlFaenp1sVkpmZkS7Rl4CVFdMrknn1HAK2NrNtRByIiEJEFEZGRlKEZGZmaaVJ9EeBNZJWS1pCuXF1rHIFSWsqJj8F/Dh5PQZsk3SNpNXAGuDPFx+2mZml1bCOPiIuSNoBjAMDwMGIOClpD1CMiDFgh6Q7gFngNeCeZNuTkr4FnAIuAJ+PiItt2hczM6tBEdF4rQwVCoUoFoudDsPMrKdIOhYRhVrLfGesmVnOOdGbmeWcE72ZWc6luWHKrG8dniixb3ySV87PsHx4iJ0b17J1ve/5s97iRG9Wx+GJErufPMHMbLmjWOn8DLufPAHgZG89xVU3ZnXsG5+8lOTnzMxeZN/4ZIciMlsYJ3qzOl45P9PUfLNu5URvVsfy4aGm5pt1Kyd6szp2blzL0ODlwycMDQ6wc+PaDkVktjBujDWrY67B1b1urNc50ZvNY+v6USd263muujEzyzknejOznHOiNzPLOSd6M7Occ6I3M8u5VIle0iZJk5KmJO2qsfx+SackvSDpB5JurFh2UdLx5N9Y9bZmZtZeDbtXShoA9gN3AmeBo5LGIuJUxWoTQCEi3pD0OeBh4B8ly2Yi4tYWx21mZimlKdFvAKYi4nREvAUcArZUrhARz0bEG8nkEWBFa8M0M7OFSpPoR4EzFdNnk3n1fBb4fsX0tZKKko5I2lprA0nbk3WK09PTKUIyM7O0WnpnrKTPAAXg1ypm3xgRJUk3Ac9IOhERL1ZuFxEHgANQHhy8lTGZmfW7NCX6ErCyYnpFMu8yku4AvgJsjog35+ZHRCn5/zTwHLB+EfGamVmT0iT6o8AaSaslLQG2AZf1npG0HniUcpL/WcX8pZKuSV4vA24DKhtxzcyszRpW3UTEBUk7gHFgADgYEScl7QGKETEG7APeDXxbEsDLEbEZ+ADwqKS3Kf+o7K3qrWNmZm2miO6qEi8UClEsFjsdhplZT5F0LCIKtZb5zlgzs5xzojczyzknejOznHOiNzPLOSd6M7Occ6I3M8s5J3ozs5xzojczyzknejOznHOiNzPLOSd6M7Occ6I3M8s5J3ozs5xzojczyzknejOznEuV6CVtkjQpaUrSrhrL75d0StILkn4g6caKZfdI+nHy755WBm9mZo01TPSSBoD9wCeAdcDdktZVrTYBFCLiV4DvAA8n274XeBD4CLABeFDS0taFb2ZmjaQp0W8ApiLidES8BRwCtlSuEBHPRsQbyeQRygOIA2wEno6IcxHxGvA0sKk1oZuZWRppEv0ocKZi+mwyr57PAt9vZltJ2yUVJRWnp6dThGRmZmm1tDFW0meAAuXBwlOLiAMRUYiIwsjISCtDMjPre2kSfQlYWTG9Ipl3GUl3AF8BNkfEm81sa2Zm7ZMm0R8F1khaLWkJsA0Yq1xB0nrgUcpJ/mcVi8aBj0tamjTCfjyZZ2ZmGbm60QoRcUHSDsoJegA4GBEnJe0BihExRrmq5t3AtyUBvBwRmyPinKSHKP9YAOyJiHNt2RMzM6tJEdHpGC5TKBSiWCx2Ogwzs54i6VhEFGot852xZmY550RvZpZzTvRmZjnnRG9mlnNO9GZmOedEb2aWc070ZmY550RvZpZzTvRmZjnnRG9mlnNO9GZmOedEb2aWcw2fXmntdXiixL7xSV45P8Py4SF2blzL1vXzDeBlZtYcJ/oOOjxRYveTJ5iZvQhA6fwMu588AeBkb2Yt46qbDto3Pnkpyc+Zmb3IvvHJDkVkZnmUKtFL2iRpUtKUpF01lt8u6X9LuiDpt6qWXZR0PPk3Vr1tP3vl/ExT883MFqJh1Y2kAWA/cCdwFjgqaSwiTlWs9jJwL/Ava7zFTETc2oJYc2f58BClGkl9+fBQB6Ixs7xKU6LfAExFxOmIeAs4BGypXCEiXoqIF4C32xBjbu3cuJahwYHL5g0NDrBz49oORWRmeZQm0Y8CZyqmzybz0rpWUlHSEUlba60gaXuyTnF6erqJt+5tW9eP8tVP38Lo8BACRoeH+Oqnb3FDrJm1VBa9bm6MiJKkm4BnJJ2IiBcrV4iIA8ABKI8Zm0FMXWPr+lEndjNrqzQl+hKwsmJ6RTIvlYgoJf+fBp4D1jcRn5mZLVKaRH8UWCNptaQlwDYgVe8ZSUslXZO8XgbcBpyafyszM2ulhok+Ii4AO4Bx4EfAtyLipKQ9kjYDSPq7ks4C/xB4VNLJZPMPAEVJfwE8C+yt6q1jZmZtpojuqhIvFApRLBY7HYaZWU+RdCwiCrWW+c5YM7Oc67oSvaRp4K/nWWUZ8DcZhdNt+nXfvd/9p1/3fTH7fWNEjNRa0HWJvhFJxXqXJ3nXr/vu/e4//brv7dpvV92YmeWcE72ZWc71YqI/0OkAOqhf99373X/6dd/bst89V0dvZmbN6cUSvZmZNcGJ3sws57o20acY1eoaSU8ky5+XtCr7KFsvxX7fL+mUpBck/UDSjZ2Isx0a7XvFendJCkm56H6XZr8l/XZy3E9KejzrGNshxbl+g6RnJU0k5/snOxFnq0k6KOlnkv6yznJJ+nfJ5/KCpA8v+o9GRNf9AwaAF4GbgCXAXwDrqtb558AjyettwBOdjjuj/f4YcF3y+nN52O+0+56sdz3wQ+AIUOh03Bkd8zXABLA0mf7bnY47o/0+AHwueb0OeKnTcbdo328HPgz8ZZ3lnwS+Dwj4KPD8Yv9mt5boG45qlUx/I3n9HeA3JSnDGNshzWhez0bEG8nkEcqPjc6DNMcc4CHga8AvsgyujdLs9z8F9kfEawAR8bOMY2yHNPsdwHuS178EvJJhfG0TET8Ezs2zyhbgP0fZEWBY0vsW8ze7NdGnGdXq0jpRfsLm68DfyiS69ml2NK/PUv7lz4OG+55cwq6MiKeyDKzN0hzzm4GbJf1pMlLbpsyia580+/2vgc8kT8b9HvAvsgmt4xY7qt8VshhhytpA0meAAvBrnY4lC5KuAr5OeRD6fnM15eqbX6d8BfdDSbdExPmORtV+dwP/KSL+UNLfA/6LpA9FhMemblK3lujTjGp1aR1JV1O+tHs1k+jaJ9VoXpLuAL4CbI6INzOKrd0a7fv1wIeA5yS9RLnuciwHDbJpjvlZYCwiZiPiJ8BfUU78vSzNfn8W+BZARPwZcC3lh37l3aJG9aulWxN9mlGtxoB7kte/BTwTSUtGD2u435LWA49STvJ5qKudM+++R8TrEbEsIlZFxCrK7RObI6LXBy9Ic64fplyanxup7WbgdJZBtkGa/X4Z+E0ASR+gnOinM42yM8aAf5z0vvko8HpE/HQxb9iVVTcRcUHS3KhWA8DBSEa1AooRMQb8R8qXclOUGza2dS7i1ki53/uAdwPfTtqeX46IzR0LukVS7nvupNzvceDjkk4BF4GdEdHTV68p9/vLwH+Q9CXKDbP35qAwh6RvUv7hXpa0PzwIDAJExCOU2yM+CUwBbwD/ZNF/Mwefm5mZzaNbq27MzKxFnOjNzHLOid7MLOec6M3Mcs6J3sws55zozcxyzonezCzn/j+oKU/QYaou0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(output_validation[:, 0], y_pred[:, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vc6zEuA60pjh",
        "outputId": "09493f4d-8c4b-44aa-a4ed-ba540dd88b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 16ms/step\n",
            "test_nrmse is:  0.9729840519127527\n",
            "test_mse is: 0.060578331553446725\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/TCN_400/{}.pickle\".format(41), \"rb\") as fin:\n",
        "    best_tcn = pickle.load(fin)\n",
        "    model = best_tcn\n",
        "tcn_400_y_pred = model.predict(input_test)\n",
        "tcn400_test_nrmse = np.sqrt(np.sum((output_test - tcn_400_y_pred)**2))/np.sqrt(np.sum((output_test - np.average(output_test))**2))\n",
        "mse = mean_squared_error(output_test, tcn_400_y_pred)\n",
        "print(\"test_nrmse is: \",tcn400_test_nrmse)\n",
        "print(\"test_mse is:\", mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f4Qq05kV0taf",
        "outputId": "a97d3842-e329-49a4-8eb7-9d85241492b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 2s 883ms/step\n",
            "test_nrmse is:  0.8421295850719867\n",
            "test_mse is: 0.04537991875378236\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/transformer_pk/{}.pickle\".format(1), \"rb\") as fin:\n",
        "    best_transf = pickle.load(fin)\n",
        "model_transf = best_transf\n",
        "y_pred = model_transf.predict(input_test)\n",
        "test_nrmse = np.sqrt(np.sum((output_test - y_pred)**2))/np.sqrt(np.sum((output_test - np.average(output_test))**2))\n",
        "mse = mean_squared_error(output_test, y_pred)\n",
        "print(\"test_nrmse is: \",test_nrmse)\n",
        "print(\"test_mse is:\", mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Dzj-zmWX2T2P",
        "outputId": "0e6f03b7-2a43-4177-bb8c-9158921c3f22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fa7119a54d0>"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYuElEQVR4nO3dfYxc133e8e/D9cpep4qplhvEWlFe2qDYyFYsWlPZhRC3USyTsVCSsJKUboNYQRpBqVgHtrEIiRqNSwcwbSJqXFSBwyhCnKY2JavCYg21WLiVHaNCqXCIlcyQ7iYUlYpcGchGEuW2WlNL6tc/5i49O5qXOzt33s4+H4Dg3reZc+/MPHPnnHPPVURgZmbp2tDvApiZWXc56M3MEuegNzNLnIPezCxxDnozs8S9qd8FqLVp06aYnJzsdzHMzIbKiRMn/jYixustG7ign5ycpFwu97sYZmZDRdL/brTMVTdmZolz0JuZJc5Bb2aWOAe9mVniHPRmZokbuF43ZoNmem6Bw7PzvHBhiWs3jjG1Yxt7tk/0u1hmuTnozZqYnlvgwGMnWVq+DMDChSUOPHYSwGFvQ8NVN2ZNHJ6dvxLyK5aWL3N4dr5PJTJrn4PerIkXLiy1Nd9sEDnozZq4duNYW/PNBpGD3qyJqR3bGBsdWTVvbHSEqR3b+lQis/a5MdasiZUGV/e6sWHmoDdrYc/2CQe7DTVX3ZiZJc5Bb2aWOAe9mVniHPRmZolz0JuZJS5X0EvaKWle0hlJ++ssv1vSoqSns3//omrZ5ar5M0UW3szMWmvZvVLSCPAAcAdwHjguaSYiTtes+nBE7KvzEEsRcXPnRTUzs7XIc0Z/K3AmIs5GxGvAUWB3d4tlZmZFyRP0E8C5qunz2bxad0n6rqRHJW2umv8WSWVJxyTt6aSwZmbWvqIaY78BTEbETwPfBL5StewdEVEC/hnwe5LeVbuxpHuyL4Py4uJiQUUyMzPIF/QLQPUZ+nXZvCsi4sWIuJhNPgjcUrVsIfv/LPBtYHvtE0TEkYgoRURpfHy8rR0wM7Pm8ox1cxzYKmkLlYDfS+Xs/ApJb4+I72eTu4DvZfOvAV6NiIuSNgG3AV8sqvBmVgzfLjFtLYM+Ii5J2gfMAiPAQxFxStJBoBwRM8AnJO0CLgEvAXdnm/8U8AeSXqfy6+FQnd46liiHx3Dw7RLTp4jodxlWKZVKUS6X+10M61BteEBlHPfPf/Qmh8eAue3QEyzUuWPWxMYxntx/ex9KZGsh6UTWHvoGvjLWusL3Wh0evl1i+hz01hUOj+Hh2yWmz0FvXeHwGB6+XWL6HPTWFQ6P4bFn+wSf/+hNTGwcQ1Tq5t2WkhbfStC6wvdaHS6+XWLaHPTWNQ4Ps8HgoC+Q+42b2SBy0BfEF50Ur/aL82f//jjf+l+L/iI1a5MbYwvifuPFWvniXLiwRFD54vzTY8+vmj7w2Emm5xZaPZTZuuegL4j7jRer3hdnLX+RmuXjoC+I+40XK+8XpL9IzVpz0BfE/caLlfcLcr1/kU7PLXDboSfYsv9xbjv0hKuyrC4HfUF80Umx6n1x1lrvX6T12jHcbmH1uNdNgdxvvDj1Lrhyr5vVmnUAWM/Hxd7IQW8Dy1+czbkDgOXlqhuzIeUOAJaXg95sSLkDgOXlqhuzIeWB4ywvB73ZEHM7huXhqhszs8Q56M3MEuegNzNLnOvoe8Rj1ZtZvzjoe8Bj1ZtZP7nqpgc8Vr2Z9ZPP6HtgkC5VdxXSYPDrYNW6/X7IFfSSdgJfAkaAByPiUM3yu4HDwMqwef8hIh7Mln0c+Ew2/3ci4isFlLunOn0Rrt04xkKdUC/yUvVGZaye/7axUf7fa5dYvhzA+qpCWjkOCxeWGJG4HMFEdpyg/kVH3frwuSqv9wb5i7UX7wdFRPMVpBHgL4E7gPPAceBjEXG6ap27gVJE7KvZ9u8CZaAEBHACuCUiXm70fKVSKcrl8pp2phtqXwSoXGbezhDERTzGWh7/rlsm+M8nFlreqWli4xhP7r+94WN3K+x69cGrd3xWjG4QiCtfftD42BX1mt126Im6X/zNXod+GIRwnJ5b4LMzp7iwtAzANW8d5bf/ybvfUI5mZe32569TRb0fJJ2IiFK9ZXnO6G8FzkTE2ezBjgK7gdNNt6rYAXwzIl7Ktv0msBP4Wp6CF2l6boF/+41TvPxq5Q2zcWyUz+564xum0frV2h0KttuXqjdqA/jTY8/n2r5RFVKRZxrVH8S3jG5gafn1K8u6fUbb7LaEy6+/8URnafkyX3vqHJdrToKave7thGKzqrxBCFdo/7XvpNzNfo1Off2ZVa/Ry68uM/XoM6vK8Znpk/ynY8+zslZtWQd9OOd6Id9s/lrkCfoJ4FzV9Hng/XXWu0vSB6mc/X8yIs412PYNR1bSPcA9ANdff32+krdhem6BqUefWXXWdmFpmamvr37DNFu/Vrv16928VL3Tuv5GVUiNPiCffuQZPvnw07k/0LWhUR3y1Y/brQ/eWo5Pbcg3e6x2Q7FRVd7bxkYHpkqnnXDs5ISg2baHZ+frfhEvX44r5ZieW1gV8vXK2osg7cRKVWK9+UUpqtfNN4DJiPhp4JtAW/XwEXEkIkoRURofHy+oSD9yeHa+bmgvvx51e740Wr/aIA0F20lZmo122CggL0e0dUejPDf6bvZ8nVrL8Wn0Iav3WO32qmo06qTEwPTOaqcDQSe9yppt2+z9sLLs8Oz8G0K+dp1Gr2WRQdqJRicVjeavRZ6gXwA2V01fx48aXQGIiBcj4mI2+SBwS95teyHPGybv+jB4Q8Hmue3eitEN4pq3jua63WGegFw5w28W9nkDvFtfns2Oz+gGMTqy+gM/NjrCx96/OfcQwO32qmp028kLdaoJmz1ON7Uz1n0nvcqabdvs/bCyrNlzrKzTiyDtxESD/Ww0fy3yBP1xYKukLZKuAvYCM9UrSHp71eQu4HvZ37PAhyVdI+ka4MPZvJ7K84bJu/6INDCNOCtqg6PZGczhX3wvc//mwzx36E6e3H970/3I+wVyOaLpmX2eAFf2fN1QfXzgR8dnYuMYh3/xvRz+hfe+IXR/Z89Nue8BvJYbgOzZPsGT+29f9ToM0o1E2hnrvpNyN9t2ase2SmN5jdERXSlHo+2r30+9CNJO9OK+Ai3r6CPikqR9VAJ6BHgoIk5JOgiUI2IG+ISkXcAl4CXg7mzblyR9jsqXBcDBlYbZXqjuUlfP6AbVPZhTO7bVraMf3VAJykEK+RXVbQBF9TKobUTe0KAuEZrXsU/t2Naw1wtUPpT//APXd/W4tmojqbcsb7tKvf1bywe1qMcpQjsdCDopd7NtV56rWa+betvXvp8G6bjW04v7CrTsXtlrRXWvbNalDtrvddNq/UHTjd4brY6pgOcO3dmyPG8bG0WCC68uD1yf5rWqd7yh/Q/voPS6aVc3et0U+dzDelzb0ax7ZbJBPyx9lYfN9NwCn37kmbpn9j62PzLofbctPc2CPtmxbgZp2IGU7Nk+we/+0nt9r9IWPL6RDZJkg36QGrZSU9v4u3FslLeMbuCTDz/NbYeeaNndcj3wiYYNkmSDvhct2evZSq+Rf/dPb+bipdd5+dXltvrWp84nGjZIkg36Rn2VXT9aLFdR1OcTje6YnlvgtkNPsGX/4/712Iakhynu5rADVuEqivp60WVuvfGon2uXdNBb9/ViCOZh5RONYg364GSDLNmqG+sNV1FYr/jX49o56K0jbguxXnED99q56sY65ioKa8dar1Id9KEMBlkyQb8eLnE2G3adNKi6gXvtkgh6t8abDYdOG1T963Ftkgh6t8ZbL/hXY+fcoNofSTTG+s1j3bbyq3HhwpKvAO6AG1T7I4mg95vHus1XABfD3XH7I4mg95vHus2/Govh7rj9kUQdvVvjrdt8BXBx3KDae0kEPfjNY93lPtw2zJIJenCvCOse/2q0YZZM0LsvvXWbfzXasEqiMRbcK8LMrJFkgt69IszM6kum6ma994pw+0R/+LjbMEjmjH4996X3VZv94eNuwyKZoF/PF2K4faI/fNxtWOSqupG0E/gSMAI8GBGHGqx3F/Ao8A8ioixpEvgesPLOPxYR93Za6EbWa68It0/0h4+7DYuWQS9pBHgAuAM4DxyXNBMRp2vWuxr4TeCpmod4NiJuLqi8Vsd6b5/olyKPu+v6rZvyVN3cCpyJiLMR8RpwFNhdZ73PAV8Aflhg+SyH9dw+0U9FHXfX9Vu35Qn6CeBc1fT5bN4Vkt4HbI6Ix+tsv0XSnKQ/k/Qz9Z5A0j2SypLKi4uLectumfXcPtFPRR131/Vbt3XcvVLSBuB+4O46i78PXB8RL0q6BZiW9O6I+EH1ShFxBDgCUCqVotMyrUfrtX2i34o47q7rt27LE/QLwOaq6euyeSuuBt4DfFsSwE8CM5J2RUQZuAgQESckPQvcAJQLKLtZ2waxLtxtLNZteapujgNbJW2RdBWwF5hZWRgRr0TEpoiYjIhJ4BiwK+t1M5415iLpncBW4Gzhe2GWw6DWhbuNxbqtZdBHxCVgHzBLpavkIxFxStJBSbtabP5B4LuSnqbS7fLeiHip00KbrcWg1oW7jcW6TRGDVSVeKpWiXHbNzqAZxCqPdm3Z/zj13u0Cnjt0Z6+LY1YoSSciolRvWTJXxlr3DGqVR7t8b2Fbrxz01tKgVnm0y3Xhtl4lM3qldU8q3f98lyhbrxz01lJK3f98vYGtR666sZZc5WE23HxGby25ysNsuDnoLRdXeZgNL1fdmJklzkFvZpY4B72ZWeJcR5+AFIYnMLPucdAPuZXhCVauXF0ZngBw2JsZ4KqboZfK8ARm1j0O+iGXyvAEZtY9Dvoh5xEZzawVB/2Q8/AEZtaKG2OHnIcnMLNWHPQJ8PAEZtaMq27MzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PE5Qp6STslzUs6I2l/k/XukhSSSlXzDmTbzUvaUUShzcwsv5ZXxkoaAR4A7gDOA8clzUTE6Zr1rgZ+E3iqat6NwF7g3cC1wH+TdENErB5X18zMuibPGf2twJmIOBsRrwFHgd111vsc8AXgh1XzdgNHI+JiRDwHnMkez8zMeiRP0E8A56qmz2fzrpD0PmBzRDze7rbZ9vdIKksqLy4u5iq4mZnl03FjrKQNwP3Ap9f6GBFxJCJKEVEaHx/vtEhmZlYlz+iVC8DmqunrsnkrrgbeA3xbEsBPAjOSduXY1szMuizPGf1xYKukLZKuotK4OrOyMCJeiYhNETEZEZPAMWBXRJSz9fZKerOkLcBW4M8L3wszM2uo5Rl9RFyStA+YBUaAhyLilKSDQDkiZppse0rSI8Bp4BJwn3vcmJn1liKi32VYpVQqRblc7ncxzMyGiqQTEVGqt8xXxpqZJc5Bb2aWON8zdohNzy34puBm1pKDfkhNzy1w4LGTLC1X2rYXLixx4LGTAA57M1vFVTdD6vDs/JWQX7G0fJnDs/N9KpGZDSoH/ZB64cJSW/PNbP1y0A+pazeOtTXfzNYvB/2QmtqxjbHRkVXzxkZHmNqxrU8lMrNB5cbYIbXS4OpeN2bWioN+iO3ZPuFgN7OWXHVjZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzhdMmdXhsf4tJQ56sxoe699S46obsxoe699S46A3q+Gx/i01DnqzGh7r31LjoDer4bH+LTVujDWr4bH+LTW5gl7STuBLwAjwYEQcqll+L3AfcBn4v8A9EXFa0iTwPWClFetYRNxbTNHNusdj/VtKWga9pBHgAeAO4DxwXNJMRJyuWu2rEfHlbP1dwP3AzmzZsxFxc7HFNjOzvPLU0d8KnImIsxHxGnAU2F29QkT8oGryx4AorohmZtaJPEE/AZyrmj6fzVtF0n2SngW+CHyiatEWSXOS/kzSz9R7Akn3SCpLKi8uLrZRfDMza6WwXjcR8UBEvAv4LeAz2ezvA9dHxHbgU8BXJf14nW2PREQpIkrj4+NFFcnMzMgX9AvA5qrp67J5jRwF9gBExMWIeDH7+wTwLHDD2opqZmZrkSfojwNbJW2RdBWwF5ipXkHS1qrJO4G/yuaPZ425SHonsBU4W0TBzcwsn5a9biLikqR9wCyV7pUPRcQpSQeBckTMAPskfQhYBl4GPp5t/kHgoKRl4HXg3oh4qRs7YmZm9SlisDrIlEqlKJfL/S6GmdlQkXQiIkr1lnkIBDOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxLW8laANvum5BQ7PzvPChSWu3TjG1I5t7Nk+0e9imdmAcNAPuem5BQ48dpKl5csALFxY4sBjJwEc9mYGuOpm6B2enb8S8iuWli9zeHa+TyUys0HjoB9yL1xYamu+ma0/Dvohd+3Gsbbmm9n646AfclM7tjE2OrJq3tjoCFM7tvWpRGY2aNwYO+RWGlzd68bMGnHQJ2DP9gkHu5k1lKvqRtJOSfOSzkjaX2f5vZJOSnpa0v+QdGPVsgPZdvOSdhRZeDMza61l0EsaAR4Afh64EfhYdZBnvhoRN0XEzcAXgfuzbW8E9gLvBnYCv589npmZ9UieM/pbgTMRcTYiXgOOArurV4iIH1RN/hgQ2d+7gaMRcTEingPOZI9nZmY9kqeOfgI4VzV9Hnh/7UqS7gM+BVwF3F617bGabV2ZbGbWQ4V1r4yIByLiXcBvAZ9pZ1tJ90gqSyovLi4WVSQzMyNf0C8Am6umr8vmNXIU2NPOthFxJCJKEVEaHx/PUSQzM8srT9AfB7ZK2iLpKiqNqzPVK0jaWjV5J/BX2d8zwF5Jb5a0BdgK/HnnxTYzs7xa1tFHxCVJ+4BZYAR4KCJOSToIlCNiBtgn6UPAMvAy8PFs21OSHgFOA5eA+yLict0nMjOzrlBEtF6rh0qlUpTL5X4Xw8xsqEg6ERGless81o2ZWeIc9GZmifNYN9aUb1NoNvwc9NaQb1NolgYHvTXU7DaFeYLevwbMBoOD3hrq5DaF/jVgNjjcGGsNdXKbQt+03GxwOOitoU5uU+iblpsNDge9NbRn+wSf/+hNTGwcQ8DExjE+/9GbclW9+KblZoPDdfTW1FpvUzi1Y9uqOnrwTcvN+sVBb13hm5abDQ4HvXWNb1puNhhcR29mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mlriBu8OUpP8DrOfr5DcBf9vvQvTZej8G3n/v/1r2/x0RMV5vwSB2r5xvdDus9UBSeT3vP/gYeP+9/0Xvv6tuzMwS56A3M0vcIAb9kX4XoM/W+/6Dj4H3f30rfP8HrjHWzMyKNYhn9GZmViAHvZlZ4voW9JJ2SpqXdEbS/jrL3yzp4Wz5U5Ime1/K7smx/5+SdFrSdyX9d0nv6Ec5u6XV/letd5ekkJRUd7s8+y/pl7L3wClJX+11Gbspx/v/eknfkjSXfQY+0o9ydoukhyT9jaS/aLBckv59dny+K+l9HT1hRPT8HzACPAu8E7gKeAa4sWadfwl8Oft7L/BwP8rax/3/WeCt2d+/sd72P1vvauA7wDGg1O9y9/j13wrMAddk0z/R73L3eP+PAL+R/X0j8Nf9LnfBx+CDwPuAv2iw/CPAfwUEfAB4qpPn69cZ/a3AmYg4GxGvAUeB3TXr7Aa+kv39KPBzktTDMnZTy/2PiG9FxKvZ5DHguh6XsZvyvP4AnwO+APywl4XrgTz7/+vAAxHxMkBE/E2Py9hNefY/gB/P/n4b8EIPy9d1EfEd4KUmq+wG/iQqjgEbJb19rc/Xr6CfAM5VTZ/P5tVdJyIuAa8Af68npeu+PPtf7deofLunouX+Zz9VN0fE470sWI/kef1vAG6Q9KSkY5J29qx03Zdn/z8L/LKk88B/Af5Vb4o2MNrNiKYGcQgEqyLpl4ES8I/6XZZekbQBuB+4u89F6ac3Uam++cdUfs19R9JNEXGhr6XqnY8BfxwRvyvpHwL/UdJ7IuL1fhdsGPXrjH4B2Fw1fV02r+46kt5E5efbiz0pXffl2X8kfQj418CuiLjYo7L1Qqv9vxp4D/BtSX9NpY5yJqEG2Tyv/3lgJiKWI+I54C+pBH8K8uz/rwGPAETE/wTeQmWwr/UiV0bk1a+gPw5slbRF0lVUGltnataZAT6e/f0LwBORtVIkoOX+S9oO/AGVkE+pfhZa7H9EvBIRmyJiMiImqbRR7IqIcn+KW7g87/9pKmfzSNpEpSrnbC8L2UV59v954OcAJP0UlaBf7Gkp+2sG+JWs980HgFci4vtrfbC+VN1ExCVJ+4BZKi3wD0XEKUkHgXJEzAB/ROXn2hkqjRZ7+1HWbsi5/4eBvwN8PWuDfj4idvWt0AXKuf/Jyrn/s8CHJZ0GLgNTEZHEL9qc+/9p4A8lfZJKw+zdCZ3oIelrVL7IN2XtEL8NjAJExJeptEt8BDgDvAr8akfPl9CxMzOzOnxlrJlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXu/wPcGHu5Rl5tuAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(output_test[:, 0], tcn_400_y_pred[:, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UPs_afKT2tw9",
        "outputId": "d75e5f03-c718-429e-c33d-c1565a381643"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fa7119a5ad0>"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(output_test[:, 0], y_pred[:, 0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}